{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oTQepFU0ygro"
   },
   "source": [
    "# **DENSE NET**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MG_iKsii0Fbr"
   },
   "source": [
    "1.  Please visit this link to access the state-of-art DenseNet code for reference - DenseNet - cifar10 notebook link\n",
    "2.  You need to create a copy of this and \"retrain\" this model to achieve 90+ test accuracy. \n",
    "3.  You cannot use Dense Layers (also called fully connected layers), or DropOut.\n",
    "4.  You MUST use Image Augmentation Techniques.\n",
    "5.  You cannot use an already trained model as a beginning points, you have to initilize as your own\n",
    "6.  You cannot run the program for more than 300 Epochs, and it should be clear from your log, that you have only used 300 Epochs\n",
    "7.  You cannot use test images for training the model.\n",
    "8.  You cannot change the general architecture of DenseNet (which means you must use Dense Block, Transition and Output blocks as mentioned in the code)\n",
    "9.  You are free to change Convolution types (e.g. from 3x3 normal convolution to Depthwise Separable, etc)\n",
    "10. You cannot have more than 1 Million parameters in total\n",
    "11. You are free to move the code from Keras to Tensorflow, Pytorch, MXNET etc. \n",
    "12. You can use any optimization algorithm you need. \n",
    "13. You can checkpoint your model and retrain the model from that checkpoint so that no need of training the model from first if you lost at any epoch while training. You can directly load that model and Train from that epoch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BnuTgWt-yf8L"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a3rdlaYXyzZw"
   },
   "source": [
    "## 1. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "9HDuNkepynB4",
    "outputId": "0c72ed48-26b0-4c69-b14a-ce10b1cd3f30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 1)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oyPGwUr60U2W"
   },
   "source": [
    "## 2. Look at some random images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "colab_type": "code",
    "id": "V5SpYpee0QIJ",
    "outputId": "6c523cdd-a9f2-4ef0-c826-be548cef6a6f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/matplotlib/text.py:1150: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if s != self._text:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    " random_num = np.random.randint(0, len(X_train))\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.imshow(cv2.cvtColor(X_train[random_num], cv2.COLOR_BGR2RGB))\n",
    "plt.title(y_train[random_num])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1JoZ6WTL1POz"
   },
   "source": [
    "## 3. Normalise the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dfG-bJJe01X4"
   },
   "outputs": [],
   "source": [
    "X_train = X_train/255.0\n",
    "X_test = X_test/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JS85KQk21ZBN"
   },
   "source": [
    "## 4. Reshaping the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sCuTyC291e-O"
   },
   "outputs": [],
   "source": [
    "img_height = 32\n",
    "img_width = 32\n",
    "channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C6be8vPF1YR8"
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    X_train = X_train.reshape(X_train.shape[0], channels, img_height, img_width).astype('float32')\n",
    "    X_test = X_test.reshape(X_test.shape[0], channels, img_height, img_width).astype('float32')\n",
    "    input_size = (channels, img_height, img_width)\n",
    "    \n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_height, img_width, channels).astype('float32')\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_height, img_width, channels).astype('float32')\n",
    "    input_size = (img_height, img_width, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "wqi1juDU5IUd",
    "outputId": "7f20721a-0025-42ab-f6fd-b54f17f779c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 1)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 1)\n",
      "(32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print(input_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-lT2CGU_5ZLe"
   },
   "source": [
    "## 5. Convert y to 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "Ro1DmuyjzcAi",
    "outputId": "0dad6692-c2fb-44d8-f9fc-80043f7b1294"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "#convert y to 10 categories\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UmR7R47p5uA5"
   },
   "source": [
    "## 6. Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m6WvPgM05Uvd"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "data_generator = ImageDataGenerator(\n",
    "                        featurewise_center=False,\n",
    "                        featurewise_std_normalization=False,\n",
    "                        rotation_range=10,\n",
    "                        width_shift_range=0.1,\n",
    "                        height_shift_range=0.1,\n",
    "                        zoom_range=.1,\n",
    "                        horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u5ImRtcE56gp"
   },
   "source": [
    "## 7. Model- Architecture\n",
    "1. Dense Block\n",
    "2. Transition Block\n",
    "3. Output layer\n",
    "### Refer: https://www.pluralsight.com/guides/introduction-to-densenet-with-tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g_IPBrG273V1"
   },
   "source": [
    "![Dense Net Architecure](https://images.app.goo.gl/rbnE7H8rUTkP5PVv6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QZEX_xD5-5gP"
   },
   "source": [
    "### 7.1 Dense Block\n",
    "- https://images.app.goo.gl/VDzxZGQUEL7kt5N58\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GT-9O15TOWSp"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RIU4UGEMP01s"
   },
   "outputs": [],
   "source": [
    "#BN-->ReLU-->Conv2D-->Dropout-->concat(input, output)-->(put in loop)\n",
    "\n",
    "def denseblock(input, num_filter, dropout_rate):\n",
    "    global compression      # to keep the growth rate of number of filters\n",
    "    temp = input\n",
    "    for _ in range(l): \n",
    "        BatchNorm = layers.BatchNormalization()(temp)\n",
    "        relu = layers.Activation('relu')(BatchNorm)\n",
    "        Conv2D_3_3 = layers.Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n",
    "        if dropout_rate>0:\n",
    "            Conv2D_3_3 = layers.Dropout(dropout_rate)(Conv2D_3_3)\n",
    "\n",
    "        #concat the input(temp) and output(conv2d_3_3) , in resnet we add but here we concat \n",
    "        concat = layers.Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
    "        \n",
    "        #change the concat as input\n",
    "        temp = concat\n",
    "        \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2LOf4gFBCrRZ"
   },
   "source": [
    "### 7.2 Transition Block\n",
    "- https://images.app.goo.gl/7ETwBQqHKwQwXPH26\n",
    "- Conv 1x1 is the bottle neck layer here like in resnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kkjMvAEMQLkT"
   },
   "outputs": [],
   "source": [
    "#BN-->relu-->conv2d(1x1)-->dropout-->avg_pool\n",
    "def transition(input, num_filter, dropout_rate):\n",
    "    global compression\n",
    "    BatchNorm = layers.BatchNormalization()(input)\n",
    "    relu = layers.Activation('relu')(BatchNorm)\n",
    "    Conv2D_BottleNeck = layers.Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
    "    if dropout_rate>0:\n",
    "         Conv2D_BottleNeck = layers.Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
    "    avg = layers.AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
    "    return avg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2XSLEffmFNsi"
   },
   "source": [
    "### 7.3 Output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vdsSzRe6QSAu"
   },
   "outputs": [],
   "source": [
    "#BN-->relu-->avgpool-->flat-->softmax\n",
    "def output_layer(input):\n",
    "    global compression\n",
    "    BatchNorm = layers.BatchNormalization()(input)\n",
    "    relu = layers.Activation('relu')(BatchNorm)\n",
    "    AvgPooling = layers.AveragePooling2D(pool_size=(2,2))(relu)\n",
    "    flat = layers.Flatten()(AvgPooling)\n",
    "    output = layers.Dense(num_classes, activation='softmax')(flat)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eoS2_JI0GQ1J"
   },
   "source": [
    "### 7.4 Full Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YuaTbC2xGDmq"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "l = 12\n",
    "num_filter = 12\n",
    "compression = 0.5\n",
    "dropout_rate = 0.2\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AfdZZql5QYsF"
   },
   "outputs": [],
   "source": [
    "input = layers.Input(shape=(input_size))\n",
    "First_Conv2D = layers.Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
    "\n",
    "#First dense and transition block\n",
    "First_Block = denseblock(First_Conv2D, num_filter, dropout_rate)\n",
    "First_Transition = transition(First_Block, num_filter, dropout_rate)\n",
    "\n",
    "#Second dense and transition block\n",
    "Second_Block = denseblock(First_Transition, num_filter, dropout_rate)\n",
    "Second_Transition = transition(Second_Block, num_filter, dropout_rate)\n",
    "\n",
    "#Third dense and transition block\n",
    "Third_Block = denseblock(Second_Transition, num_filter, dropout_rate)\n",
    "Third_Transition = transition(Third_Block, num_filter, dropout_rate)\n",
    "\n",
    "#last dense and output block\n",
    "Last_Block = denseblock(Third_Transition,  num_filter, dropout_rate)\n",
    "output = output_layer(Last_Block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "RssbqWd5JZAx",
    "outputId": "5c63f915-7460-44b4-c8a9-180932a24893"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 32, 12)   324         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32, 32, 12)   48          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 32, 32, 12)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 6)    648         activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 32, 32, 6)    0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 32, 32, 18)   0           conv2d[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 18)   72          concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 18)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 6)    972         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32, 32, 6)    0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 24)   0           concatenate[0][0]                \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 24)   96          concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 24)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 6)    1296        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32, 32, 6)    0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 30)   0           concatenate_1[0][0]              \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 30)   120         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 30)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 6)    1620        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32, 32, 6)    0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 32, 32, 36)   0           concatenate_2[0][0]              \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 36)   144         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 36)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 6)    1944        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32, 32, 6)    0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 32, 32, 42)   0           concatenate_3[0][0]              \n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 42)   168         concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 42)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 6)    2268        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 32, 32, 6)    0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 32, 32, 48)   0           concatenate_4[0][0]              \n",
      "                                                                 dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 48)   192         concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 6)    2592        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 32, 32, 6)    0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 32, 32, 54)   0           concatenate_5[0][0]              \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 54)   216         concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 54)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 6)    2916        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 32, 32, 6)    0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 32, 32, 60)   0           concatenate_6[0][0]              \n",
      "                                                                 dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 60)   240         concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 60)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 6)    3240        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 32, 32, 6)    0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 32, 32, 66)   0           concatenate_7[0][0]              \n",
      "                                                                 dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 66)   264         concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 66)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 6)    3564        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 32, 32, 6)    0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 32, 32, 72)   0           concatenate_8[0][0]              \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 32, 72)   288         concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 32, 32, 72)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 6)    3888        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 32, 32, 6)    0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 32, 32, 78)   0           concatenate_9[0][0]              \n",
      "                                                                 dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 78)   312         concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 32, 32, 78)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 6)    4212        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 32, 32, 6)    0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 32, 32, 84)   0           concatenate_10[0][0]             \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 32, 32, 84)   336         concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 32, 32, 84)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 6)    504         activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 32, 32, 6)    0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 16, 16, 6)    0           dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 6)    24          average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 6)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 6)    324         activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 16, 16, 6)    0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 16, 16, 12)   0           average_pooling2d[0][0]          \n",
      "                                                                 dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 12)   48          concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16, 16, 12)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 16, 6)    648         activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 16, 16, 6)    0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 16, 16, 18)   0           concatenate_12[0][0]             \n",
      "                                                                 dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 16, 18)   72          concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 16, 16, 18)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 6)    972         activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 16, 16, 6)    0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 16, 16, 24)   0           concatenate_13[0][0]             \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 24)   96          concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 24)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 6)    1296        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 16, 16, 6)    0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 16, 16, 30)   0           concatenate_14[0][0]             \n",
      "                                                                 dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 30)   120         concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 30)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 16, 6)    1620        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 16, 16, 6)    0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 16, 16, 36)   0           concatenate_15[0][0]             \n",
      "                                                                 dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 16, 16, 36)   144         concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16, 16, 36)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 16, 16, 6)    1944        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 16, 16, 6)    0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 16, 16, 42)   0           concatenate_16[0][0]             \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 16, 16, 42)   168         concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 16, 16, 42)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 16, 16, 6)    2268        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 16, 16, 6)    0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 16, 16, 48)   0           concatenate_17[0][0]             \n",
      "                                                                 dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 16, 16, 48)   192         concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 16, 16, 6)    2592        activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 16, 16, 6)    0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 16, 16, 54)   0           concatenate_18[0][0]             \n",
      "                                                                 dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 16, 16, 54)   216         concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 16, 16, 54)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 16, 16, 6)    2916        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 16, 16, 6)    0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 16, 16, 60)   0           concatenate_19[0][0]             \n",
      "                                                                 dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 16, 16, 60)   240         concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 16, 16, 60)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 16, 16, 6)    3240        activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 16, 16, 6)    0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 16, 16, 66)   0           concatenate_20[0][0]             \n",
      "                                                                 dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 16, 16, 66)   264         concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 16, 16, 66)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 16, 16, 6)    3564        activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 16, 16, 6)    0           conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 16, 16, 72)   0           concatenate_21[0][0]             \n",
      "                                                                 dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 16, 16, 72)   288         concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 16, 16, 72)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 16, 16, 6)    3888        activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 16, 16, 6)    0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 16, 16, 78)   0           concatenate_22[0][0]             \n",
      "                                                                 dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 16, 16, 78)   312         concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16, 16, 78)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 16, 16, 6)    468         activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 16, 16, 6)    0           conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 8, 8, 6)      0           dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 8, 8, 6)      24          average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 8, 8, 6)      0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 8, 8, 6)      324         activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 8, 8, 6)      0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 8, 8, 12)     0           average_pooling2d_1[0][0]        \n",
      "                                                                 dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 8, 8, 12)     48          concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 8, 8, 12)     0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 8, 8, 6)      648         activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 8, 8, 6)      0           conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 8, 8, 18)     0           concatenate_24[0][0]             \n",
      "                                                                 dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 8, 8, 18)     72          concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 8, 8, 18)     0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 8, 8, 6)      972         activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 8, 8, 6)      0           conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 8, 8, 24)     0           concatenate_25[0][0]             \n",
      "                                                                 dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 8, 8, 24)     96          concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 8, 8, 24)     0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 8, 8, 6)      1296        activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 8, 8, 6)      0           conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 8, 8, 30)     0           concatenate_26[0][0]             \n",
      "                                                                 dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 8, 8, 30)     120         concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 8, 8, 30)     0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 8, 8, 6)      1620        activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 8, 8, 6)      0           conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 8, 8, 36)     0           concatenate_27[0][0]             \n",
      "                                                                 dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 8, 8, 36)     144         concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 8, 8, 36)     0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 8, 8, 6)      1944        activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 8, 8, 6)      0           conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 8, 8, 42)     0           concatenate_28[0][0]             \n",
      "                                                                 dropout_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 8, 8, 42)     168         concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 8, 8, 42)     0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 8, 8, 6)      2268        activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 8, 8, 6)      0           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 8, 8, 48)     0           concatenate_29[0][0]             \n",
      "                                                                 dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 8, 8, 48)     192         concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 8, 8, 48)     0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 8, 8, 6)      2592        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 8, 8, 6)      0           conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 8, 8, 54)     0           concatenate_30[0][0]             \n",
      "                                                                 dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 8, 8, 54)     216         concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 8, 8, 54)     0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 8, 8, 6)      2916        activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 8, 8, 6)      0           conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 8, 8, 60)     0           concatenate_31[0][0]             \n",
      "                                                                 dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 8, 8, 60)     240         concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 8, 8, 60)     0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 8, 8, 6)      3240        activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 8, 8, 6)      0           conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 8, 8, 66)     0           concatenate_32[0][0]             \n",
      "                                                                 dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 8, 8, 66)     264         concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 8, 8, 66)     0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 8, 8, 6)      3564        activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 8, 8, 6)      0           conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)    (None, 8, 8, 72)     0           concatenate_33[0][0]             \n",
      "                                                                 dropout_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 8, 8, 72)     288         concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 8, 8, 72)     0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 8, 8, 6)      3888        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 8, 8, 6)      0           conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)    (None, 8, 8, 78)     0           concatenate_34[0][0]             \n",
      "                                                                 dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 8, 8, 78)     312         concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 8, 8, 78)     0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 8, 8, 6)      468         activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 8, 8, 6)      0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 4, 4, 6)      0           dropout_38[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 4, 4, 6)      24          average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 4, 4, 6)      0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 4, 4, 6)      324         activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 4, 4, 6)      0           conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)    (None, 4, 4, 12)     0           average_pooling2d_2[0][0]        \n",
      "                                                                 dropout_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 4, 4, 12)     48          concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 4, 4, 12)     0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 4, 4, 6)      648         activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 4, 4, 6)      0           conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_37 (Concatenate)    (None, 4, 4, 18)     0           concatenate_36[0][0]             \n",
      "                                                                 dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 4, 4, 18)     72          concatenate_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 4, 4, 18)     0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 4, 4, 6)      972         activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (None, 4, 4, 6)      0           conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_38 (Concatenate)    (None, 4, 4, 24)     0           concatenate_37[0][0]             \n",
      "                                                                 dropout_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 4, 4, 24)     96          concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 4, 4, 24)     0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 4, 4, 6)      1296        activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)            (None, 4, 4, 6)      0           conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_39 (Concatenate)    (None, 4, 4, 30)     0           concatenate_38[0][0]             \n",
      "                                                                 dropout_42[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 4, 4, 30)     120         concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 4, 4, 30)     0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 4, 4, 6)      1620        activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)            (None, 4, 4, 6)      0           conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_40 (Concatenate)    (None, 4, 4, 36)     0           concatenate_39[0][0]             \n",
      "                                                                 dropout_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 4, 4, 36)     144         concatenate_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 4, 4, 36)     0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 4, 4, 6)      1944        activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_44 (Dropout)            (None, 4, 4, 6)      0           conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_41 (Concatenate)    (None, 4, 4, 42)     0           concatenate_40[0][0]             \n",
      "                                                                 dropout_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 4, 4, 42)     168         concatenate_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 4, 4, 42)     0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 4, 4, 6)      2268        activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_45 (Dropout)            (None, 4, 4, 6)      0           conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_42 (Concatenate)    (None, 4, 4, 48)     0           concatenate_41[0][0]             \n",
      "                                                                 dropout_45[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 4, 4, 48)     192         concatenate_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 4, 4, 48)     0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 4, 4, 6)      2592        activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_46 (Dropout)            (None, 4, 4, 6)      0           conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_43 (Concatenate)    (None, 4, 4, 54)     0           concatenate_42[0][0]             \n",
      "                                                                 dropout_46[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 4, 4, 54)     216         concatenate_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 4, 4, 54)     0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 4, 4, 6)      2916        activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)            (None, 4, 4, 6)      0           conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_44 (Concatenate)    (None, 4, 4, 60)     0           concatenate_43[0][0]             \n",
      "                                                                 dropout_47[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 4, 4, 60)     240         concatenate_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 4, 4, 60)     0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 4, 4, 6)      3240        activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)            (None, 4, 4, 6)      0           conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_45 (Concatenate)    (None, 4, 4, 66)     0           concatenate_44[0][0]             \n",
      "                                                                 dropout_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 4, 4, 66)     264         concatenate_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 4, 4, 66)     0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 4, 4, 6)      3564        activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)            (None, 4, 4, 6)      0           conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_46 (Concatenate)    (None, 4, 4, 72)     0           concatenate_45[0][0]             \n",
      "                                                                 dropout_49[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 4, 4, 72)     288         concatenate_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 4, 4, 72)     0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 4, 4, 6)      3888        activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)            (None, 4, 4, 6)      0           conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_47 (Concatenate)    (None, 4, 4, 78)     0           concatenate_46[0][0]             \n",
      "                                                                 dropout_50[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 4, 4, 78)     312         concatenate_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 4, 4, 78)     0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 2, 2, 78)     0           activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 312)          0           average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           3130        flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 118,918\n",
      "Trainable params: 114,394\n",
      "Non-trainable params: 4,524\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Model(inputs=[input], outputs=[output])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j_zRqXYjREi3"
   },
   "source": [
    "## 8. Model Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6pwdBRfQMOt-"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w0G7k6luRnil"
   },
   "source": [
    "## 9. Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CjBQuM1mRksh"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "patience = 50\n",
    "base_path = '/home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/'\n",
    "checkpoint_file_name = base_path + 'CIFAR' + '_{epoch:02d}-{val_loss:.2f}.hdf5'\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(checkpoint_file_name, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "early_stop = EarlyStopping('val_loss', patience = patience)\n",
    "reduce_LR = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=int(patience/3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [model_checkpoint, early_stop, reduce_LR]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XPcBNrHkSYPt"
   },
   "source": [
    "## 10. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K8z8p-MNSe4s"
   },
   "outputs": [],
   "source": [
    "epochs = 300\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ej2U-uG_Sa5i"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 390 steps, validate on 10000 samples\n",
      "Epoch 1/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 1.3848 - accuracy: 0.4909\n",
      "Epoch 00001: val_loss improved from inf to 1.78309, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_01-1.78.hdf5\n",
      "390/390 [==============================] - 29s 73ms/step - loss: 1.3847 - accuracy: 0.4911 - val_loss: 1.7831 - val_accuracy: 0.4376\n",
      "Epoch 2/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 1.2734 - accuracy: 0.5363\n",
      "Epoch 00002: val_loss improved from 1.78309 to 1.33771, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_02-1.34.hdf5\n",
      "390/390 [==============================] - 28s 73ms/step - loss: 1.2729 - accuracy: 0.5363 - val_loss: 1.3377 - val_accuracy: 0.5480\n",
      "Epoch 3/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 1.1915 - accuracy: 0.5660\n",
      "Epoch 00003: val_loss improved from 1.33771 to 1.29796, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_03-1.30.hdf5\n",
      "390/390 [==============================] - 29s 73ms/step - loss: 1.1918 - accuracy: 0.5658 - val_loss: 1.2980 - val_accuracy: 0.5614\n",
      "Epoch 4/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 1.1337 - accuracy: 0.5858\n",
      "Epoch 00004: val_loss did not improve from 1.29796\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 1.1334 - accuracy: 0.5860 - val_loss: 1.3236 - val_accuracy: 0.5745\n",
      "Epoch 5/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 1.0955 - accuracy: 0.6046\n",
      "Epoch 00005: val_loss did not improve from 1.29796\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 1.0954 - accuracy: 0.6046 - val_loss: 1.9929 - val_accuracy: 0.4908\n",
      "Epoch 6/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 1.0594 - accuracy: 0.6175\n",
      "Epoch 00006: val_loss improved from 1.29796 to 1.18068, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_06-1.18.hdf5\n",
      "390/390 [==============================] - 29s 74ms/step - loss: 1.0590 - accuracy: 0.6177 - val_loss: 1.1807 - val_accuracy: 0.6074\n",
      "Epoch 7/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 1.0249 - accuracy: 0.6278\n",
      "Epoch 00007: val_loss did not improve from 1.18068\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 1.0251 - accuracy: 0.6277 - val_loss: 1.2659 - val_accuracy: 0.5894\n",
      "Epoch 8/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 1.0049 - accuracy: 0.6378\n",
      "Epoch 00008: val_loss did not improve from 1.18068\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 1.0050 - accuracy: 0.6379 - val_loss: 1.1914 - val_accuracy: 0.6099\n",
      "Epoch 9/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.9846 - accuracy: 0.6446\n",
      "Epoch 00009: val_loss did not improve from 1.18068\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.9845 - accuracy: 0.6447 - val_loss: 1.3551 - val_accuracy: 0.5842\n",
      "Epoch 10/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.9545 - accuracy: 0.6587\n",
      "Epoch 00010: val_loss improved from 1.18068 to 1.10336, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_10-1.10.hdf5\n",
      "390/390 [==============================] - 29s 73ms/step - loss: 0.9545 - accuracy: 0.6586 - val_loss: 1.1034 - val_accuracy: 0.6427\n",
      "Epoch 11/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.9394 - accuracy: 0.6630\n",
      "Epoch 00011: val_loss improved from 1.10336 to 0.94139, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_11-0.94.hdf5\n",
      "390/390 [==============================] - 29s 74ms/step - loss: 0.9396 - accuracy: 0.6629 - val_loss: 0.9414 - val_accuracy: 0.6786\n",
      "Epoch 12/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.9245 - accuracy: 0.6696\n",
      "Epoch 00012: val_loss did not improve from 0.94139\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.9247 - accuracy: 0.6695 - val_loss: 1.0617 - val_accuracy: 0.6490\n",
      "Epoch 13/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.9047 - accuracy: 0.6767\n",
      "Epoch 00013: val_loss did not improve from 0.94139\n",
      "390/390 [==============================] - 28s 73ms/step - loss: 0.9049 - accuracy: 0.6767 - val_loss: 1.1002 - val_accuracy: 0.6536\n",
      "Epoch 14/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.8909 - accuracy: 0.6834\n",
      "Epoch 00014: val_loss did not improve from 0.94139\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.8906 - accuracy: 0.6835 - val_loss: 1.0150 - val_accuracy: 0.6749\n",
      "Epoch 15/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.8734 - accuracy: 0.6898\n",
      "Epoch 00015: val_loss did not improve from 0.94139\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.8739 - accuracy: 0.6895 - val_loss: 1.1756 - val_accuracy: 0.6430\n",
      "Epoch 16/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.8600 - accuracy: 0.6926\n",
      "Epoch 00016: val_loss did not improve from 0.94139\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.8600 - accuracy: 0.6927 - val_loss: 1.0592 - val_accuracy: 0.6671\n",
      "Epoch 17/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.8465 - accuracy: 0.6996\n",
      "Epoch 00017: val_loss did not improve from 0.94139\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.8465 - accuracy: 0.6996 - val_loss: 1.2268 - val_accuracy: 0.6355\n",
      "Epoch 18/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.8321 - accuracy: 0.7059\n",
      "Epoch 00018: val_loss did not improve from 0.94139\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.8323 - accuracy: 0.7059 - val_loss: 1.2344 - val_accuracy: 0.6350\n",
      "Epoch 19/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.8191 - accuracy: 0.7082\n",
      "Epoch 00019: val_loss did not improve from 0.94139\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.8188 - accuracy: 0.7083 - val_loss: 1.2781 - val_accuracy: 0.6406\n",
      "Epoch 20/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.8106 - accuracy: 0.7138\n",
      "Epoch 00020: val_loss did not improve from 0.94139\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.8106 - accuracy: 0.7139 - val_loss: 1.2194 - val_accuracy: 0.6414\n",
      "Epoch 21/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.8049 - accuracy: 0.7149\n",
      "Epoch 00021: val_loss did not improve from 0.94139\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.8046 - accuracy: 0.7150 - val_loss: 1.2590 - val_accuracy: 0.6343\n",
      "Epoch 22/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.7908 - accuracy: 0.7202\n",
      "Epoch 00022: val_loss improved from 0.94139 to 0.87153, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_22-0.87.hdf5\n",
      "390/390 [==============================] - 29s 73ms/step - loss: 0.7912 - accuracy: 0.7201 - val_loss: 0.8715 - val_accuracy: 0.7155\n",
      "Epoch 23/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.7823 - accuracy: 0.7232\n",
      "Epoch 00023: val_loss did not improve from 0.87153\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.7823 - accuracy: 0.7232 - val_loss: 1.0189 - val_accuracy: 0.6918\n",
      "Epoch 24/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.7748 - accuracy: 0.7264\n",
      "Epoch 00024: val_loss improved from 0.87153 to 0.81352, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_24-0.81.hdf5\n",
      "390/390 [==============================] - 29s 74ms/step - loss: 0.7747 - accuracy: 0.7263 - val_loss: 0.8135 - val_accuracy: 0.7388\n",
      "Epoch 25/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.7626 - accuracy: 0.7287\n",
      "Epoch 00025: val_loss did not improve from 0.81352\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.7628 - accuracy: 0.7287 - val_loss: 0.8556 - val_accuracy: 0.7213\n",
      "Epoch 26/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.7562 - accuracy: 0.7340\n",
      "Epoch 00026: val_loss did not improve from 0.81352\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.7563 - accuracy: 0.7339 - val_loss: 0.8655 - val_accuracy: 0.7198\n",
      "Epoch 27/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.7543 - accuracy: 0.7345\n",
      "Epoch 00027: val_loss did not improve from 0.81352\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.7546 - accuracy: 0.7343 - val_loss: 0.8424 - val_accuracy: 0.7317\n",
      "Epoch 28/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.7436 - accuracy: 0.7358\n",
      "Epoch 00028: val_loss did not improve from 0.81352\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.7435 - accuracy: 0.7358 - val_loss: 0.8330 - val_accuracy: 0.7308\n",
      "Epoch 29/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.7377 - accuracy: 0.7401\n",
      "Epoch 00029: val_loss did not improve from 0.81352\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.7380 - accuracy: 0.7401 - val_loss: 0.8146 - val_accuracy: 0.7381\n",
      "Epoch 30/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.7251 - accuracy: 0.7444\n",
      "Epoch 00030: val_loss did not improve from 0.81352\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.7254 - accuracy: 0.7443 - val_loss: 0.8778 - val_accuracy: 0.7308\n",
      "Epoch 31/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.7246 - accuracy: 0.7457\n",
      "Epoch 00031: val_loss did not improve from 0.81352\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.7245 - accuracy: 0.7457 - val_loss: 0.9214 - val_accuracy: 0.7228\n",
      "Epoch 32/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.7206 - accuracy: 0.7465\n",
      "Epoch 00032: val_loss did not improve from 0.81352\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.7204 - accuracy: 0.7467 - val_loss: 0.9153 - val_accuracy: 0.7089\n",
      "Epoch 33/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.7189 - accuracy: 0.7475\n",
      "Epoch 00033: val_loss improved from 0.81352 to 0.77029, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_33-0.77.hdf5\n",
      "390/390 [==============================] - 29s 73ms/step - loss: 0.7190 - accuracy: 0.7473 - val_loss: 0.7703 - val_accuracy: 0.7468\n",
      "Epoch 34/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.7063 - accuracy: 0.7501\n",
      "Epoch 00034: val_loss did not improve from 0.77029\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.7063 - accuracy: 0.7502 - val_loss: 1.1673 - val_accuracy: 0.6510\n",
      "Epoch 35/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.7024 - accuracy: 0.7526\n",
      "Epoch 00035: val_loss did not improve from 0.77029\n",
      "390/390 [==============================] - 28s 73ms/step - loss: 0.7026 - accuracy: 0.7526 - val_loss: 0.8781 - val_accuracy: 0.7302\n",
      "Epoch 36/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.6992 - accuracy: 0.7558\n",
      "Epoch 00036: val_loss did not improve from 0.77029\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.6992 - accuracy: 0.7558 - val_loss: 0.8242 - val_accuracy: 0.7402\n",
      "Epoch 37/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.6883 - accuracy: 0.7576\n",
      "Epoch 00037: val_loss did not improve from 0.77029\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.6885 - accuracy: 0.7575 - val_loss: 1.0020 - val_accuracy: 0.7077\n",
      "Epoch 38/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.6875 - accuracy: 0.7587\n",
      "Epoch 00038: val_loss did not improve from 0.77029\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.6877 - accuracy: 0.7586 - val_loss: 0.8783 - val_accuracy: 0.7372\n",
      "Epoch 39/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.6794 - accuracy: 0.7622\n",
      "Epoch 00039: val_loss did not improve from 0.77029\n",
      "390/390 [==============================] - 28s 73ms/step - loss: 0.6794 - accuracy: 0.7623 - val_loss: 1.0037 - val_accuracy: 0.7105\n",
      "Epoch 40/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.6805 - accuracy: 0.7613\n",
      "Epoch 00040: val_loss did not improve from 0.77029\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.6804 - accuracy: 0.7613 - val_loss: 0.9206 - val_accuracy: 0.7253\n",
      "Epoch 41/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.6700 - accuracy: 0.7626\n",
      "Epoch 00041: val_loss did not improve from 0.77029\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.6699 - accuracy: 0.7627 - val_loss: 0.8955 - val_accuracy: 0.7375\n",
      "Epoch 42/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.6690 - accuracy: 0.7654\n",
      "Epoch 00042: val_loss did not improve from 0.77029\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.6693 - accuracy: 0.7653 - val_loss: 0.8193 - val_accuracy: 0.7536\n",
      "Epoch 43/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.6670 - accuracy: 0.7661\n",
      "Epoch 00043: val_loss did not improve from 0.77029\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.6675 - accuracy: 0.7660 - val_loss: 0.9809 - val_accuracy: 0.7126\n",
      "Epoch 44/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.6590 - accuracy: 0.7683\n",
      "Epoch 00044: val_loss improved from 0.77029 to 0.71524, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_44-0.72.hdf5\n",
      "390/390 [==============================] - 29s 74ms/step - loss: 0.6588 - accuracy: 0.7683 - val_loss: 0.7152 - val_accuracy: 0.7723\n",
      "Epoch 45/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.6596 - accuracy: 0.7676\n",
      "Epoch 00045: val_loss did not improve from 0.71524\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.6592 - accuracy: 0.7678 - val_loss: 0.8049 - val_accuracy: 0.7541\n",
      "Epoch 46/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.6559 - accuracy: 0.7695\n",
      "Epoch 00046: val_loss improved from 0.71524 to 0.67775, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_46-0.68.hdf5\n",
      "390/390 [==============================] - 28s 73ms/step - loss: 0.6561 - accuracy: 0.7695 - val_loss: 0.6777 - val_accuracy: 0.7879\n",
      "Epoch 47/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.6484 - accuracy: 0.7718\n",
      "Epoch 00047: val_loss did not improve from 0.67775\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.6484 - accuracy: 0.7720 - val_loss: 0.8008 - val_accuracy: 0.7513\n",
      "Epoch 48/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.6476 - accuracy: 0.7728\n",
      "Epoch 00048: val_loss did not improve from 0.67775\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.6475 - accuracy: 0.7729 - val_loss: 0.7841 - val_accuracy: 0.7539\n",
      "Epoch 49/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.6424 - accuracy: 0.7738\n",
      "Epoch 00049: val_loss did not improve from 0.67775\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.6425 - accuracy: 0.7738 - val_loss: 0.9057 - val_accuracy: 0.7353\n",
      "Epoch 50/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.6407 - accuracy: 0.7738\n",
      "Epoch 00050: val_loss did not improve from 0.67775\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.6406 - accuracy: 0.7739 - val_loss: 0.8436 - val_accuracy: 0.7444\n",
      "Epoch 51/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.6338 - accuracy: 0.7779\n",
      "Epoch 00051: val_loss did not improve from 0.67775\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.6336 - accuracy: 0.7779 - val_loss: 0.9483 - val_accuracy: 0.7206\n",
      "Epoch 52/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.6318 - accuracy: 0.7778\n",
      "Epoch 00052: val_loss did not improve from 0.67775\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.6318 - accuracy: 0.7779 - val_loss: 1.0205 - val_accuracy: 0.7098\n",
      "Epoch 53/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.6314 - accuracy: 0.7780\n",
      "Epoch 00053: val_loss did not improve from 0.67775\n",
      "390/390 [==============================] - 28s 71ms/step - loss: 0.6314 - accuracy: 0.7781 - val_loss: 0.7074 - val_accuracy: 0.7772\n",
      "Epoch 54/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.6308 - accuracy: 0.7782\n",
      "Epoch 00054: val_loss did not improve from 0.67775\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.6308 - accuracy: 0.7783 - val_loss: 0.8820 - val_accuracy: 0.7428\n",
      "Epoch 55/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.6277 - accuracy: 0.7795\n",
      "Epoch 00055: val_loss did not improve from 0.67775\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.6281 - accuracy: 0.7794 - val_loss: 0.9102 - val_accuracy: 0.7383\n",
      "Epoch 56/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.6222 - accuracy: 0.7822\n",
      "Epoch 00057: val_loss did not improve from 0.67775\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.6223 - accuracy: 0.7821 - val_loss: 0.8572 - val_accuracy: 0.7502\n",
      "Epoch 58/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.6216 - accuracy: 0.7836\n",
      "Epoch 00058: val_loss did not improve from 0.67775\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.6216 - accuracy: 0.7836 - val_loss: 0.7145 - val_accuracy: 0.7728\n",
      "Epoch 59/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.6186 - accuracy: 0.7839\n",
      "Epoch 00059: val_loss did not improve from 0.67775\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.6186 - accuracy: 0.7838 - val_loss: 0.6832 - val_accuracy: 0.7870\n",
      "Epoch 60/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.6119 - accuracy: 0.7862\n",
      "Epoch 00060: val_loss did not improve from 0.67775\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.6118 - accuracy: 0.7861 - val_loss: 0.8445 - val_accuracy: 0.7423\n",
      "Epoch 61/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.6129 - accuracy: 0.7835\n",
      "Epoch 00061: val_loss did not improve from 0.67775\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.6130 - accuracy: 0.7834 - val_loss: 0.7096 - val_accuracy: 0.7794\n",
      "Epoch 62/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.6093 - accuracy: 0.7868\n",
      "Epoch 00062: val_loss did not improve from 0.67775\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.6091 - accuracy: 0.7869 - val_loss: 0.6784 - val_accuracy: 0.7823\n",
      "Epoch 63/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5725 - accuracy: 0.7984\n",
      "Epoch 00063: val_loss improved from 0.67775 to 0.64425, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_63-0.64.hdf5\n",
      "390/390 [==============================] - 28s 73ms/step - loss: 0.5722 - accuracy: 0.7986 - val_loss: 0.6443 - val_accuracy: 0.8006\n",
      "Epoch 64/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5617 - accuracy: 0.8050\n",
      "Epoch 00064: val_loss improved from 0.64425 to 0.63837, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_64-0.64.hdf5\n",
      "390/390 [==============================] - 29s 75ms/step - loss: 0.5612 - accuracy: 0.8052 - val_loss: 0.6384 - val_accuracy: 0.8023\n",
      "Epoch 65/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5654 - accuracy: 0.8026\n",
      "Epoch 00065: val_loss improved from 0.63837 to 0.63668, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_65-0.64.hdf5\n",
      "390/390 [==============================] - 29s 74ms/step - loss: 0.5651 - accuracy: 0.8026 - val_loss: 0.6367 - val_accuracy: 0.8006\n",
      "Epoch 66/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5588 - accuracy: 0.8060\n",
      "Epoch 00066: val_loss improved from 0.63668 to 0.61334, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_66-0.61.hdf5\n",
      "390/390 [==============================] - 29s 74ms/step - loss: 0.5592 - accuracy: 0.8059 - val_loss: 0.6133 - val_accuracy: 0.8083\n",
      "Epoch 67/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5551 - accuracy: 0.8055\n",
      "Epoch 00067: val_loss did not improve from 0.61334\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5551 - accuracy: 0.8056 - val_loss: 0.6187 - val_accuracy: 0.8103\n",
      "Epoch 68/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5554 - accuracy: 0.8054\n",
      "Epoch 00068: val_loss did not improve from 0.61334\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5552 - accuracy: 0.8055 - val_loss: 0.6215 - val_accuracy: 0.8081\n",
      "Epoch 69/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5520 - accuracy: 0.8078\n",
      "Epoch 00069: val_loss did not improve from 0.61334\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5519 - accuracy: 0.8079 - val_loss: 0.6524 - val_accuracy: 0.8005\n",
      "Epoch 70/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5526 - accuracy: 0.8078\n",
      "Epoch 00070: val_loss did not improve from 0.61334\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5526 - accuracy: 0.8079 - val_loss: 0.6199 - val_accuracy: 0.8097\n",
      "Epoch 71/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5509 - accuracy: 0.8086\n",
      "Epoch 00071: val_loss did not improve from 0.61334\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5509 - accuracy: 0.8086 - val_loss: 0.6481 - val_accuracy: 0.8015\n",
      "Epoch 72/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5506 - accuracy: 0.8066\n",
      "Epoch 00072: val_loss did not improve from 0.61334\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5508 - accuracy: 0.8065 - val_loss: 0.6337 - val_accuracy: 0.8084\n",
      "Epoch 73/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5497 - accuracy: 0.8080\n",
      "Epoch 00073: val_loss did not improve from 0.61334\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5500 - accuracy: 0.8079 - val_loss: 0.6421 - val_accuracy: 0.8075\n",
      "Epoch 74/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5547 - accuracy: 0.8057\n",
      "Epoch 00074: val_loss did not improve from 0.61334\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5547 - accuracy: 0.8057 - val_loss: 0.6373 - val_accuracy: 0.8060\n",
      "Epoch 75/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5483 - accuracy: 0.8092\n",
      "Epoch 00075: val_loss did not improve from 0.61334\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5483 - accuracy: 0.8092 - val_loss: 0.6167 - val_accuracy: 0.8111\n",
      "Epoch 76/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5500 - accuracy: 0.8074\n",
      "Epoch 00076: val_loss did not improve from 0.61334\n",
      "390/390 [==============================] - 28s 73ms/step - loss: 0.5498 - accuracy: 0.8074 - val_loss: 0.6347 - val_accuracy: 0.8072\n",
      "Epoch 77/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5490 - accuracy: 0.8063\n",
      "Epoch 00077: val_loss did not improve from 0.61334\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5492 - accuracy: 0.8062 - val_loss: 0.6422 - val_accuracy: 0.8064\n",
      "Epoch 78/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5466 - accuracy: 0.8081\n",
      "Epoch 00078: val_loss did not improve from 0.61334\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5468 - accuracy: 0.8080 - val_loss: 0.6581 - val_accuracy: 0.8033\n",
      "Epoch 79/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5482 - accuracy: 0.8071\n",
      "Epoch 00079: val_loss did not improve from 0.61334\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5482 - accuracy: 0.8072 - val_loss: 0.6333 - val_accuracy: 0.8066\n",
      "Epoch 80/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5440 - accuracy: 0.8101\n",
      "Epoch 00080: val_loss did not improve from 0.61334\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5442 - accuracy: 0.8100 - val_loss: 0.6199 - val_accuracy: 0.8100\n",
      "Epoch 81/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5473 - accuracy: 0.8087\n",
      "Epoch 00081: val_loss did not improve from 0.61334\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5475 - accuracy: 0.8087 - val_loss: 0.6548 - val_accuracy: 0.8027\n",
      "Epoch 82/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5432 - accuracy: 0.8098\n",
      "Epoch 00082: val_loss did not improve from 0.61334\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5432 - accuracy: 0.8097 - val_loss: 0.6311 - val_accuracy: 0.8073\n",
      "Epoch 83/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5412 - accuracy: 0.8100\n",
      "Epoch 00083: val_loss did not improve from 0.61334\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5410 - accuracy: 0.8101 - val_loss: 0.6273 - val_accuracy: 0.8099\n",
      "Epoch 84/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5421 - accuracy: 0.8094\n",
      "Epoch 00084: val_loss did not improve from 0.61334\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5423 - accuracy: 0.8093 - val_loss: 0.6330 - val_accuracy: 0.8076\n",
      "Epoch 85/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5415 - accuracy: 0.8098\n",
      "Epoch 00085: val_loss did not improve from 0.61334\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5416 - accuracy: 0.8098 - val_loss: 0.6334 - val_accuracy: 0.8071\n",
      "Epoch 86/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5345 - accuracy: 0.8111\n",
      "Epoch 00086: val_loss did not improve from 0.61334\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5345 - accuracy: 0.8112 - val_loss: 0.6329 - val_accuracy: 0.8076\n",
      "Epoch 87/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5400 - accuracy: 0.8103\n",
      "Epoch 00087: val_loss did not improve from 0.61334\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5405 - accuracy: 0.8102 - val_loss: 0.6290 - val_accuracy: 0.8083\n",
      "Epoch 88/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5397 - accuracy: 0.8104\n",
      "Epoch 00088: val_loss did not improve from 0.61334\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5397 - accuracy: 0.8104 - val_loss: 0.6333 - val_accuracy: 0.8077\n",
      "Epoch 89/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5407 - accuracy: 0.8104\n",
      "Epoch 00089: val_loss did not improve from 0.61334\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5406 - accuracy: 0.8104 - val_loss: 0.6309 - val_accuracy: 0.8078\n",
      "Epoch 90/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5407 - accuracy: 0.8108\n",
      "Epoch 00090: val_loss did not improve from 0.61334\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5406 - accuracy: 0.8108 - val_loss: 0.6319 - val_accuracy: 0.8083\n",
      "Epoch 91/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5386 - accuracy: 0.8113\n",
      "Epoch 00091: val_loss did not improve from 0.61334\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5386 - accuracy: 0.8112 - val_loss: 0.6342 - val_accuracy: 0.8079\n",
      "Epoch 92/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5425 - accuracy: 0.8111\n",
      "Epoch 00092: val_loss did not improve from 0.61334\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5429 - accuracy: 0.8110 - val_loss: 0.6361 - val_accuracy: 0.8075\n",
      "Epoch 93/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5433 - accuracy: 0.8110\n",
      "Epoch 00093: val_loss did not improve from 0.61334\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5434 - accuracy: 0.8111 - val_loss: 0.6344 - val_accuracy: 0.8078\n",
      "Epoch 94/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5339 - accuracy: 0.8139\n",
      "Epoch 00094: val_loss did not improve from 0.61334\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5340 - accuracy: 0.8138 - val_loss: 0.6330 - val_accuracy: 0.8086\n",
      "Epoch 95/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5400 - accuracy: 0.8112\n",
      "Epoch 00095: val_loss did not improve from 0.61334\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5401 - accuracy: 0.8111 - val_loss: 0.6314 - val_accuracy: 0.8095\n",
      "Epoch 96/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5386 - accuracy: 0.8127\n",
      "Epoch 00096: val_loss did not improve from 0.61334\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5385 - accuracy: 0.8127 - val_loss: 0.6285 - val_accuracy: 0.8104\n",
      "Epoch 97/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5371 - accuracy: 0.8094\n",
      "Epoch 00097: val_loss did not improve from 0.61334\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5365 - accuracy: 0.8097 - val_loss: 0.6297 - val_accuracy: 0.8098\n",
      "Epoch 98/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5337 - accuracy: 0.8133\n",
      "Epoch 00098: val_loss did not improve from 0.61334\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5332 - accuracy: 0.8136 - val_loss: 0.6319 - val_accuracy: 0.8098\n",
      "Epoch 99/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5353 - accuracy: 0.8129\n",
      "Epoch 00099: val_loss did not improve from 0.61334\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5355 - accuracy: 0.8129 - val_loss: 0.6303 - val_accuracy: 0.8106\n",
      "Epoch 100/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5371 - accuracy: 0.8118\n",
      "Epoch 00100: val_loss did not improve from 0.61334\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5376 - accuracy: 0.8117 - val_loss: 0.6304 - val_accuracy: 0.8101\n",
      "Epoch 101/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5376 - accuracy: 0.8116\n",
      "Epoch 00101: val_loss did not improve from 0.61334\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5375 - accuracy: 0.8117 - val_loss: 0.6314 - val_accuracy: 0.8097\n",
      "Epoch 102/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5374 - accuracy: 0.8120\n",
      "Epoch 00102: val_loss did not improve from 0.61334\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5374 - accuracy: 0.8120 - val_loss: 0.6313 - val_accuracy: 0.8096\n",
      "Epoch 103/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5401 - accuracy: 0.8105\n",
      "Epoch 00103: val_loss did not improve from 0.61334\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5402 - accuracy: 0.8104 - val_loss: 0.6311 - val_accuracy: 0.8095\n",
      "Epoch 104/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5383 - accuracy: 0.8105\n",
      "Epoch 00104: val_loss did not improve from 0.61334\n",
      "390/390 [==============================] - 28s 71ms/step - loss: 0.5385 - accuracy: 0.8105 - val_loss: 0.6305 - val_accuracy: 0.8094\n",
      "Epoch 105/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5389 - accuracy: 0.8092\n",
      "Epoch 00105: val_loss did not improve from 0.61334\n",
      "390/390 [==============================] - 28s 71ms/step - loss: 0.5388 - accuracy: 0.8093 - val_loss: 0.6312 - val_accuracy: 0.8102\n",
      "Epoch 106/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5379 - accuracy: 0.8111\n",
      "Epoch 00106: val_loss did not improve from 0.61334\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5380 - accuracy: 0.8111 - val_loss: 0.6300 - val_accuracy: 0.8101\n",
      "Epoch 107/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5384 - accuracy: 0.8112\n",
      "Epoch 00107: val_loss did not improve from 0.61334\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5383 - accuracy: 0.8113 - val_loss: 0.6302 - val_accuracy: 0.8101\n",
      "Epoch 108/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5387 - accuracy: 0.8119\n",
      "Epoch 00108: val_loss did not improve from 0.61334\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5387 - accuracy: 0.8119 - val_loss: 0.6306 - val_accuracy: 0.8096\n",
      "Epoch 109/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5403 - accuracy: 0.8100\n",
      "Epoch 00109: val_loss did not improve from 0.61334\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5400 - accuracy: 0.8101 - val_loss: 0.6319 - val_accuracy: 0.8096\n",
      "Epoch 110/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5367 - accuracy: 0.8115\n",
      "Epoch 00110: val_loss did not improve from 0.61334\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5369 - accuracy: 0.8115 - val_loss: 0.6307 - val_accuracy: 0.8096\n",
      "Epoch 111/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5384 - accuracy: 0.8111\n",
      "Epoch 00111: val_loss did not improve from 0.61334\n",
      "390/390 [==============================] - 28s 71ms/step - loss: 0.5382 - accuracy: 0.8111 - val_loss: 0.6308 - val_accuracy: 0.8099\n",
      "Epoch 112/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5396 - accuracy: 0.8110\n",
      "Epoch 00112: val_loss did not improve from 0.61334\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5395 - accuracy: 0.8109 - val_loss: 0.6310 - val_accuracy: 0.8094\n",
      "Epoch 113/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5375 - accuracy: 0.8116\n",
      "Epoch 00113: val_loss did not improve from 0.61334\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5376 - accuracy: 0.8116 - val_loss: 0.6309 - val_accuracy: 0.8096\n",
      "Epoch 114/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5408 - accuracy: 0.8107\n",
      "Epoch 00114: val_loss did not improve from 0.61334\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5413 - accuracy: 0.8105 - val_loss: 0.6318 - val_accuracy: 0.8089\n",
      "Epoch 115/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5329 - accuracy: 0.8126\n",
      "Epoch 00115: val_loss did not improve from 0.61334\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5333 - accuracy: 0.8126 - val_loss: 0.6309 - val_accuracy: 0.8096\n",
      "Epoch 116/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5349 - accuracy: 0.8118\n",
      "Epoch 00116: val_loss did not improve from 0.61334\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5351 - accuracy: 0.8117 - val_loss: 0.6307 - val_accuracy: 0.8094\n"
     ]
    }
   ],
   "source": [
    "#https://keras.io/api/preprocessing/image/#flow-method\n",
    "\n",
    "history = model.fit(data_generator.flow(X_train, y_train, batch_size),\n",
    "                    steps_per_epoch = int(len(X_train)/batch_size),\n",
    "                    epochs = epochs,\n",
    "                    callbacks = callbacks,\n",
    "                    validation_data = (X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#history plot for accyracy\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title(\"Model Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend([\"train\", \"test\"], loc=\"upper left\")\n",
    "plt.show()\n",
    "\n",
    "# history plot for accuracy\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.title(\"Model Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend([\"train\", \"test\"], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'accuracy']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 348us/sample - loss: 0.6133 - accuracy: 0.8083\n",
      "[0.6133434212684631, 0.8083]\n"
     ]
    }
   ],
   "source": [
    "best_model_1 = tf.keras.models.load_model('/home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_66-0.61.hdf5')\n",
    "scores = best_model_1.evaluate(X_test, y_test, verbose=1)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary:\n",
    "- The model early stopped because the val loss is not reducing for 50 epochs. The best model is at epoch 66 and it gives the test accuracy of 0.8083. We can improve the accuracy further"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. By trying different learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 32, 12)   324         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32, 32, 12)   48          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 32, 32, 12)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 6)    648         activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 32, 32, 6)    0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 32, 32, 18)   0           conv2d[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 18)   72          concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 18)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 6)    972         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32, 32, 6)    0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 24)   0           concatenate[0][0]                \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 24)   96          concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 24)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 6)    1296        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32, 32, 6)    0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 30)   0           concatenate_1[0][0]              \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 30)   120         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 30)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 6)    1620        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32, 32, 6)    0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 32, 32, 36)   0           concatenate_2[0][0]              \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 36)   144         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 36)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 6)    1944        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32, 32, 6)    0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 32, 32, 42)   0           concatenate_3[0][0]              \n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 42)   168         concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 42)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 6)    2268        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 32, 32, 6)    0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 32, 32, 48)   0           concatenate_4[0][0]              \n",
      "                                                                 dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 48)   192         concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 6)    2592        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 32, 32, 6)    0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 32, 32, 54)   0           concatenate_5[0][0]              \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 54)   216         concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 54)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 6)    2916        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 32, 32, 6)    0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 32, 32, 60)   0           concatenate_6[0][0]              \n",
      "                                                                 dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 60)   240         concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 60)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 6)    3240        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 32, 32, 6)    0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 32, 32, 66)   0           concatenate_7[0][0]              \n",
      "                                                                 dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 66)   264         concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 66)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 6)    3564        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 32, 32, 6)    0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 32, 32, 72)   0           concatenate_8[0][0]              \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 32, 72)   288         concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 32, 32, 72)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 6)    3888        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 32, 32, 6)    0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 32, 32, 78)   0           concatenate_9[0][0]              \n",
      "                                                                 dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 78)   312         concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 32, 32, 78)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 6)    4212        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 32, 32, 6)    0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 32, 32, 84)   0           concatenate_10[0][0]             \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 32, 32, 84)   336         concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 32, 32, 84)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 6)    504         activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 32, 32, 6)    0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 16, 16, 6)    0           dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 6)    24          average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 6)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 6)    324         activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 16, 16, 6)    0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 16, 16, 12)   0           average_pooling2d[0][0]          \n",
      "                                                                 dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 12)   48          concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16, 16, 12)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 16, 6)    648         activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 16, 16, 6)    0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 16, 16, 18)   0           concatenate_12[0][0]             \n",
      "                                                                 dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 16, 18)   72          concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 16, 16, 18)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 6)    972         activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 16, 16, 6)    0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 16, 16, 24)   0           concatenate_13[0][0]             \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 24)   96          concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 24)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 6)    1296        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 16, 16, 6)    0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 16, 16, 30)   0           concatenate_14[0][0]             \n",
      "                                                                 dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 30)   120         concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 30)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 16, 6)    1620        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 16, 16, 6)    0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 16, 16, 36)   0           concatenate_15[0][0]             \n",
      "                                                                 dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 16, 16, 36)   144         concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16, 16, 36)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 16, 16, 6)    1944        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 16, 16, 6)    0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 16, 16, 42)   0           concatenate_16[0][0]             \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 16, 16, 42)   168         concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 16, 16, 42)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 16, 16, 6)    2268        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 16, 16, 6)    0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 16, 16, 48)   0           concatenate_17[0][0]             \n",
      "                                                                 dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 16, 16, 48)   192         concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 16, 16, 6)    2592        activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 16, 16, 6)    0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 16, 16, 54)   0           concatenate_18[0][0]             \n",
      "                                                                 dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 16, 16, 54)   216         concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 16, 16, 54)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 16, 16, 6)    2916        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 16, 16, 6)    0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 16, 16, 60)   0           concatenate_19[0][0]             \n",
      "                                                                 dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 16, 16, 60)   240         concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 16, 16, 60)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 16, 16, 6)    3240        activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 16, 16, 6)    0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 16, 16, 66)   0           concatenate_20[0][0]             \n",
      "                                                                 dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 16, 16, 66)   264         concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 16, 16, 66)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 16, 16, 6)    3564        activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 16, 16, 6)    0           conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 16, 16, 72)   0           concatenate_21[0][0]             \n",
      "                                                                 dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 16, 16, 72)   288         concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 16, 16, 72)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 16, 16, 6)    3888        activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 16, 16, 6)    0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 16, 16, 78)   0           concatenate_22[0][0]             \n",
      "                                                                 dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 16, 16, 78)   312         concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16, 16, 78)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 16, 16, 6)    468         activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 16, 16, 6)    0           conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 8, 8, 6)      0           dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 8, 8, 6)      24          average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 8, 8, 6)      0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 8, 8, 6)      324         activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 8, 8, 6)      0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 8, 8, 12)     0           average_pooling2d_1[0][0]        \n",
      "                                                                 dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 8, 8, 12)     48          concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 8, 8, 12)     0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 8, 8, 6)      648         activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 8, 8, 6)      0           conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 8, 8, 18)     0           concatenate_24[0][0]             \n",
      "                                                                 dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 8, 8, 18)     72          concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 8, 8, 18)     0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 8, 8, 6)      972         activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 8, 8, 6)      0           conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 8, 8, 24)     0           concatenate_25[0][0]             \n",
      "                                                                 dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 8, 8, 24)     96          concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 8, 8, 24)     0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 8, 8, 6)      1296        activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 8, 8, 6)      0           conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 8, 8, 30)     0           concatenate_26[0][0]             \n",
      "                                                                 dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 8, 8, 30)     120         concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 8, 8, 30)     0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 8, 8, 6)      1620        activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 8, 8, 6)      0           conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 8, 8, 36)     0           concatenate_27[0][0]             \n",
      "                                                                 dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 8, 8, 36)     144         concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 8, 8, 36)     0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 8, 8, 6)      1944        activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 8, 8, 6)      0           conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 8, 8, 42)     0           concatenate_28[0][0]             \n",
      "                                                                 dropout_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 8, 8, 42)     168         concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 8, 8, 42)     0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 8, 8, 6)      2268        activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 8, 8, 6)      0           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 8, 8, 48)     0           concatenate_29[0][0]             \n",
      "                                                                 dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 8, 8, 48)     192         concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 8, 8, 48)     0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 8, 8, 6)      2592        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 8, 8, 6)      0           conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 8, 8, 54)     0           concatenate_30[0][0]             \n",
      "                                                                 dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 8, 8, 54)     216         concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 8, 8, 54)     0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 8, 8, 6)      2916        activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 8, 8, 6)      0           conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 8, 8, 60)     0           concatenate_31[0][0]             \n",
      "                                                                 dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 8, 8, 60)     240         concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 8, 8, 60)     0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 8, 8, 6)      3240        activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 8, 8, 6)      0           conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 8, 8, 66)     0           concatenate_32[0][0]             \n",
      "                                                                 dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 8, 8, 66)     264         concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 8, 8, 66)     0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 8, 8, 6)      3564        activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 8, 8, 6)      0           conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)    (None, 8, 8, 72)     0           concatenate_33[0][0]             \n",
      "                                                                 dropout_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 8, 8, 72)     288         concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 8, 8, 72)     0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 8, 8, 6)      3888        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 8, 8, 6)      0           conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)    (None, 8, 8, 78)     0           concatenate_34[0][0]             \n",
      "                                                                 dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 8, 8, 78)     312         concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 8, 8, 78)     0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 8, 8, 6)      468         activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 8, 8, 6)      0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 4, 4, 6)      0           dropout_38[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 4, 4, 6)      24          average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 4, 4, 6)      0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 4, 4, 6)      324         activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 4, 4, 6)      0           conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)    (None, 4, 4, 12)     0           average_pooling2d_2[0][0]        \n",
      "                                                                 dropout_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 4, 4, 12)     48          concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 4, 4, 12)     0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 4, 4, 6)      648         activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 4, 4, 6)      0           conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_37 (Concatenate)    (None, 4, 4, 18)     0           concatenate_36[0][0]             \n",
      "                                                                 dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 4, 4, 18)     72          concatenate_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 4, 4, 18)     0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 4, 4, 6)      972         activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (None, 4, 4, 6)      0           conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_38 (Concatenate)    (None, 4, 4, 24)     0           concatenate_37[0][0]             \n",
      "                                                                 dropout_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 4, 4, 24)     96          concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 4, 4, 24)     0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 4, 4, 6)      1296        activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)            (None, 4, 4, 6)      0           conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_39 (Concatenate)    (None, 4, 4, 30)     0           concatenate_38[0][0]             \n",
      "                                                                 dropout_42[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 4, 4, 30)     120         concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 4, 4, 30)     0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 4, 4, 6)      1620        activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)            (None, 4, 4, 6)      0           conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_40 (Concatenate)    (None, 4, 4, 36)     0           concatenate_39[0][0]             \n",
      "                                                                 dropout_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 4, 4, 36)     144         concatenate_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 4, 4, 36)     0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 4, 4, 6)      1944        activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_44 (Dropout)            (None, 4, 4, 6)      0           conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_41 (Concatenate)    (None, 4, 4, 42)     0           concatenate_40[0][0]             \n",
      "                                                                 dropout_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 4, 4, 42)     168         concatenate_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 4, 4, 42)     0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 4, 4, 6)      2268        activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_45 (Dropout)            (None, 4, 4, 6)      0           conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_42 (Concatenate)    (None, 4, 4, 48)     0           concatenate_41[0][0]             \n",
      "                                                                 dropout_45[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 4, 4, 48)     192         concatenate_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 4, 4, 48)     0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 4, 4, 6)      2592        activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_46 (Dropout)            (None, 4, 4, 6)      0           conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_43 (Concatenate)    (None, 4, 4, 54)     0           concatenate_42[0][0]             \n",
      "                                                                 dropout_46[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 4, 4, 54)     216         concatenate_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 4, 4, 54)     0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 4, 4, 6)      2916        activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)            (None, 4, 4, 6)      0           conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_44 (Concatenate)    (None, 4, 4, 60)     0           concatenate_43[0][0]             \n",
      "                                                                 dropout_47[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 4, 4, 60)     240         concatenate_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 4, 4, 60)     0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 4, 4, 6)      3240        activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)            (None, 4, 4, 6)      0           conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_45 (Concatenate)    (None, 4, 4, 66)     0           concatenate_44[0][0]             \n",
      "                                                                 dropout_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 4, 4, 66)     264         concatenate_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 4, 4, 66)     0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 4, 4, 6)      3564        activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)            (None, 4, 4, 6)      0           conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_46 (Concatenate)    (None, 4, 4, 72)     0           concatenate_45[0][0]             \n",
      "                                                                 dropout_49[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 4, 4, 72)     288         concatenate_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 4, 4, 72)     0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 4, 4, 6)      3888        activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)            (None, 4, 4, 6)      0           conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_47 (Concatenate)    (None, 4, 4, 78)     0           concatenate_46[0][0]             \n",
      "                                                                 dropout_50[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 4, 4, 78)     312         concatenate_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 4, 4, 78)     0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 2, 2, 78)     0           activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 312)          0           average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           3130        flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 118,918\n",
      "Trainable params: 114,394\n",
      "Non-trainable params: 4,524\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2 = tf.keras.models.load_model('/home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_66-0.61.hdf5')\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "patience = 50\n",
    "base_path = '/home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/'\n",
    "checkpoint_file_name = base_path + 'CIFAR_model2' + '_{epoch:02d}-{val_accuracy:.2f}.hdf5'\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(checkpoint_file_name, monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "early_stop = EarlyStopping('val_accuracy', mode='max', patience = patience)\n",
    "reduce_LR = ReduceLROnPlateau(monitor='val_accuracy', mode='max', factor=0.1, patience=int(patience/3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [model_checkpoint, early_stop, reduce_LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 300\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 390 steps, validate on 10000 samples\n",
      "Epoch 1/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5581 - accuracy: 0.8033\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.80040, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model2_01-0.80.hdf5\n",
      "390/390 [==============================] - 37s 95ms/step - loss: 0.5583 - accuracy: 0.8032 - val_loss: 0.6419 - val_accuracy: 0.8004\n",
      "Epoch 2/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5614 - accuracy: 0.8053\n",
      "Epoch 00002: val_accuracy improved from 0.80040 to 0.80220, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model2_02-0.80.hdf5\n",
      "390/390 [==============================] - 29s 74ms/step - loss: 0.5614 - accuracy: 0.8053 - val_loss: 0.6375 - val_accuracy: 0.8022\n",
      "Epoch 3/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5594 - accuracy: 0.8042\n",
      "Epoch 00003: val_accuracy did not improve from 0.80220\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5594 - accuracy: 0.8043 - val_loss: 0.6571 - val_accuracy: 0.7997\n",
      "Epoch 4/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5554 - accuracy: 0.8039\n",
      "Epoch 00004: val_accuracy improved from 0.80220 to 0.81070, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model2_04-0.81.hdf5\n",
      "390/390 [==============================] - 29s 74ms/step - loss: 0.5556 - accuracy: 0.8038 - val_loss: 0.6188 - val_accuracy: 0.8107\n",
      "Epoch 5/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5544 - accuracy: 0.8040\n",
      "Epoch 00005: val_accuracy did not improve from 0.81070\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5543 - accuracy: 0.8040 - val_loss: 0.6297 - val_accuracy: 0.8076\n",
      "Epoch 6/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5526 - accuracy: 0.8050\n",
      "Epoch 00006: val_accuracy did not improve from 0.81070\n",
      "390/390 [==============================] - 28s 73ms/step - loss: 0.5526 - accuracy: 0.8050 - val_loss: 0.6591 - val_accuracy: 0.8010\n",
      "Epoch 7/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5490 - accuracy: 0.8075\n",
      "Epoch 00007: val_accuracy did not improve from 0.81070\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5492 - accuracy: 0.8074 - val_loss: 0.6238 - val_accuracy: 0.8076\n",
      "Epoch 8/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5464 - accuracy: 0.8093\n",
      "Epoch 00008: val_accuracy did not improve from 0.81070\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5467 - accuracy: 0.8092 - val_loss: 0.6312 - val_accuracy: 0.8067\n",
      "Epoch 9/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5498 - accuracy: 0.8046\n",
      "Epoch 00009: val_accuracy did not improve from 0.81070\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5501 - accuracy: 0.8045 - val_loss: 0.6622 - val_accuracy: 0.8012\n",
      "Epoch 10/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5455 - accuracy: 0.8087\n",
      "Epoch 00010: val_accuracy did not improve from 0.81070\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5454 - accuracy: 0.8088 - val_loss: 0.6520 - val_accuracy: 0.8009\n",
      "Epoch 11/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5481 - accuracy: 0.8091\n",
      "Epoch 00011: val_accuracy did not improve from 0.81070\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5481 - accuracy: 0.8091 - val_loss: 0.6431 - val_accuracy: 0.8018\n",
      "Epoch 12/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5409 - accuracy: 0.8104\n",
      "Epoch 00012: val_accuracy did not improve from 0.81070\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5409 - accuracy: 0.8104 - val_loss: 0.6439 - val_accuracy: 0.8050\n",
      "Epoch 13/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5465 - accuracy: 0.8081\n",
      "Epoch 00013: val_accuracy did not improve from 0.81070\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5463 - accuracy: 0.8081 - val_loss: 0.6619 - val_accuracy: 0.8008\n",
      "Epoch 14/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5451 - accuracy: 0.8081\n",
      "Epoch 00014: val_accuracy did not improve from 0.81070\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5452 - accuracy: 0.8081 - val_loss: 0.6316 - val_accuracy: 0.8095\n",
      "Epoch 15/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5490 - accuracy: 0.8098\n",
      "Epoch 00015: val_accuracy improved from 0.81070 to 0.81330, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model2_15-0.81.hdf5\n",
      "390/390 [==============================] - 29s 74ms/step - loss: 0.5492 - accuracy: 0.8097 - val_loss: 0.6198 - val_accuracy: 0.8133\n",
      "Epoch 16/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5428 - accuracy: 0.8093\n",
      "Epoch 00016: val_accuracy did not improve from 0.81330\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5433 - accuracy: 0.8091 - val_loss: 0.6484 - val_accuracy: 0.8048\n",
      "Epoch 17/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5452 - accuracy: 0.8111\n",
      "Epoch 00017: val_accuracy did not improve from 0.81330\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5447 - accuracy: 0.8112 - val_loss: 0.6252 - val_accuracy: 0.8105\n",
      "Epoch 18/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5454 - accuracy: 0.8068\n",
      "Epoch 00018: val_accuracy did not improve from 0.81330\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5451 - accuracy: 0.8070 - val_loss: 0.6236 - val_accuracy: 0.8098\n",
      "Epoch 19/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5433 - accuracy: 0.8096\n",
      "Epoch 00019: val_accuracy did not improve from 0.81330\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5432 - accuracy: 0.8096 - val_loss: 0.6261 - val_accuracy: 0.8099\n",
      "Epoch 20/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5443 - accuracy: 0.8093\n",
      "Epoch 00020: val_accuracy did not improve from 0.81330\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5447 - accuracy: 0.8092 - val_loss: 0.6298 - val_accuracy: 0.8111\n",
      "Epoch 21/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5438 - accuracy: 0.8087\n",
      "Epoch 00021: val_accuracy did not improve from 0.81330\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5438 - accuracy: 0.8088 - val_loss: 0.6196 - val_accuracy: 0.8110\n",
      "Epoch 22/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5457 - accuracy: 0.8086\n",
      "Epoch 00022: val_accuracy did not improve from 0.81330\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5456 - accuracy: 0.8085 - val_loss: 0.6491 - val_accuracy: 0.8020\n",
      "Epoch 23/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5433 - accuracy: 0.8101\n",
      "Epoch 00023: val_accuracy did not improve from 0.81330\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5433 - accuracy: 0.8100 - val_loss: 0.6528 - val_accuracy: 0.8067\n",
      "Epoch 24/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5456 - accuracy: 0.8086\n",
      "Epoch 00024: val_accuracy did not improve from 0.81330\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5454 - accuracy: 0.8087 - val_loss: 0.6227 - val_accuracy: 0.8119\n",
      "Epoch 25/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5426 - accuracy: 0.8093\n",
      "Epoch 00025: val_accuracy did not improve from 0.81330\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5426 - accuracy: 0.8093 - val_loss: 0.6399 - val_accuracy: 0.8086\n",
      "Epoch 26/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5419 - accuracy: 0.8092\n",
      "Epoch 00026: val_accuracy did not improve from 0.81330\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5416 - accuracy: 0.8092 - val_loss: 0.6489 - val_accuracy: 0.8045\n",
      "Epoch 27/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5459 - accuracy: 0.8083\n",
      "Epoch 00027: val_accuracy did not improve from 0.81330\n",
      "390/390 [==============================] - 28s 73ms/step - loss: 0.5461 - accuracy: 0.8083 - val_loss: 0.6226 - val_accuracy: 0.8121\n",
      "Epoch 28/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5440 - accuracy: 0.8079\n",
      "Epoch 00028: val_accuracy did not improve from 0.81330\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5439 - accuracy: 0.8079 - val_loss: 0.6395 - val_accuracy: 0.8060\n",
      "Epoch 29/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5365 - accuracy: 0.8132\n",
      "Epoch 00029: val_accuracy did not improve from 0.81330\n",
      "390/390 [==============================] - 28s 73ms/step - loss: 0.5368 - accuracy: 0.8132 - val_loss: 0.6366 - val_accuracy: 0.8097\n",
      "Epoch 30/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5392 - accuracy: 0.8124\n",
      "Epoch 00030: val_accuracy did not improve from 0.81330\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5390 - accuracy: 0.8125 - val_loss: 0.6457 - val_accuracy: 0.8061\n",
      "Epoch 31/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5378 - accuracy: 0.8101\n",
      "Epoch 00031: val_accuracy did not improve from 0.81330\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5379 - accuracy: 0.8101 - val_loss: 0.6383 - val_accuracy: 0.8075\n",
      "Epoch 32/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5366 - accuracy: 0.8110\n",
      "Epoch 00032: val_accuracy did not improve from 0.81330\n",
      "390/390 [==============================] - 28s 71ms/step - loss: 0.5366 - accuracy: 0.8110 - val_loss: 0.6434 - val_accuracy: 0.8048\n",
      "Epoch 33/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5380 - accuracy: 0.8124\n",
      "Epoch 00033: val_accuracy did not improve from 0.81330\n",
      "390/390 [==============================] - 27s 70ms/step - loss: 0.5378 - accuracy: 0.8125 - val_loss: 0.6457 - val_accuracy: 0.8052\n",
      "Epoch 34/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5308 - accuracy: 0.8136\n",
      "Epoch 00034: val_accuracy did not improve from 0.81330\n",
      "390/390 [==============================] - 28s 71ms/step - loss: 0.5308 - accuracy: 0.8135 - val_loss: 0.6438 - val_accuracy: 0.8054\n",
      "Epoch 35/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5358 - accuracy: 0.8119\n",
      "Epoch 00035: val_accuracy did not improve from 0.81330\n",
      "390/390 [==============================] - 27s 70ms/step - loss: 0.5360 - accuracy: 0.8118 - val_loss: 0.6379 - val_accuracy: 0.8071\n",
      "Epoch 36/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5380 - accuracy: 0.8110\n",
      "Epoch 00036: val_accuracy did not improve from 0.81330\n",
      "390/390 [==============================] - 27s 70ms/step - loss: 0.5380 - accuracy: 0.8111 - val_loss: 0.6425 - val_accuracy: 0.8069\n",
      "Epoch 37/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5303 - accuracy: 0.8142\n",
      "Epoch 00037: val_accuracy did not improve from 0.81330\n",
      "390/390 [==============================] - 28s 71ms/step - loss: 0.5303 - accuracy: 0.8142 - val_loss: 0.6417 - val_accuracy: 0.8068\n",
      "Epoch 38/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5342 - accuracy: 0.8135\n",
      "Epoch 00038: val_accuracy did not improve from 0.81330\n",
      "390/390 [==============================] - 28s 71ms/step - loss: 0.5344 - accuracy: 0.8134 - val_loss: 0.6397 - val_accuracy: 0.8076\n",
      "Epoch 39/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5352 - accuracy: 0.8128\n",
      "Epoch 00039: val_accuracy did not improve from 0.81330\n",
      "390/390 [==============================] - 28s 71ms/step - loss: 0.5353 - accuracy: 0.8127 - val_loss: 0.6358 - val_accuracy: 0.8082\n",
      "Epoch 40/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5310 - accuracy: 0.8140\n",
      "Epoch 00040: val_accuracy did not improve from 0.81330\n",
      "390/390 [==============================] - 28s 71ms/step - loss: 0.5308 - accuracy: 0.8141 - val_loss: 0.6359 - val_accuracy: 0.8076\n",
      "Epoch 41/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5309 - accuracy: 0.8153\n",
      "Epoch 00041: val_accuracy did not improve from 0.81330\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5308 - accuracy: 0.8154 - val_loss: 0.6379 - val_accuracy: 0.8082\n",
      "Epoch 42/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5322 - accuracy: 0.8146\n",
      "Epoch 00042: val_accuracy did not improve from 0.81330\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5318 - accuracy: 0.8147 - val_loss: 0.6380 - val_accuracy: 0.8082\n",
      "Epoch 43/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5333 - accuracy: 0.8116\n",
      "Epoch 00043: val_accuracy did not improve from 0.81330\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5334 - accuracy: 0.8116 - val_loss: 0.6386 - val_accuracy: 0.8086\n",
      "Epoch 44/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5337 - accuracy: 0.8135\n",
      "Epoch 00044: val_accuracy did not improve from 0.81330\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5340 - accuracy: 0.8133 - val_loss: 0.6378 - val_accuracy: 0.8076\n",
      "Epoch 45/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5355 - accuracy: 0.8113\n",
      "Epoch 00045: val_accuracy did not improve from 0.81330\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5355 - accuracy: 0.8113 - val_loss: 0.6396 - val_accuracy: 0.8072\n",
      "Epoch 46/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5328 - accuracy: 0.8158\n",
      "Epoch 00046: val_accuracy did not improve from 0.81330\n",
      "390/390 [==============================] - 28s 73ms/step - loss: 0.5324 - accuracy: 0.8159 - val_loss: 0.6391 - val_accuracy: 0.8070\n",
      "Epoch 47/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5281 - accuracy: 0.8146\n",
      "Epoch 00047: val_accuracy did not improve from 0.81330\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5280 - accuracy: 0.8145 - val_loss: 0.6334 - val_accuracy: 0.8089\n",
      "Epoch 48/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5326 - accuracy: 0.8127\n",
      "Epoch 00048: val_accuracy did not improve from 0.81330\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5326 - accuracy: 0.8127 - val_loss: 0.6348 - val_accuracy: 0.8083\n",
      "Epoch 49/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5293 - accuracy: 0.8127\n",
      "Epoch 00049: val_accuracy did not improve from 0.81330\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5292 - accuracy: 0.8127 - val_loss: 0.6332 - val_accuracy: 0.8091\n",
      "Epoch 50/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5316 - accuracy: 0.8149\n",
      "Epoch 00050: val_accuracy did not improve from 0.81330\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5318 - accuracy: 0.8148 - val_loss: 0.6348 - val_accuracy: 0.8085\n",
      "Epoch 51/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5313 - accuracy: 0.8131\n",
      "Epoch 00051: val_accuracy did not improve from 0.81330\n",
      "390/390 [==============================] - 28s 73ms/step - loss: 0.5313 - accuracy: 0.8131 - val_loss: 0.6352 - val_accuracy: 0.8082\n",
      "Epoch 52/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5248 - accuracy: 0.8156\n",
      "Epoch 00052: val_accuracy did not improve from 0.81330\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5252 - accuracy: 0.8154 - val_loss: 0.6336 - val_accuracy: 0.8087\n",
      "Epoch 53/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5272 - accuracy: 0.8158\n",
      "Epoch 00053: val_accuracy did not improve from 0.81330\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5272 - accuracy: 0.8158 - val_loss: 0.6357 - val_accuracy: 0.8085\n",
      "Epoch 54/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5305 - accuracy: 0.8145\n",
      "Epoch 00054: val_accuracy did not improve from 0.81330\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5308 - accuracy: 0.8143 - val_loss: 0.6346 - val_accuracy: 0.8083\n",
      "Epoch 55/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5306 - accuracy: 0.8148\n",
      "Epoch 00055: val_accuracy did not improve from 0.81330\n",
      "390/390 [==============================] - 28s 73ms/step - loss: 0.5308 - accuracy: 0.8147 - val_loss: 0.6348 - val_accuracy: 0.8086\n",
      "Epoch 56/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5336 - accuracy: 0.8118\n",
      "Epoch 00056: val_accuracy did not improve from 0.81330\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5336 - accuracy: 0.8118 - val_loss: 0.6342 - val_accuracy: 0.8092\n",
      "Epoch 57/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5297 - accuracy: 0.8140\n",
      "Epoch 00057: val_accuracy did not improve from 0.81330\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5298 - accuracy: 0.8141 - val_loss: 0.6349 - val_accuracy: 0.8082\n",
      "Epoch 58/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5317 - accuracy: 0.8150\n",
      "Epoch 00058: val_accuracy did not improve from 0.81330\n",
      "390/390 [==============================] - 28s 73ms/step - loss: 0.5318 - accuracy: 0.8148 - val_loss: 0.6356 - val_accuracy: 0.8085\n",
      "Epoch 59/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5347 - accuracy: 0.8130\n",
      "Epoch 00059: val_accuracy did not improve from 0.81330\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5346 - accuracy: 0.8130 - val_loss: 0.6365 - val_accuracy: 0.8081\n",
      "Epoch 60/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5304 - accuracy: 0.8126\n",
      "Epoch 00060: val_accuracy did not improve from 0.81330\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5304 - accuracy: 0.8126 - val_loss: 0.6335 - val_accuracy: 0.8082\n",
      "Epoch 61/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5296 - accuracy: 0.8138\n",
      "Epoch 00061: val_accuracy did not improve from 0.81330\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5297 - accuracy: 0.8136 - val_loss: 0.6367 - val_accuracy: 0.8081\n",
      "Epoch 62/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5310 - accuracy: 0.8135\n",
      "Epoch 00062: val_accuracy did not improve from 0.81330\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5312 - accuracy: 0.8134 - val_loss: 0.6355 - val_accuracy: 0.8080\n",
      "Epoch 63/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5334 - accuracy: 0.8119\n",
      "Epoch 00063: val_accuracy did not improve from 0.81330\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5335 - accuracy: 0.8119 - val_loss: 0.6378 - val_accuracy: 0.8079\n",
      "Epoch 64/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5328 - accuracy: 0.8157\n",
      "Epoch 00064: val_accuracy did not improve from 0.81330\n",
      "390/390 [==============================] - 28s 73ms/step - loss: 0.5326 - accuracy: 0.8157 - val_loss: 0.6364 - val_accuracy: 0.8078\n",
      "Epoch 65/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5313 - accuracy: 0.8158\n",
      "Epoch 00065: val_accuracy did not improve from 0.81330\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5312 - accuracy: 0.8159 - val_loss: 0.6366 - val_accuracy: 0.8083\n"
     ]
    }
   ],
   "source": [
    "#https://keras.io/api/preprocessing/image/#flow-method\n",
    "\n",
    "history_2 = model_2.fit(data_generator.flow(X_train, y_train, batch_size),\n",
    "                    steps_per_epoch = int(len(X_train)/batch_size),\n",
    "                    epochs = epochs,\n",
    "                    callbacks = callbacks,\n",
    "                    validation_data = (X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#history plot for accyracy\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.plot(history_2.history['accuracy'])\n",
    "plt.plot(history_2.history['val_accuracy'])\n",
    "plt.title(\"Model Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend([\"train\", \"test\"], loc=\"upper left\")\n",
    "plt.show()\n",
    "\n",
    "# history plot for accuracy\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.plot(history_2.history[\"loss\"])\n",
    "plt.plot(history_2.history[\"val_loss\"])\n",
    "plt.title(\"Model Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend([\"train\", \"test\"], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary:\n",
    "- Even after changing the learning rate the model accuracy is not improved. Next we can try is different convolution and different num of filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 347us/sample - loss: 0.6198 - accuracy: 0.8133\n",
      "[0.6198125976085663, 0.8133]\n"
     ]
    }
   ],
   "source": [
    "best_model_2 = tf.keras.models.load_model('/home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model2_15-0.81.hdf5')\n",
    "scores = best_model_2.evaluate(X_test, y_test, verbose=1)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Model-3\n",
    "- Seperable convolution\n",
    "- num filters 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BN-->ReLU-->Conv2D-->Dropout-->concat(input, output)-->(put in loop)\n",
    "\n",
    "def denseblock(input, num_filter, dropout_rate = 0.2):\n",
    "    global compression      # to keep the growth rate of number of filters\n",
    "    temp = input\n",
    "    for _ in range(l): \n",
    "        BatchNorm = layers.BatchNormalization()(temp)\n",
    "        relu = layers.Activation('relu')(BatchNorm)\n",
    "        Conv2D_5_5= layers.SeparableConv2D(int(num_filter*compression), (5,5), use_bias=False, padding='same')(relu)\n",
    "        #Conv2D_3_3 = layers.Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n",
    "        if dropout_rate>0:\n",
    "            Conv2D_5_5 = layers.Dropout(dropout_rate)(Conv2D_5_5)\n",
    "\n",
    "        #concat the input(temp) and output(conv2d_3_3) , in resnet we add but here we concat \n",
    "        concat = layers.Concatenate(axis=-1)([temp,Conv2D_5_5])\n",
    "        \n",
    "        #change the concat as input\n",
    "        temp = concat\n",
    "        \n",
    "    return temp\n",
    "\n",
    "#BN-->relu-->conv2d(1x1)-->dropout-->avg_pool\n",
    "def transition(input, num_filter, dropout_rate = 0.2):\n",
    "    global compression\n",
    "    BatchNorm = layers.BatchNormalization()(input)\n",
    "    relu = layers.Activation('relu')(BatchNorm)\n",
    "    #Conv2D_BottleNeck = layers.Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
    "    Conv2D_BottleNeck = layers.SeparableConvolution2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
    "    if dropout_rate>0:\n",
    "         Conv2D_BottleNeck = layers.Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
    "    avg = layers.AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
    "    return avg\n",
    "\n",
    "#BN-->relu-->avgpool-->flat-->softmax\n",
    "def output_layer(input):\n",
    "    global compression\n",
    "    BatchNorm = layers.BatchNormalization()(input)\n",
    "    relu = layers.Activation('relu')(BatchNorm)\n",
    "    AvgPooling = layers.AveragePooling2D(pool_size=(2,2))(relu)\n",
    "    flat = layers.Flatten()(AvgPooling)\n",
    "    output = layers.Dense(num_classes, activation='softmax')(flat)\n",
    "    return output\n",
    "\n",
    "# Hyperparameters\n",
    "l = 12\n",
    "num_filter = 32\n",
    "compression = 0.5\n",
    "dropout_rate = 0.2\n",
    "num_classes = 10\n",
    "\n",
    "input = layers.Input(shape=(input_size))\n",
    "First_Conv2D = layers.Conv2D(num_filter, (5,5), use_bias=False ,padding='same')(input)\n",
    "\n",
    "#First dense and transition block\n",
    "First_Block = denseblock(First_Conv2D, num_filter, dropout_rate)\n",
    "First_Transition = transition(First_Block, num_filter, dropout_rate)\n",
    "\n",
    "#Second dense and transition block\n",
    "Second_Block = denseblock(First_Transition, num_filter, dropout_rate)\n",
    "Second_Transition = transition(Second_Block, num_filter, dropout_rate)\n",
    "\n",
    "#Third dense and transition block\n",
    "Third_Block = denseblock(Second_Transition, num_filter, dropout_rate)\n",
    "Third_Transition = transition(Third_Block, num_filter, dropout_rate)\n",
    "\n",
    "#last dense and output block\n",
    "Last_Block = denseblock(Third_Transition,  num_filter, dropout_rate)\n",
    "output = output_layer(Last_Block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 32, 32, 32)   2400        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 32, 32, 32)   128         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 32, 32, 32)   0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_51 (SeparableC (None, 32, 32, 16)   1312        activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_102 (Dropout)           (None, 32, 32, 16)   0           separable_conv2d_51[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_96 (Concatenate)    (None, 32, 32, 48)   0           conv2d_53[0][0]                  \n",
      "                                                                 dropout_102[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 32, 32, 48)   192         concatenate_96[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 32, 32, 48)   0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_52 (SeparableC (None, 32, 32, 16)   1968        activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_103 (Dropout)           (None, 32, 32, 16)   0           separable_conv2d_52[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_97 (Concatenate)    (None, 32, 32, 64)   0           concatenate_96[0][0]             \n",
      "                                                                 dropout_103[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 32, 32, 64)   256         concatenate_97[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 32, 32, 64)   0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_53 (SeparableC (None, 32, 32, 16)   2624        activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_104 (Dropout)           (None, 32, 32, 16)   0           separable_conv2d_53[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_98 (Concatenate)    (None, 32, 32, 80)   0           concatenate_97[0][0]             \n",
      "                                                                 dropout_104[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 32, 32, 80)   320         concatenate_98[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 32, 32, 80)   0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_54 (SeparableC (None, 32, 32, 16)   3280        activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_105 (Dropout)           (None, 32, 32, 16)   0           separable_conv2d_54[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_99 (Concatenate)    (None, 32, 32, 96)   0           concatenate_98[0][0]             \n",
      "                                                                 dropout_105[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 32, 32, 96)   384         concatenate_99[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 32, 32, 96)   0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_55 (SeparableC (None, 32, 32, 16)   3936        activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_106 (Dropout)           (None, 32, 32, 16)   0           separable_conv2d_55[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_100 (Concatenate)   (None, 32, 32, 112)  0           concatenate_99[0][0]             \n",
      "                                                                 dropout_106[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 32, 32, 112)  448         concatenate_100[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 32, 32, 112)  0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_56 (SeparableC (None, 32, 32, 16)   4592        activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_107 (Dropout)           (None, 32, 32, 16)   0           separable_conv2d_56[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_101 (Concatenate)   (None, 32, 32, 128)  0           concatenate_100[0][0]            \n",
      "                                                                 dropout_107[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 32, 32, 128)  512         concatenate_101[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 32, 32, 128)  0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_57 (SeparableC (None, 32, 32, 16)   5248        activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_108 (Dropout)           (None, 32, 32, 16)   0           separable_conv2d_57[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_102 (Concatenate)   (None, 32, 32, 144)  0           concatenate_101[0][0]            \n",
      "                                                                 dropout_108[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 32, 32, 144)  576         concatenate_102[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 32, 32, 144)  0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_58 (SeparableC (None, 32, 32, 16)   5904        activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_109 (Dropout)           (None, 32, 32, 16)   0           separable_conv2d_58[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_103 (Concatenate)   (None, 32, 32, 160)  0           concatenate_102[0][0]            \n",
      "                                                                 dropout_109[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 32, 32, 160)  640         concatenate_103[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 32, 32, 160)  0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_59 (SeparableC (None, 32, 32, 16)   6560        activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_110 (Dropout)           (None, 32, 32, 16)   0           separable_conv2d_59[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_104 (Concatenate)   (None, 32, 32, 176)  0           concatenate_103[0][0]            \n",
      "                                                                 dropout_110[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 32, 32, 176)  704         concatenate_104[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 32, 32, 176)  0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_60 (SeparableC (None, 32, 32, 16)   7216        activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_111 (Dropout)           (None, 32, 32, 16)   0           separable_conv2d_60[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_105 (Concatenate)   (None, 32, 32, 192)  0           concatenate_104[0][0]            \n",
      "                                                                 dropout_111[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 32, 32, 192)  768         concatenate_105[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 32, 32, 192)  0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_61 (SeparableC (None, 32, 32, 16)   7872        activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_112 (Dropout)           (None, 32, 32, 16)   0           separable_conv2d_61[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_106 (Concatenate)   (None, 32, 32, 208)  0           concatenate_105[0][0]            \n",
      "                                                                 dropout_112[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 32, 32, 208)  832         concatenate_106[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 32, 32, 208)  0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_62 (SeparableC (None, 32, 32, 16)   8528        activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_113 (Dropout)           (None, 32, 32, 16)   0           separable_conv2d_62[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_107 (Concatenate)   (None, 32, 32, 224)  0           concatenate_106[0][0]            \n",
      "                                                                 dropout_113[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 32, 32, 224)  896         concatenate_107[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 32, 32, 224)  0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_63 (SeparableC (None, 32, 32, 16)   3808        activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_114 (Dropout)           (None, 32, 32, 16)   0           separable_conv2d_63[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 16, 16, 16)   0           dropout_114[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 16, 16, 16)   64          average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 16, 16, 16)   0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_64 (SeparableC (None, 16, 16, 16)   656         activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_115 (Dropout)           (None, 16, 16, 16)   0           separable_conv2d_64[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_108 (Concatenate)   (None, 16, 16, 32)   0           average_pooling2d_8[0][0]        \n",
      "                                                                 dropout_115[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 16, 16, 32)   128         concatenate_108[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 16, 16, 32)   0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_65 (SeparableC (None, 16, 16, 16)   1312        activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_116 (Dropout)           (None, 16, 16, 16)   0           separable_conv2d_65[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_109 (Concatenate)   (None, 16, 16, 48)   0           concatenate_108[0][0]            \n",
      "                                                                 dropout_116[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 16, 16, 48)   192         concatenate_109[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 16, 16, 48)   0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_66 (SeparableC (None, 16, 16, 16)   1968        activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_117 (Dropout)           (None, 16, 16, 16)   0           separable_conv2d_66[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_110 (Concatenate)   (None, 16, 16, 64)   0           concatenate_109[0][0]            \n",
      "                                                                 dropout_117[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 16, 16, 64)   256         concatenate_110[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 16, 16, 64)   0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_67 (SeparableC (None, 16, 16, 16)   2624        activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_118 (Dropout)           (None, 16, 16, 16)   0           separable_conv2d_67[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_111 (Concatenate)   (None, 16, 16, 80)   0           concatenate_110[0][0]            \n",
      "                                                                 dropout_118[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 16, 16, 80)   320         concatenate_111[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 16, 16, 80)   0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_68 (SeparableC (None, 16, 16, 16)   3280        activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_119 (Dropout)           (None, 16, 16, 16)   0           separable_conv2d_68[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_112 (Concatenate)   (None, 16, 16, 96)   0           concatenate_111[0][0]            \n",
      "                                                                 dropout_119[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 16, 16, 96)   384         concatenate_112[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 16, 16, 96)   0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_69 (SeparableC (None, 16, 16, 16)   3936        activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_120 (Dropout)           (None, 16, 16, 16)   0           separable_conv2d_69[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_113 (Concatenate)   (None, 16, 16, 112)  0           concatenate_112[0][0]            \n",
      "                                                                 dropout_120[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 16, 16, 112)  448         concatenate_113[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 16, 16, 112)  0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_70 (SeparableC (None, 16, 16, 16)   4592        activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_121 (Dropout)           (None, 16, 16, 16)   0           separable_conv2d_70[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_114 (Concatenate)   (None, 16, 16, 128)  0           concatenate_113[0][0]            \n",
      "                                                                 dropout_121[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 16, 16, 128)  512         concatenate_114[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 16, 16, 128)  0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_71 (SeparableC (None, 16, 16, 16)   5248        activation_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_122 (Dropout)           (None, 16, 16, 16)   0           separable_conv2d_71[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_115 (Concatenate)   (None, 16, 16, 144)  0           concatenate_114[0][0]            \n",
      "                                                                 dropout_122[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 16, 16, 144)  576         concatenate_115[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 16, 16, 144)  0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_72 (SeparableC (None, 16, 16, 16)   5904        activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_123 (Dropout)           (None, 16, 16, 16)   0           separable_conv2d_72[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_116 (Concatenate)   (None, 16, 16, 160)  0           concatenate_115[0][0]            \n",
      "                                                                 dropout_123[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 16, 16, 160)  640         concatenate_116[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 16, 16, 160)  0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_73 (SeparableC (None, 16, 16, 16)   6560        activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_124 (Dropout)           (None, 16, 16, 16)   0           separable_conv2d_73[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_117 (Concatenate)   (None, 16, 16, 176)  0           concatenate_116[0][0]            \n",
      "                                                                 dropout_124[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 16, 16, 176)  704         concatenate_117[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 16, 16, 176)  0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_74 (SeparableC (None, 16, 16, 16)   7216        activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_125 (Dropout)           (None, 16, 16, 16)   0           separable_conv2d_74[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_118 (Concatenate)   (None, 16, 16, 192)  0           concatenate_117[0][0]            \n",
      "                                                                 dropout_125[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 16, 16, 192)  768         concatenate_118[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 16, 16, 192)  0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_75 (SeparableC (None, 16, 16, 16)   7872        activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_126 (Dropout)           (None, 16, 16, 16)   0           separable_conv2d_75[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_119 (Concatenate)   (None, 16, 16, 208)  0           concatenate_118[0][0]            \n",
      "                                                                 dropout_126[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 16, 16, 208)  832         concatenate_119[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 16, 16, 208)  0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_76 (SeparableC (None, 16, 16, 16)   3536        activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_127 (Dropout)           (None, 16, 16, 16)   0           separable_conv2d_76[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 8, 8, 16)     0           dropout_127[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 8, 8, 16)     64          average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 8, 8, 16)     0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_77 (SeparableC (None, 8, 8, 16)     656         activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_128 (Dropout)           (None, 8, 8, 16)     0           separable_conv2d_77[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_120 (Concatenate)   (None, 8, 8, 32)     0           average_pooling2d_9[0][0]        \n",
      "                                                                 dropout_128[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 8, 8, 32)     128         concatenate_120[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 8, 8, 32)     0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_78 (SeparableC (None, 8, 8, 16)     1312        activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_129 (Dropout)           (None, 8, 8, 16)     0           separable_conv2d_78[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_121 (Concatenate)   (None, 8, 8, 48)     0           concatenate_120[0][0]            \n",
      "                                                                 dropout_129[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 8, 8, 48)     192         concatenate_121[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 8, 8, 48)     0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_79 (SeparableC (None, 8, 8, 16)     1968        activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_130 (Dropout)           (None, 8, 8, 16)     0           separable_conv2d_79[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_122 (Concatenate)   (None, 8, 8, 64)     0           concatenate_121[0][0]            \n",
      "                                                                 dropout_130[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 8, 8, 64)     256         concatenate_122[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 8, 8, 64)     0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_80 (SeparableC (None, 8, 8, 16)     2624        activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_131 (Dropout)           (None, 8, 8, 16)     0           separable_conv2d_80[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_123 (Concatenate)   (None, 8, 8, 80)     0           concatenate_122[0][0]            \n",
      "                                                                 dropout_131[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 8, 8, 80)     320         concatenate_123[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 8, 8, 80)     0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_81 (SeparableC (None, 8, 8, 16)     3280        activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_132 (Dropout)           (None, 8, 8, 16)     0           separable_conv2d_81[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_124 (Concatenate)   (None, 8, 8, 96)     0           concatenate_123[0][0]            \n",
      "                                                                 dropout_132[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 8, 8, 96)     384         concatenate_124[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 8, 8, 96)     0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_82 (SeparableC (None, 8, 8, 16)     3936        activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_133 (Dropout)           (None, 8, 8, 16)     0           separable_conv2d_82[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_125 (Concatenate)   (None, 8, 8, 112)    0           concatenate_124[0][0]            \n",
      "                                                                 dropout_133[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 8, 8, 112)    448         concatenate_125[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 8, 8, 112)    0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_83 (SeparableC (None, 8, 8, 16)     4592        activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_134 (Dropout)           (None, 8, 8, 16)     0           separable_conv2d_83[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_126 (Concatenate)   (None, 8, 8, 128)    0           concatenate_125[0][0]            \n",
      "                                                                 dropout_134[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 8, 8, 128)    512         concatenate_126[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 8, 8, 128)    0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_84 (SeparableC (None, 8, 8, 16)     5248        activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_135 (Dropout)           (None, 8, 8, 16)     0           separable_conv2d_84[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_127 (Concatenate)   (None, 8, 8, 144)    0           concatenate_126[0][0]            \n",
      "                                                                 dropout_135[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 8, 8, 144)    576         concatenate_127[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 8, 8, 144)    0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_85 (SeparableC (None, 8, 8, 16)     5904        activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_136 (Dropout)           (None, 8, 8, 16)     0           separable_conv2d_85[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_128 (Concatenate)   (None, 8, 8, 160)    0           concatenate_127[0][0]            \n",
      "                                                                 dropout_136[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 8, 8, 160)    640         concatenate_128[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 8, 8, 160)    0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_86 (SeparableC (None, 8, 8, 16)     6560        activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_137 (Dropout)           (None, 8, 8, 16)     0           separable_conv2d_86[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_129 (Concatenate)   (None, 8, 8, 176)    0           concatenate_128[0][0]            \n",
      "                                                                 dropout_137[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 8, 8, 176)    704         concatenate_129[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 8, 8, 176)    0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_87 (SeparableC (None, 8, 8, 16)     7216        activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_138 (Dropout)           (None, 8, 8, 16)     0           separable_conv2d_87[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_130 (Concatenate)   (None, 8, 8, 192)    0           concatenate_129[0][0]            \n",
      "                                                                 dropout_138[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 8, 8, 192)    768         concatenate_130[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 8, 8, 192)    0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_88 (SeparableC (None, 8, 8, 16)     7872        activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_139 (Dropout)           (None, 8, 8, 16)     0           separable_conv2d_88[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_131 (Concatenate)   (None, 8, 8, 208)    0           concatenate_130[0][0]            \n",
      "                                                                 dropout_139[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 8, 8, 208)    832         concatenate_131[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 8, 8, 208)    0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_89 (SeparableC (None, 8, 8, 16)     3536        activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_140 (Dropout)           (None, 8, 8, 16)     0           separable_conv2d_89[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_10 (AveragePo (None, 4, 4, 16)     0           dropout_140[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 4, 4, 16)     64          average_pooling2d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 4, 4, 16)     0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_90 (SeparableC (None, 4, 4, 16)     656         activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_141 (Dropout)           (None, 4, 4, 16)     0           separable_conv2d_90[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_132 (Concatenate)   (None, 4, 4, 32)     0           average_pooling2d_10[0][0]       \n",
      "                                                                 dropout_141[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 4, 4, 32)     128         concatenate_132[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 4, 4, 32)     0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_91 (SeparableC (None, 4, 4, 16)     1312        activation_144[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_142 (Dropout)           (None, 4, 4, 16)     0           separable_conv2d_91[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_133 (Concatenate)   (None, 4, 4, 48)     0           concatenate_132[0][0]            \n",
      "                                                                 dropout_142[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 4, 4, 48)     192         concatenate_133[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 4, 4, 48)     0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_92 (SeparableC (None, 4, 4, 16)     1968        activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_143 (Dropout)           (None, 4, 4, 16)     0           separable_conv2d_92[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_134 (Concatenate)   (None, 4, 4, 64)     0           concatenate_133[0][0]            \n",
      "                                                                 dropout_143[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 4, 4, 64)     256         concatenate_134[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 4, 4, 64)     0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_93 (SeparableC (None, 4, 4, 16)     2624        activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_144 (Dropout)           (None, 4, 4, 16)     0           separable_conv2d_93[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_135 (Concatenate)   (None, 4, 4, 80)     0           concatenate_134[0][0]            \n",
      "                                                                 dropout_144[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 4, 4, 80)     320         concatenate_135[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 4, 4, 80)     0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_94 (SeparableC (None, 4, 4, 16)     3280        activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_145 (Dropout)           (None, 4, 4, 16)     0           separable_conv2d_94[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_136 (Concatenate)   (None, 4, 4, 96)     0           concatenate_135[0][0]            \n",
      "                                                                 dropout_145[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 4, 4, 96)     384         concatenate_136[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 4, 4, 96)     0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_95 (SeparableC (None, 4, 4, 16)     3936        activation_148[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_146 (Dropout)           (None, 4, 4, 16)     0           separable_conv2d_95[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_137 (Concatenate)   (None, 4, 4, 112)    0           concatenate_136[0][0]            \n",
      "                                                                 dropout_146[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 4, 4, 112)    448         concatenate_137[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 4, 4, 112)    0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_96 (SeparableC (None, 4, 4, 16)     4592        activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_147 (Dropout)           (None, 4, 4, 16)     0           separable_conv2d_96[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_138 (Concatenate)   (None, 4, 4, 128)    0           concatenate_137[0][0]            \n",
      "                                                                 dropout_147[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 4, 4, 128)    512         concatenate_138[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 4, 4, 128)    0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_97 (SeparableC (None, 4, 4, 16)     5248        activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_148 (Dropout)           (None, 4, 4, 16)     0           separable_conv2d_97[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_139 (Concatenate)   (None, 4, 4, 144)    0           concatenate_138[0][0]            \n",
      "                                                                 dropout_148[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 4, 4, 144)    576         concatenate_139[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 4, 4, 144)    0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_98 (SeparableC (None, 4, 4, 16)     5904        activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_149 (Dropout)           (None, 4, 4, 16)     0           separable_conv2d_98[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_140 (Concatenate)   (None, 4, 4, 160)    0           concatenate_139[0][0]            \n",
      "                                                                 dropout_149[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 4, 4, 160)    640         concatenate_140[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 4, 4, 160)    0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_99 (SeparableC (None, 4, 4, 16)     6560        activation_152[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_150 (Dropout)           (None, 4, 4, 16)     0           separable_conv2d_99[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_141 (Concatenate)   (None, 4, 4, 176)    0           concatenate_140[0][0]            \n",
      "                                                                 dropout_150[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 4, 4, 176)    704         concatenate_141[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 4, 4, 176)    0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_100 (Separable (None, 4, 4, 16)     7216        activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_151 (Dropout)           (None, 4, 4, 16)     0           separable_conv2d_100[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_142 (Concatenate)   (None, 4, 4, 192)    0           concatenate_141[0][0]            \n",
      "                                                                 dropout_151[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 4, 4, 192)    768         concatenate_142[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 4, 4, 192)    0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_101 (Separable (None, 4, 4, 16)     7872        activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_152 (Dropout)           (None, 4, 4, 16)     0           separable_conv2d_101[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_143 (Concatenate)   (None, 4, 4, 208)    0           concatenate_142[0][0]            \n",
      "                                                                 dropout_152[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 4, 4, 208)    832         concatenate_143[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 4, 4, 208)    0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_11 (AveragePo (None, 2, 2, 208)    0           activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 832)          0           average_pooling2d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           8330        flatten_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 258,282\n",
      "Trainable params: 246,218\n",
      "Non-trainable params: 12,064\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_3 = tf.keras.models.Model(inputs=[input], outputs=[output])\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 195 steps, validate on 10000 samples\n",
      "Epoch 1/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 1.6785 - accuracy: 0.3742\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.10000, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model3_01-0.10.hdf5\n",
      "195/195 [==============================] - 41s 208ms/step - loss: 1.6764 - accuracy: 0.3745 - val_loss: 2.3508 - val_accuracy: 0.1000\n",
      "Epoch 2/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 1.3361 - accuracy: 0.5122\n",
      "Epoch 00002: val_accuracy improved from 0.10000 to 0.13040, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model3_02-0.13.hdf5\n",
      "195/195 [==============================] - 28s 145ms/step - loss: 1.3360 - accuracy: 0.5123 - val_loss: 2.6361 - val_accuracy: 0.1304\n",
      "Epoch 3/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 1.1621 - accuracy: 0.5800\n",
      "Epoch 00003: val_accuracy improved from 0.13040 to 0.54500, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model3_03-0.55.hdf5\n",
      "195/195 [==============================] - 28s 145ms/step - loss: 1.1613 - accuracy: 0.5804 - val_loss: 1.3663 - val_accuracy: 0.5450\n",
      "Epoch 4/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 1.0322 - accuracy: 0.6288\n",
      "Epoch 00004: val_accuracy did not improve from 0.54500\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 1.0319 - accuracy: 0.6293 - val_loss: 1.7844 - val_accuracy: 0.5219\n",
      "Epoch 5/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.9398 - accuracy: 0.6622\n",
      "Epoch 00005: val_accuracy improved from 0.54500 to 0.59910, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model3_05-0.60.hdf5\n",
      "195/195 [==============================] - 28s 145ms/step - loss: 0.9401 - accuracy: 0.6621 - val_loss: 1.2854 - val_accuracy: 0.5991\n",
      "Epoch 6/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.8755 - accuracy: 0.6872\n",
      "Epoch 00006: val_accuracy did not improve from 0.59910\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.8745 - accuracy: 0.6874 - val_loss: 1.6606 - val_accuracy: 0.5682\n",
      "Epoch 7/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.8165 - accuracy: 0.7100\n",
      "Epoch 00007: val_accuracy improved from 0.59910 to 0.64520, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model3_07-0.65.hdf5\n",
      "195/195 [==============================] - 28s 146ms/step - loss: 0.8160 - accuracy: 0.7102 - val_loss: 1.2518 - val_accuracy: 0.6452\n",
      "Epoch 8/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.7745 - accuracy: 0.7274\n",
      "Epoch 00008: val_accuracy improved from 0.64520 to 0.67210, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model3_08-0.67.hdf5\n",
      "195/195 [==============================] - 28s 145ms/step - loss: 0.7748 - accuracy: 0.7274 - val_loss: 1.1228 - val_accuracy: 0.6721\n",
      "Epoch 9/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.7389 - accuracy: 0.7384\n",
      "Epoch 00009: val_accuracy did not improve from 0.67210\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.7385 - accuracy: 0.7386 - val_loss: 1.2116 - val_accuracy: 0.6537\n",
      "Epoch 10/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.7091 - accuracy: 0.7485\n",
      "Epoch 00010: val_accuracy did not improve from 0.67210\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.7087 - accuracy: 0.7486 - val_loss: 1.6817 - val_accuracy: 0.5975\n",
      "Epoch 11/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.6844 - accuracy: 0.7588\n",
      "Epoch 00011: val_accuracy improved from 0.67210 to 0.71550, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model3_11-0.72.hdf5\n",
      "195/195 [==============================] - 28s 145ms/step - loss: 0.6845 - accuracy: 0.7588 - val_loss: 0.9364 - val_accuracy: 0.7155\n",
      "Epoch 12/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.6538 - accuracy: 0.7710\n",
      "Epoch 00012: val_accuracy did not improve from 0.71550\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.6535 - accuracy: 0.7712 - val_loss: 1.4434 - val_accuracy: 0.6396\n",
      "Epoch 13/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.6384 - accuracy: 0.7773\n",
      "Epoch 00013: val_accuracy did not improve from 0.71550\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.6383 - accuracy: 0.7775 - val_loss: 1.2199 - val_accuracy: 0.6821\n",
      "Epoch 14/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.6177 - accuracy: 0.7850\n",
      "Epoch 00014: val_accuracy did not improve from 0.71550\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.6181 - accuracy: 0.7849 - val_loss: 1.4715 - val_accuracy: 0.6352\n",
      "Epoch 15/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.5979 - accuracy: 0.7906\n",
      "Epoch 00015: val_accuracy did not improve from 0.71550\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.5980 - accuracy: 0.7905 - val_loss: 1.2906 - val_accuracy: 0.6463\n",
      "Epoch 16/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.5799 - accuracy: 0.7985\n",
      "Epoch 00016: val_accuracy improved from 0.71550 to 0.72990, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model3_16-0.73.hdf5\n",
      "195/195 [==============================] - 28s 146ms/step - loss: 0.5801 - accuracy: 0.7983 - val_loss: 0.9909 - val_accuracy: 0.7299\n",
      "Epoch 17/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.5756 - accuracy: 0.8000\n",
      "Epoch 00017: val_accuracy improved from 0.72990 to 0.75800, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model3_17-0.76.hdf5\n",
      "195/195 [==============================] - 28s 145ms/step - loss: 0.5755 - accuracy: 0.8001 - val_loss: 0.8110 - val_accuracy: 0.7580\n",
      "Epoch 18/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.5569 - accuracy: 0.8053\n",
      "Epoch 00018: val_accuracy did not improve from 0.75800\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.5567 - accuracy: 0.8054 - val_loss: 1.0143 - val_accuracy: 0.7238\n",
      "Epoch 19/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.5450 - accuracy: 0.8104\n",
      "Epoch 00019: val_accuracy improved from 0.75800 to 0.78400, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model3_19-0.78.hdf5\n",
      "195/195 [==============================] - 28s 146ms/step - loss: 0.5454 - accuracy: 0.8102 - val_loss: 0.7006 - val_accuracy: 0.7840\n",
      "Epoch 20/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.5347 - accuracy: 0.8134\n",
      "Epoch 00020: val_accuracy did not improve from 0.78400\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.5345 - accuracy: 0.8134 - val_loss: 0.8453 - val_accuracy: 0.7636\n",
      "Epoch 21/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.5244 - accuracy: 0.8169\n",
      "Epoch 00021: val_accuracy did not improve from 0.78400\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.5242 - accuracy: 0.8170 - val_loss: 1.2476 - val_accuracy: 0.6963\n",
      "Epoch 22/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.5153 - accuracy: 0.8187\n",
      "Epoch 00022: val_accuracy did not improve from 0.78400\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.5154 - accuracy: 0.8187 - val_loss: 0.7055 - val_accuracy: 0.7833\n",
      "Epoch 23/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.5022 - accuracy: 0.8246\n",
      "Epoch 00023: val_accuracy did not improve from 0.78400\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.5024 - accuracy: 0.8245 - val_loss: 0.9178 - val_accuracy: 0.7420\n",
      "Epoch 24/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.4994 - accuracy: 0.8256\n",
      "Epoch 00024: val_accuracy did not improve from 0.78400\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.4993 - accuracy: 0.8256 - val_loss: 0.8734 - val_accuracy: 0.7555\n",
      "Epoch 25/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.4891 - accuracy: 0.8278\n",
      "Epoch 00025: val_accuracy did not improve from 0.78400\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.4895 - accuracy: 0.8276 - val_loss: 1.1021 - val_accuracy: 0.7249\n",
      "Epoch 26/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.4821 - accuracy: 0.8319\n",
      "Epoch 00026: val_accuracy did not improve from 0.78400\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.4822 - accuracy: 0.8319 - val_loss: 0.7443 - val_accuracy: 0.7774\n",
      "Epoch 27/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.4708 - accuracy: 0.8359\n",
      "Epoch 00027: val_accuracy did not improve from 0.78400\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.4706 - accuracy: 0.8361 - val_loss: 0.8986 - val_accuracy: 0.7506\n",
      "Epoch 28/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.4754 - accuracy: 0.8355\n",
      "Epoch 00028: val_accuracy did not improve from 0.78400\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.4756 - accuracy: 0.8353 - val_loss: 0.7706 - val_accuracy: 0.7776\n",
      "Epoch 29/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.4600 - accuracy: 0.8393\n",
      "Epoch 00029: val_accuracy improved from 0.78400 to 0.80120, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model3_29-0.80.hdf5\n",
      "195/195 [==============================] - 28s 146ms/step - loss: 0.4601 - accuracy: 0.8394 - val_loss: 0.6982 - val_accuracy: 0.8012\n",
      "Epoch 30/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.4511 - accuracy: 0.8430\n",
      "Epoch 00030: val_accuracy did not improve from 0.80120\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.4511 - accuracy: 0.8428 - val_loss: 1.0080 - val_accuracy: 0.7376\n",
      "Epoch 31/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.4443 - accuracy: 0.8438\n",
      "Epoch 00031: val_accuracy improved from 0.80120 to 0.81090, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model3_31-0.81.hdf5\n",
      "195/195 [==============================] - 28s 146ms/step - loss: 0.4442 - accuracy: 0.8439 - val_loss: 0.6098 - val_accuracy: 0.8109\n",
      "Epoch 32/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.4417 - accuracy: 0.8466\n",
      "Epoch 00032: val_accuracy did not improve from 0.81090\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.4417 - accuracy: 0.8467 - val_loss: 0.7732 - val_accuracy: 0.7825\n",
      "Epoch 33/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.4375 - accuracy: 0.8479\n",
      "Epoch 00033: val_accuracy did not improve from 0.81090\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.4371 - accuracy: 0.8480 - val_loss: 0.8289 - val_accuracy: 0.7722\n",
      "Epoch 34/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.4349 - accuracy: 0.8495\n",
      "Epoch 00034: val_accuracy did not improve from 0.81090\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.4346 - accuracy: 0.8496 - val_loss: 0.7130 - val_accuracy: 0.7963\n",
      "Epoch 35/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.4251 - accuracy: 0.8524\n",
      "Epoch 00035: val_accuracy did not improve from 0.81090\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.4256 - accuracy: 0.8523 - val_loss: 0.7658 - val_accuracy: 0.7869\n",
      "Epoch 36/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.4234 - accuracy: 0.8526\n",
      "Epoch 00036: val_accuracy did not improve from 0.81090\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.4230 - accuracy: 0.8528 - val_loss: 0.9025 - val_accuracy: 0.7674\n",
      "Epoch 37/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.4136 - accuracy: 0.8553\n",
      "Epoch 00037: val_accuracy did not improve from 0.81090\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.4136 - accuracy: 0.8552 - val_loss: 0.6681 - val_accuracy: 0.8063\n",
      "Epoch 38/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.4137 - accuracy: 0.8573\n",
      "Epoch 00038: val_accuracy did not improve from 0.81090\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.4138 - accuracy: 0.8572 - val_loss: 0.8125 - val_accuracy: 0.7778\n",
      "Epoch 39/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.4021 - accuracy: 0.8593\n",
      "Epoch 00039: val_accuracy did not improve from 0.81090\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.4022 - accuracy: 0.8592 - val_loss: 0.9117 - val_accuracy: 0.7663\n",
      "Epoch 40/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.4021 - accuracy: 0.8583\n",
      "Epoch 00040: val_accuracy improved from 0.81090 to 0.84530, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model3_40-0.85.hdf5\n",
      "195/195 [==============================] - 28s 146ms/step - loss: 0.4023 - accuracy: 0.8583 - val_loss: 0.5169 - val_accuracy: 0.8453\n",
      "Epoch 41/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.3989 - accuracy: 0.8601\n",
      "Epoch 00041: val_accuracy did not improve from 0.84530\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.3986 - accuracy: 0.8603 - val_loss: 0.7346 - val_accuracy: 0.7989\n",
      "Epoch 42/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.3965 - accuracy: 0.8604\n",
      "Epoch 00042: val_accuracy did not improve from 0.84530\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.3971 - accuracy: 0.8601 - val_loss: 0.7958 - val_accuracy: 0.7897\n",
      "Epoch 43/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.3900 - accuracy: 0.8652\n",
      "Epoch 00043: val_accuracy did not improve from 0.84530\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.3899 - accuracy: 0.8653 - val_loss: 0.7988 - val_accuracy: 0.7866\n",
      "Epoch 44/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.8646\n",
      "Epoch 00044: val_accuracy did not improve from 0.84530\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.3836 - accuracy: 0.8646 - val_loss: 0.8270 - val_accuracy: 0.7836\n",
      "Epoch 45/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.3881 - accuracy: 0.8646\n",
      "Epoch 00045: val_accuracy did not improve from 0.84530\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.3878 - accuracy: 0.8646 - val_loss: 1.0867 - val_accuracy: 0.7382\n",
      "Epoch 46/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.3794 - accuracy: 0.8677\n",
      "Epoch 00046: val_accuracy did not improve from 0.84530\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.3794 - accuracy: 0.8677 - val_loss: 0.6583 - val_accuracy: 0.8115\n",
      "Epoch 47/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.3724 - accuracy: 0.8705\n",
      "Epoch 00047: val_accuracy did not improve from 0.84530\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.3722 - accuracy: 0.8706 - val_loss: 0.6326 - val_accuracy: 0.8270\n",
      "Epoch 48/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.3743 - accuracy: 0.8688\n",
      "Epoch 00048: val_accuracy did not improve from 0.84530\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.3745 - accuracy: 0.8687 - val_loss: 0.7164 - val_accuracy: 0.8055\n",
      "Epoch 49/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.3685 - accuracy: 0.8697\n",
      "Epoch 00049: val_accuracy did not improve from 0.84530\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.3683 - accuracy: 0.8699 - val_loss: 0.5649 - val_accuracy: 0.8385\n",
      "Epoch 50/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.3636 - accuracy: 0.8741\n",
      "Epoch 00050: val_accuracy did not improve from 0.84530\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.3638 - accuracy: 0.8739 - val_loss: 0.6285 - val_accuracy: 0.8294\n",
      "Epoch 51/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.3600 - accuracy: 0.8742\n",
      "Epoch 00051: val_accuracy did not improve from 0.84530\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.3603 - accuracy: 0.8741 - val_loss: 0.8583 - val_accuracy: 0.7843\n",
      "Epoch 52/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.3578 - accuracy: 0.8742\n",
      "Epoch 00052: val_accuracy did not improve from 0.84530\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.3581 - accuracy: 0.8742 - val_loss: 0.7306 - val_accuracy: 0.8084\n",
      "Epoch 53/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.3515 - accuracy: 0.8762\n",
      "Epoch 00053: val_accuracy did not improve from 0.84530\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.3517 - accuracy: 0.8761 - val_loss: 0.6683 - val_accuracy: 0.8223\n",
      "Epoch 54/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.3529 - accuracy: 0.8762\n",
      "Epoch 00054: val_accuracy did not improve from 0.84530\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.3527 - accuracy: 0.8762 - val_loss: 0.6907 - val_accuracy: 0.8068\n",
      "Epoch 55/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.3511 - accuracy: 0.8764\n",
      "Epoch 00055: val_accuracy did not improve from 0.84530\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.3508 - accuracy: 0.8765 - val_loss: 0.8694 - val_accuracy: 0.7840\n",
      "Epoch 56/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.3438 - accuracy: 0.8799\n",
      "Epoch 00056: val_accuracy did not improve from 0.84530\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.3436 - accuracy: 0.8800 - val_loss: 0.8278 - val_accuracy: 0.7906\n",
      "Epoch 57/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.3016 - accuracy: 0.8932\n",
      "Epoch 00057: val_accuracy improved from 0.84530 to 0.85590, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model3_57-0.86.hdf5\n",
      "195/195 [==============================] - 28s 145ms/step - loss: 0.3015 - accuracy: 0.8933 - val_loss: 0.5141 - val_accuracy: 0.8559\n",
      "Epoch 58/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2892 - accuracy: 0.8981\n",
      "Epoch 00058: val_accuracy did not improve from 0.85590\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2890 - accuracy: 0.8982 - val_loss: 0.5282 - val_accuracy: 0.8504\n",
      "Epoch 59/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2818 - accuracy: 0.9017\n",
      "Epoch 00059: val_accuracy improved from 0.85590 to 0.85790, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model3_59-0.86.hdf5\n",
      "195/195 [==============================] - 28s 145ms/step - loss: 0.2822 - accuracy: 0.9014 - val_loss: 0.5006 - val_accuracy: 0.8579\n",
      "Epoch 60/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2814 - accuracy: 0.9005\n",
      "Epoch 00060: val_accuracy did not improve from 0.85790\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2814 - accuracy: 0.9006 - val_loss: 0.5421 - val_accuracy: 0.8481\n",
      "Epoch 61/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2794 - accuracy: 0.9006\n",
      "Epoch 00061: val_accuracy did not improve from 0.85790\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2792 - accuracy: 0.9007 - val_loss: 0.5408 - val_accuracy: 0.8508\n",
      "Epoch 62/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2739 - accuracy: 0.9040\n",
      "Epoch 00062: val_accuracy did not improve from 0.85790\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2739 - accuracy: 0.9039 - val_loss: 0.5336 - val_accuracy: 0.8522\n",
      "Epoch 63/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2726 - accuracy: 0.9040\n",
      "Epoch 00063: val_accuracy improved from 0.85790 to 0.86340, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model3_63-0.86.hdf5\n",
      "195/195 [==============================] - 28s 145ms/step - loss: 0.2727 - accuracy: 0.9039 - val_loss: 0.4907 - val_accuracy: 0.8634\n",
      "Epoch 64/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2733 - accuracy: 0.9046\n",
      "Epoch 00064: val_accuracy did not improve from 0.86340\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2732 - accuracy: 0.9046 - val_loss: 0.5027 - val_accuracy: 0.8614\n",
      "Epoch 65/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2686 - accuracy: 0.9054\n",
      "Epoch 00065: val_accuracy did not improve from 0.86340\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2686 - accuracy: 0.9055 - val_loss: 0.5090 - val_accuracy: 0.8563\n",
      "Epoch 66/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2699 - accuracy: 0.9052\n",
      "Epoch 00066: val_accuracy did not improve from 0.86340\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2699 - accuracy: 0.9052 - val_loss: 0.5374 - val_accuracy: 0.8527\n",
      "Epoch 67/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2657 - accuracy: 0.9074\n",
      "Epoch 00067: val_accuracy did not improve from 0.86340\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2658 - accuracy: 0.9074 - val_loss: 0.5612 - val_accuracy: 0.8500\n",
      "Epoch 68/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2683 - accuracy: 0.9056\n",
      "Epoch 00068: val_accuracy did not improve from 0.86340\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2682 - accuracy: 0.9056 - val_loss: 0.5471 - val_accuracy: 0.8542\n",
      "Epoch 69/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2657 - accuracy: 0.9060\n",
      "Epoch 00069: val_accuracy did not improve from 0.86340\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2656 - accuracy: 0.9060 - val_loss: 0.4954 - val_accuracy: 0.8631\n",
      "Epoch 70/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2658 - accuracy: 0.9046\n",
      "Epoch 00070: val_accuracy improved from 0.86340 to 0.86810, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model3_70-0.87.hdf5\n",
      "195/195 [==============================] - 28s 145ms/step - loss: 0.2663 - accuracy: 0.9045 - val_loss: 0.4829 - val_accuracy: 0.8681\n",
      "Epoch 71/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2643 - accuracy: 0.9067\n",
      "Epoch 00071: val_accuracy did not improve from 0.86810\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2640 - accuracy: 0.9069 - val_loss: 0.4899 - val_accuracy: 0.8635\n",
      "Epoch 72/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2650 - accuracy: 0.9073\n",
      "Epoch 00072: val_accuracy did not improve from 0.86810\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2653 - accuracy: 0.9072 - val_loss: 0.5181 - val_accuracy: 0.8581\n",
      "Epoch 73/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2616 - accuracy: 0.9079\n",
      "Epoch 00073: val_accuracy did not improve from 0.86810\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2617 - accuracy: 0.9078 - val_loss: 0.5228 - val_accuracy: 0.8574\n",
      "Epoch 74/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2562 - accuracy: 0.9111\n",
      "Epoch 00074: val_accuracy did not improve from 0.86810\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2567 - accuracy: 0.9108 - val_loss: 0.5139 - val_accuracy: 0.8611\n",
      "Epoch 75/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2587 - accuracy: 0.9086\n",
      "Epoch 00075: val_accuracy did not improve from 0.86810\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2588 - accuracy: 0.9086 - val_loss: 0.5706 - val_accuracy: 0.8453\n",
      "Epoch 76/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2561 - accuracy: 0.9096\n",
      "Epoch 00076: val_accuracy did not improve from 0.86810\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2559 - accuracy: 0.9097 - val_loss: 0.5191 - val_accuracy: 0.8594\n",
      "Epoch 77/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2613 - accuracy: 0.9065\n",
      "Epoch 00077: val_accuracy did not improve from 0.86810\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2615 - accuracy: 0.9064 - val_loss: 0.4882 - val_accuracy: 0.8658\n",
      "Epoch 78/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2567 - accuracy: 0.9107\n",
      "Epoch 00078: val_accuracy did not improve from 0.86810\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2567 - accuracy: 0.9107 - val_loss: 0.5592 - val_accuracy: 0.8509\n",
      "Epoch 79/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2566 - accuracy: 0.9111\n",
      "Epoch 00079: val_accuracy did not improve from 0.86810\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2562 - accuracy: 0.9112 - val_loss: 0.5144 - val_accuracy: 0.8605\n",
      "Epoch 80/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2532 - accuracy: 0.9104\n",
      "Epoch 00080: val_accuracy did not improve from 0.86810\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2529 - accuracy: 0.9106 - val_loss: 0.4895 - val_accuracy: 0.8679\n",
      "Epoch 81/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2556 - accuracy: 0.9099\n",
      "Epoch 00081: val_accuracy did not improve from 0.86810\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2556 - accuracy: 0.9099 - val_loss: 0.4984 - val_accuracy: 0.8678\n",
      "Epoch 82/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2567 - accuracy: 0.9098\n",
      "Epoch 00082: val_accuracy did not improve from 0.86810\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2564 - accuracy: 0.9099 - val_loss: 0.5619 - val_accuracy: 0.8555\n",
      "Epoch 83/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2532 - accuracy: 0.9116\n",
      "Epoch 00083: val_accuracy did not improve from 0.86810\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2535 - accuracy: 0.9115 - val_loss: 0.5114 - val_accuracy: 0.8643\n",
      "Epoch 84/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2533 - accuracy: 0.9100\n",
      "Epoch 00084: val_accuracy did not improve from 0.86810\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2530 - accuracy: 0.9102 - val_loss: 0.5042 - val_accuracy: 0.8651\n",
      "Epoch 85/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2532 - accuracy: 0.9111\n",
      "Epoch 00085: val_accuracy did not improve from 0.86810\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2536 - accuracy: 0.9109 - val_loss: 0.5573 - val_accuracy: 0.8531\n",
      "Epoch 86/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2545 - accuracy: 0.9097\n",
      "Epoch 00086: val_accuracy did not improve from 0.86810\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2547 - accuracy: 0.9096 - val_loss: 0.5333 - val_accuracy: 0.8605\n",
      "Epoch 87/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2463 - accuracy: 0.9124\n",
      "Epoch 00087: val_accuracy did not improve from 0.86810\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2462 - accuracy: 0.9125 - val_loss: 0.5121 - val_accuracy: 0.8645\n",
      "Epoch 88/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2469 - accuracy: 0.9134\n",
      "Epoch 00088: val_accuracy did not improve from 0.86810\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2470 - accuracy: 0.9134 - val_loss: 0.5187 - val_accuracy: 0.8627\n",
      "Epoch 89/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2499 - accuracy: 0.9106\n",
      "Epoch 00089: val_accuracy did not improve from 0.86810\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2499 - accuracy: 0.9107 - val_loss: 0.5168 - val_accuracy: 0.8628\n",
      "Epoch 90/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2448 - accuracy: 0.9122\n",
      "Epoch 00090: val_accuracy did not improve from 0.86810\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2446 - accuracy: 0.9123 - val_loss: 0.5122 - val_accuracy: 0.8639\n",
      "Epoch 91/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2454 - accuracy: 0.9127\n",
      "Epoch 00091: val_accuracy did not improve from 0.86810\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2454 - accuracy: 0.9127 - val_loss: 0.5102 - val_accuracy: 0.8649\n",
      "Epoch 92/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2440 - accuracy: 0.9139\n",
      "Epoch 00092: val_accuracy did not improve from 0.86810\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2439 - accuracy: 0.9140 - val_loss: 0.5104 - val_accuracy: 0.8641\n",
      "Epoch 93/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2465 - accuracy: 0.9126\n",
      "Epoch 00093: val_accuracy did not improve from 0.86810\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2467 - accuracy: 0.9125 - val_loss: 0.5185 - val_accuracy: 0.8630\n",
      "Epoch 94/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2477 - accuracy: 0.9114\n",
      "Epoch 00094: val_accuracy did not improve from 0.86810\n",
      "195/195 [==============================] - 28s 143ms/step - loss: 0.2476 - accuracy: 0.9114 - val_loss: 0.5174 - val_accuracy: 0.8647\n",
      "Epoch 95/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2485 - accuracy: 0.9130\n",
      "Epoch 00095: val_accuracy did not improve from 0.86810\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2485 - accuracy: 0.9130 - val_loss: 0.5254 - val_accuracy: 0.8620\n",
      "Epoch 96/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2460 - accuracy: 0.9128\n",
      "Epoch 00096: val_accuracy did not improve from 0.86810\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2460 - accuracy: 0.9127 - val_loss: 0.5124 - val_accuracy: 0.8654\n",
      "Epoch 97/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2454 - accuracy: 0.9134\n",
      "Epoch 00097: val_accuracy did not improve from 0.86810\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2454 - accuracy: 0.9134 - val_loss: 0.5062 - val_accuracy: 0.8655\n",
      "Epoch 98/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2442 - accuracy: 0.9128\n",
      "Epoch 00098: val_accuracy did not improve from 0.86810\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2441 - accuracy: 0.9128 - val_loss: 0.5155 - val_accuracy: 0.8645\n",
      "Epoch 99/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2392 - accuracy: 0.9147\n",
      "Epoch 00099: val_accuracy did not improve from 0.86810\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2394 - accuracy: 0.9147 - val_loss: 0.5068 - val_accuracy: 0.8655\n",
      "Epoch 100/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2443 - accuracy: 0.9137\n",
      "Epoch 00100: val_accuracy did not improve from 0.86810\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2445 - accuracy: 0.9137 - val_loss: 0.5099 - val_accuracy: 0.8650\n",
      "Epoch 101/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2448 - accuracy: 0.9136\n",
      "Epoch 00101: val_accuracy did not improve from 0.86810\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2448 - accuracy: 0.9135 - val_loss: 0.5109 - val_accuracy: 0.8643\n",
      "Epoch 102/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2467 - accuracy: 0.9120\n",
      "Epoch 00102: val_accuracy did not improve from 0.86810\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2467 - accuracy: 0.9119 - val_loss: 0.5141 - val_accuracy: 0.8636\n",
      "Epoch 103/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2415 - accuracy: 0.9145\n",
      "Epoch 00103: val_accuracy did not improve from 0.86810\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2416 - accuracy: 0.9145 - val_loss: 0.5122 - val_accuracy: 0.8637\n",
      "Epoch 104/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2450 - accuracy: 0.9127\n",
      "Epoch 00104: val_accuracy did not improve from 0.86810\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2452 - accuracy: 0.9127 - val_loss: 0.5127 - val_accuracy: 0.8637\n",
      "Epoch 105/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2438 - accuracy: 0.9144\n",
      "Epoch 00105: val_accuracy did not improve from 0.86810\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2435 - accuracy: 0.9144 - val_loss: 0.5129 - val_accuracy: 0.8636\n",
      "Epoch 106/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2473 - accuracy: 0.9123\n",
      "Epoch 00106: val_accuracy did not improve from 0.86810\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2472 - accuracy: 0.9123 - val_loss: 0.5113 - val_accuracy: 0.8641\n",
      "Epoch 107/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2412 - accuracy: 0.9147\n",
      "Epoch 00107: val_accuracy did not improve from 0.86810\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2412 - accuracy: 0.9147 - val_loss: 0.5136 - val_accuracy: 0.8635\n",
      "Epoch 108/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2461 - accuracy: 0.9138\n",
      "Epoch 00108: val_accuracy did not improve from 0.86810\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2453 - accuracy: 0.9139 - val_loss: 0.5126 - val_accuracy: 0.8637\n",
      "Epoch 109/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2437 - accuracy: 0.9148\n",
      "Epoch 00109: val_accuracy did not improve from 0.86810\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2435 - accuracy: 0.9148 - val_loss: 0.5131 - val_accuracy: 0.8638\n",
      "Epoch 110/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2428 - accuracy: 0.9140\n",
      "Epoch 00110: val_accuracy did not improve from 0.86810\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2427 - accuracy: 0.9140 - val_loss: 0.5118 - val_accuracy: 0.8638\n",
      "Epoch 111/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2440 - accuracy: 0.9140\n",
      "Epoch 00111: val_accuracy did not improve from 0.86810\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2442 - accuracy: 0.9140 - val_loss: 0.5127 - val_accuracy: 0.8638\n",
      "Epoch 112/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2459 - accuracy: 0.9122\n",
      "Epoch 00112: val_accuracy did not improve from 0.86810\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2460 - accuracy: 0.9121 - val_loss: 0.5135 - val_accuracy: 0.8633\n",
      "Epoch 113/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2430 - accuracy: 0.9147\n",
      "Epoch 00113: val_accuracy did not improve from 0.86810\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2429 - accuracy: 0.9148 - val_loss: 0.5138 - val_accuracy: 0.8636\n",
      "Epoch 114/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2464 - accuracy: 0.9145\n",
      "Epoch 00114: val_accuracy did not improve from 0.86810\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2462 - accuracy: 0.9145 - val_loss: 0.5128 - val_accuracy: 0.8638\n",
      "Epoch 115/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2433 - accuracy: 0.9149\n",
      "Epoch 00115: val_accuracy did not improve from 0.86810\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2433 - accuracy: 0.9149 - val_loss: 0.5123 - val_accuracy: 0.8640\n",
      "Epoch 116/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2432 - accuracy: 0.9134\n",
      "Epoch 00116: val_accuracy did not improve from 0.86810\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2430 - accuracy: 0.9134 - val_loss: 0.5144 - val_accuracy: 0.8631\n",
      "Epoch 117/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2433 - accuracy: 0.9130\n",
      "Epoch 00117: val_accuracy did not improve from 0.86810\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2432 - accuracy: 0.9130 - val_loss: 0.5135 - val_accuracy: 0.8640\n",
      "Epoch 118/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2467 - accuracy: 0.9131\n",
      "Epoch 00118: val_accuracy did not improve from 0.86810\n",
      "195/195 [==============================] - 28s 143ms/step - loss: 0.2466 - accuracy: 0.9131 - val_loss: 0.5135 - val_accuracy: 0.8638\n",
      "Epoch 119/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2416 - accuracy: 0.9146\n",
      "Epoch 00119: val_accuracy did not improve from 0.86810\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2416 - accuracy: 0.9146 - val_loss: 0.5127 - val_accuracy: 0.8642\n",
      "Epoch 120/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2444 - accuracy: 0.9138\n",
      "Epoch 00120: val_accuracy did not improve from 0.86810\n",
      "195/195 [==============================] - 28s 142ms/step - loss: 0.2446 - accuracy: 0.9138 - val_loss: 0.5135 - val_accuracy: 0.8637\n"
     ]
    }
   ],
   "source": [
    "model_3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "patience = 50\n",
    "base_path = '/home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/'\n",
    "checkpoint_file_name = base_path + 'CIFAR_model3' + '_{epoch:02d}-{val_accuracy:.2f}.hdf5'\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(checkpoint_file_name, monitor='val_accuracy', verbose=1, save_best_only=True)\n",
    "early_stop = EarlyStopping('val_accuracy', mode='max', patience = patience)\n",
    "reduce_LR = ReduceLROnPlateau(monitor='val_accuracy', mode='max', factor=0.1, patience=int(patience/3), verbose=1)\n",
    "\n",
    "callbacks = [model_checkpoint, early_stop, reduce_LR]\n",
    "\n",
    "epochs = 300\n",
    "batch_size = 256\n",
    "\n",
    "#https://keras.io/api/preprocessing/image/#flow-method\n",
    "\n",
    "history_3 = model_3.fit(data_generator.flow(X_train, y_train, batch_size),\n",
    "                    steps_per_epoch = int(len(X_train)/batch_size),\n",
    "                    epochs = epochs,\n",
    "                    callbacks = callbacks,\n",
    "                    validation_data = (X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7AAAAEWCAYAAABfZ3sYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdd5xU1fn48c+ZPjvbC70sIB0pigiKih0QWywBNZbYoibfmHw10fyiMSYmJl9NTGI0sceCvSsqakAsKEUBqdJhWcoWtk+f8/vj3NmdXXaX3WWH3YXn/fK+7sy9d+49U1jnmeec5yitNUIIIYQQQgghRGdn6+gGCCGEEEIIIYQQLSEBrBBCCCGEEEKILkECWCGEEEIIIYQQXYIEsEIIIYQQQgghugQJYIUQQgghhBBCdAkSwAohhBBCCCGE6BIkgBVCCCHaSCmVr5TSSilHC469Uin12cFolxBCCHGokgBWCCHEYUEptUUpFVJK5TbYvswKQvM7pmX12uJTSlUppeZ0dFuEEEKIzkgCWCGEEIeTzcCs+B2l1JGAt+Oas48LgSBwhlKq58G8cEuyyEIIIURHkwBWCCHE4eQZ4PKE+1cATyceoJTKUEo9rZQqUkptVUr9Wills/bZlVL3KaWKlVKbgLMaeezjSqmdSqkdSqnfK6XsrWjfFcC/gBXApQ3O3Vcp9ZrVrhKl1IMJ+65VSq1RSlUqpVYrpY6ytmul1BEJxz2llPq9dXuKUqpAKfVLpdQu4EmlVJZS6h3rGnut230SHp+tlHpSKVVo7X/D2r5SKXV2wnFO6zUa24rnLoQQQuyXBLBCCCEOJ18C6Uqp4VZg+X3g2QbH/APIAAYCJ2EC3qusfdcCM4BxwHhMxjTRf4AIcIR1zBnANS1pmFKqHzAFeM5aLk/YZwfeAbYC+UBv4AVr30XAXdbx6cA5QElLrgn0ALKB/sB1mO8FT1r3+wF+4MGE458BUoCRQDfgr9b2p4HLEo6bDuzUWi9rYTuEEEKIFpHuQkIIIQ438SzsJ8BaYEd8R0JQO05rXQlUKqXuB34APA5cDDygtd5uHf9HTNCJUqo7MA3I1Fr7gWql1F8xgeG/W9Cuy4EVWuvVSqky4M9KqXFa62+ACUAv4FatdcQ6Pl4Q6hrgz1rrxdb9Da14LWLAb7TWQeu+H3g14fW4B5hn3e5pPb8crfVe65BPrPWzwB1KqXStdQXm9XqmFe0QQgghWkQCWCGEEIebZ4AFwAAadB8GcgEXJtMZtxWT8QQTRG5vsC+uP+AEdiql4ttsDY5vzuXAowBa60Kl1CeYLsXfAH2BrQnBa6K+wMYWXqOhIq11IH5HKZWCyapOBbKszWlWYN8XKE0IXmtZ7f0cuEAp9Tom0P1pG9skhBBCNEm6EAshhDisaK23Yoo5TQdea7C7GAhjgtG4ftRlaXdiArnEfXHbMQWYcrXWmdaSrrUeub82KaWOAwYDtyuldlljUo8FZlnFlbYD/ZootLQdGNTEqWswXX7jejTYrxvc/19gKHCs1jodODHeROs62UqpzCau9R9MN+KLgIVa6x1NHCeEEEK0mQSwQgghDkdXA6dorasTN2qto8BLwD1KqTSlVH/g59SNk30J+B+lVB+lVBZwW8JjdwJzgfuVUulKKZtSapBS6qQWtOcK4ENgBDDWWkZhgs9pwCJM8HyvNdWORyl1vPXYx4BblFJHK+MIq90Ay4BLrOJTUzFjepuThulGXKaUygZ+0+D5vQc8ZBV7ciqlTkx47BvAUZjMa8PMthBCCNEuJIAVQghx2NFab9RaL2li90+AamATZpzpbOAJa9+jwAfAcuBr9s3gXo7pgrwa2Au8AjQ7HY5SyoMZW/sPrfWuhGUzprvzFVZgfTamONQ2oAAzVhet9cvAPVY7KzGBZLZ1+p9ajyvDVDV+o7m2AA9gphUqxhS8er/B/h9gMtRrgT3AzfEd1rjfVzFdsxu+LkIIIUS7UFo37D0khBBCCNF6Sqk7gSFa68v2e7AQQgjRBlLESQghhBAHzOpyfDUmSyuEEEIkhXQhFkIIIcQBUUpdiyny9J7WekFHt0cIIcShS7oQCyGEEEIIIYToEiQDK4QQQgghhBCiS+hyY2Bzc3N1fn5+RzdDCCGEEEIIIUQSLF26tFhrndfYvi4XwObn57NkSVMzHwghhBBCCCGE6MqUUlub2iddiIUQQgghhBBCdAkSwAohhBBCCCGE6BIkgBVCCCGEEEII0SV0uTGwjQmHwxQUFBAIBDq6KUnl8Xjo06cPTqezo5sihBBCCCGEEAfdIRHAFhQUkJaWRn5+Pkqpjm5OUmitKSkpoaCggAEDBnR0c4QQQgghhBDioDskuhAHAgFycnIO2eAVQClFTk7OIZ9lFkIIIYQQQoimHBIBLHBIB69xh8NzFEIIIYQQQoimHBJdiIUQQgghRNeitSYc1QQiUYLhGMFIFJfdRk6qG7ut/X60j0RjVIei1IQiVAejVAcjVIcihCIxUt0OUj0OUt0O0txOfG47Dnvr8ztaa4KRGDGtsSmFTSnsNoVN1SUgYjFNOBYjHNVEojFCUXM7GtXY7QqnXeG02XA6bLW3Y1pTEYhQ7g9TVhOi3B+uXUKRGB6nHY/Tjtdpx+O0WfdtOGw2lAKFIp7/sCmFzQZep500j5NUtwOXY9/nqrWmwh+hqCpIsbVUBSKkehyke5yke52kexzW2ondpqgKRKgIhKkIhKkMRKjwh6kIRLDbICvFRbbPRVaKiyyfC5/LXvuahCIxSqtDFFcFKakOUVIVpLQ6hFIKl8OG227D5bAWuw27XRGOxAhGYgTCUYLW7WAkSjSqzWMcNtxOu1k7zNpuVzT1ifI47WR4nWSmOMnwOvE67fWSRtGYpqQ6yJ6KIEWVQfZUBiipDqE12G0Ku1LYbAq7AptNoZQiFtNEYppoLGbWUXNfKcxnzePA5zafu/hn0OOwY7cpHHZVe16HzbQ98b3RgNaAhpjW1ITNZ7oyEKEqGKEqEKE6GKEmFMFhN6+HK/5aOM1r6nbaGNMns02f9c5AAth2UFZWxuzZs7nxxhtb9bjp06cze/ZsMjMzk9QyIYQQQjQlFtMUVwfZXR5kZ7mf3RUBiqpCpLrtZPvc5PjMF+/4kuKyE4lp/OEogVAUfzhKjbW2KUWvDA+5qW5szQRf4WiMbaU1bCqqZktxNZXByD5fcqPWl1+H9WXWZbfhsJsvsy6HDYdN4bSbQMdlbY/ftttsTX5RD0VjtYFGVfwLbyBCZTCMQpHisuNzO+qtU1x289hIjFBUE47GCEVihK3gy+O04XM5SHHb8bkceF1mbbcpiquC7K4IsKfSrHdXBNhTEaS0JlQbfGi9bzttCrJ9brqluemW7iYv1awBKgORhCVc+6U9HI0RjWliuu41jL+OoUisVZ8Lj9NGqtuB22HH66ofHHqddqIxTWWw7rWrqm1DI08GrEASYo3v7lBuh400j4M0jxOP005ZTYiSqhChaOtes9Zw2W1kpjgJhKNUBCJJu05buew2E5x7HVQFIhRXBTvle3egVt99pgSwjVFKTQX+BtiBx7TW9zbY3x94AsgDSoHLtNYFyWxTMpSVlfHQQw/tE8BGo1HsdnuTj5szZ06ymyaEEEI0K2p9wa/LZkQJWNmwcFRjU1iZJFWbwbEpRSAcpbQ6RFlNmNLqEHtr4ksYp02R7jXZjHSPtfaa7A1AOJ6ZiJogIxzTaK3xueqyYYmZMYdNUWp9sS6tDtXL1FQFI8RimqjWRGPU3o5nQEygZQVfkfjtGCVVIXZXBIi04pupTe0/CHHaFT0yPPTM8NI700uvTA+RqGZjURWbiqrZVlqzzzUdNpNxqV3bbdiUIqatNltZu2g7f4v2uey1r7FSymQmgxGqQ9H9XkspcNpsLQp0XA4bPdI9dE93M7xXOjk+l8kU1suUmQxRMBK1slxmKaoMsmZnBcVVIQDS4tlSj5M0j4OeGR5SPQ6TnbNev/jn1WFT2O2KFKcDn7suKE91O0hxOXA5FNXBaG3WqtJ6/lXWEghHrSWGPxSlMhChqDKITSnSPA56ZXpI86TVy6jZbeZ905ragDoW08Q0OOzWDw+1a5NVtNkUUes9DkfNv4uQ9blVKDK8DjJTXNa/o7pModNuIxhvX21bzQ8q0Zhpg8nW6dp1TENNKEpVQvBfYf0YEAhHGdEzndw0F3mpbnLjS5qLNI+T6mA8sxqmwm9lXP1hwlFNWm1G1vw7j78/Ma3N34XqMKU1IcpqQpRWh9lbHcLjNNn23FQ3OakuclNd5PjcZPlcoCEYjZofTiLmtQlZ/xZcdhseZ0JGMZ5ltSnC0ZiVzTd/w4IRcz8ca/xzqjUEwtHarHZZTV2Gu8IfJtXtoFu6+TElL81T+4NKbqobpUwGNBrTxGLWbW3ec4fNVv/ftLWOxjTVoWjt56zSypZWBiImi5zww0vd2rQ9nkOOJ4eVMlt8bjupVu8B8+/DSarHgddpJxKr/3qEajPWMTyOpmOUzi5pAaxSyg78EzgdKAAWK6Xe0lqvTjjsPuBprfV/lFKnAH8EfpCsNiXLbbfdxsaNGxk7dixOp5PU1FR69uzJsmXLWL16Needdx7bt28nEAjw05/+lOuuuw6A/Px8lixZQlVVFdOmTWPy5Ml88cUX9O7dmzfffBOv19vBz0wIIUR7qwlFKCwLUO4P4bLbE7q8mS+zbqcdh01ZXz5NEJH4RbSsJsyOMj+F1rKjLEBhmZ9d5QHCzQQT4ViMcETXBnDxDFp7BUVKma6CmV4nkZim3B+mMhBOaubCpsDncpjue7Z4t01qu/TFg4XEDKXLYcPndnBEXio9MjxmSffU3s7xuakJRWoD5dKqEKU1JnCuCkTqMnFWZs5r3Y5ENTsrArXvS2GZn0WbS9lVEcCuFPm5KQzpnsbUUT0YmJfKwDwfA3N9ZHidLa5x0bALajzgCUfrBz9NcdhVbbYt1Qq2GqO1CaBqrODOZjNZYJfdhtOhaoNFpcwX8ppQBH8oWvvFvCYUJRyNkZvqpke6h3Sv44DreMSs7pdSD6QB76E8tWLrn5vTbiPFlYSmtBOHXZHhtZFxSL9vyZfMDOwEYIPWehOAUuoF4FwgMYAdAfzMuj0PeONAL/rbt1exurDiQE9Tz4he6fzm7JFN7r/33ntZuXIly5YtY/78+Zx11lmsXLmydrqbJ554guzsbPx+P8cccwwXXHABOTk59c6xfv16nn/+eR599FEuvvhiXn31VS677LJ2fR5CCCGSLxbT7Cjz893uSjbsqbKCTSuwKfdTVhNu1+vl+Fz0yvTSLycFj7PxX9S11ib4sAKQePYnngnyWFkwT8K4MY/TBCnaGmcVszJK8SyOy2Ej2+esHd+W7nHu03U2FtNUhaysjZWxUVDbHTY+3sthU4AyWa6ELpnxJRzRZPucpltvqqu2a29miqtdx0rGpVkZpP45vgM+V/wHgvZop82mcNvsuJM8AEwpZWW17CYb1gy7TdW+XsnUXLdsIcThJZl/AnsD2xPuFwDHNjhmOXABppvx+UCaUipHa12SeJBS6jrgOoB+/folrcHtZcKECfXmav373//O66+/DsD27dtZv379PgHsgAEDGDt2LABHH300W7ZsOWjtFUII0TZaa5Zs3cvKHeWs21XJut2VfLerkupQtPaYdI+DXpleemV6Oap/prmd4SXL56otRhKKRmu7ecW7ycWLr8S/tscLsmR4ndb5PPTK9DYZtHYGNpsyRV88Tsjq6NZ0jGQE2EIIcThLZgDb2F/shv1abgEeVEpdCSwAdgD7jObWWj8CPAIwfvz4ZjsjNZcpPVh8vrpfbOfPn89HH33EwoULSUlJYcqUKY3O5ep2u2tv2+12/H7/QWmrEEKI1otEY7z77U4enr+RtbsqAchKcTK0RxoXje/LkO5pDO2RyuDuabXjPoUQQghx4JIZwBYAfRPu9wEKEw/QWhcC3wNQSqUCF2ity5PYpqRIS0ujsrKy0X3l5eVkZWWRkpLC2rVr+fLLLw9y64QQQrSXQDjKy0sLeGTBRraX+hncLZX7LhrDiUNyyUt1y/g8IYQQIsmSGcAuBgYrpQZgMqszgUsSD1BK5QKlWusYcDumInGXk5OTw/HHH8+oUaPwer107969dt/UqVP517/+xejRoxk6dCgTJ07swJYKIYRoi4pAmGe/3MoTn22huCrI2L6Z3HHWCE4b3l3G5gkhhBAHkdKNTcDVXidXajrwAGYanSe01vcope4Glmit31JKXYipPKwxXYhv0loHmzvn+PHj9ZIlS+ptW7NmDcOHD0/Kc+hsDqfnKoQQraV13RQF8aksaqeRsP53VzvtQUJhovj9vTVhCvbWULDXz469/trbeyrN/5pOGJzLjVOOYOLAbMm2CiGEEEmilFqqtR7f2L6k1rHTWs8B5jTYdmfC7VeAV5LZBiGEEJ2L1pqS6hBbS6rZUlzD1pJqqoJRK6DUVoCJNXdifP5Ca0oZKwjVmMCzImDN2Zcwd19r5vVsisOm6JnpoU9mCicNyaN3lpfThndnVO+MAz63EEIIIdouyYXYhRBCdDVaayoCEXZXBNhdEWBXeYA9lUF2lZv7Zf4waW4HGV4n6V4nGdaSmeLE47TjD0Xxh6N1a+t2UWWQLSXVbC2poSpYV68vPpenUtTO5WmzKWwKczsh02nmgTS37cpM35GZYqryZia0JdXjwGZN8h6v3mv9Z80VWneN+JyhdqVI9zrpk+Wle7pHqsd2FqEa8JdCWi+w2Tq6NR1Pa6guhlgY86E2UxAB5rbLZxYhhDhESQArhBBdVDASZf3uKlbvrKC4KojLbsPlMPN7Jt5uKhCLaU1pdYidZX52lgfYWR6gsNzPrvIANQnTwMRleJ10T3eTmeJiZ3mAtbsqqfCHqQzuUzy+HpfdhsdpI9vnon+Oj2Pys+mfk0J+jo/+OSn0yUrB5ZDAJKm0rov8O6tYFPZugd2rzLJnFexeDaWbAA0OL+QNgbxhkGut84ZBVj7YO+HXmUA5FCyBgsXgy4Wxl4HT07ZzVe2BzQtg0zzYtADKtzV9rN0FR14Ex/4Ieo5u2fn3boWybRANQsRaoiGIBCAahv7HQfd2mOUhWAmlm80PEp4Ma8kEd3rr38NoBCJ+CPshXGOt/abNibcjQbA7weEGuxscLnB4rNtucHrBmVK3tjvr/q3EoqbNgXIIVph1oMK8xqndIK0HpOSArZGprKJhKC+A8u1Qth0qC802rQFdf62UaZPDY9qRuLY5rOcRsJ5nwHreAdBRsDnNMXaHWducpj12l/Wcnea23Z3wOrgSloRttoT3oHaIoU64vR/xH1NUwg8qWpvnHYuYH11i0br7yma1z2nabXdZz8Oq3K5jZom3IX6/4WtYr71toGwJr2H89XSa7fF2xKLWtaMJt2P120ViG2MNjrH2KWVe7/j77fDU/8zFX6/4ex7/DGtt2hP/FVfZ6pZYtK5dsUjdWkcTPhMNPiN2p/nsdvb/LzShE/7FF0KIw4fWmppQlDJ/mLKaEBV+EwwqK/to1gCK6mCEtbsqWLOzktWFFWwsqmqX7rJKQbc0Nz0zvAzrkcaUId3omeGhR4aH7ukeuqe76Z7uaXK+0Ug0RmUgQrk/TCASxeu043XZzdppx2GX4LRDxGKw+RNY+hSsm2O+HHqz9l1Su0G34dB9FGQPbPzLeLLUlMJ3H8Dad2DjPAhXWzuUaUv3kTD6YhMAlmyEorWw5TNY8WLdORwec1yP0SZg6zkGuo1sXbDoLzPB894tUFMCw882r0tLaW0eu/0ra1lkgnC0eS5o+OwBmHIbjJ65/2AtEoRNn1gB63zYs9ps92TCgBNg4g0mwGnsS3zRWlj2PCx7DvKtY4dMrf++ag27VsDad2HNO+bHgv3JPwEmXAdDp++//RWF5jUo2WAC1tKN5oeIqt1NP8aVZgJap6fxIA/ri308WI2G9t/mtlB2E8gChBqfYWKf4315kNYdfN1MoFu2HSp3su/skVAvwIvf1toEG21pa1seJzoZ6wcMMAFro5+bJPhVYZftrZHUIk7JIEWcDp/nKkRnoLWmKhihrCZsFn+IvTVhymtC1n2zvdxf/36FPwyA22HD7bThdthr1y67ojoUrX1cONq6v8M90j0M75nGiF7pDO9pll4ZXsKxGKFIjHC0bh2MxJr9YTrL56JbmhunBJltV7bdBILu1P0fGwmZjNym+VC9B4aeBYNONr+Gt5fK3SZ4+fo/JqjyZsHI75kvSP5S8O81S038dqmVPcBkObsNhx6jTECbNwyy+kN6n/bLclYUWoHT2yYY1VHTPXjoVOh1FHQfAXnDwZXS9DkCFVD8nQnWdq+CnStg17cQtGbiU3bIGwrpveqyTHYry+SwMk1Vu62gdSsEyuqf35UGJ/wMJt5oBYpN0BrWfwjz/wiFX5tt7nToMx76HmuW3kfDjqXw8W+h8BvIHQqn/NoEyYnZj2jY/OCw8jUTVAbLzXvWbyIMnAIDTjLBeUt+YPCXwTfPwFf/NhnArHyTke02HNa9Z17/8u0me9NvEgw7C3ocaWWDrMxdPGOpY7DqNVj0mMn8ZvSFY66Go66AlOy66235zLR/03zz3sSl9oCcQZA9ALIHmR8mfLkms+kvs7Ka5eY9CJSb4LReJi9h7XDVz5YmZiudXvP5rb1tbbe7TDaqNrOckGGuzdgmZHDji46BJ90E1W5r7Uk3t6NhqNplMuOVu8xnKb64081rlNm3/jqjj3lNm1KbUbbaE88kx6ImqK+XnU0x54oHv7GIWeKZzWjYZDujIfM3J5qwRIJmfzTUyBK2GtNI1/SWaOyHB5vdWhIymza7ua1j5nlHQ1Z7w3Vta5hljC+17Wn4+aCuva2lY/Vfv8RMsVLm74nNZtbKZtqvEu43zIqi6o4h8XnEM9JB67MXrMuwxgNXhzchQ5uQqa39oaORbG88g2xz7HtbJ2S8G35Ojr6qc/ZesTRXxEkC2C7mcHquQrQHfyjKnkozhrO4MkgoGiMa00SsyrORmCZqBXql1SGKqoKUVIUoqbbWVSFC0ViT509x2clKcdWOAc1McdaODbUpRTAcIxCJEgzHCEaiBCMmuEx1O8hIcZIZf5zXRUaKkzSPA4UyVXOhtpJuTGvcDjtDe6SR7XMdvBdQNG/nCnjkJPPFInewCTB6joGeY01A4Mkw2bNN882y5XOTZVQ2cPpMhsebDSPPg1EXmmBif+M8tTZffkJVJggIVUGwCqqLYOWrJtsai5iM2dFXwrAZzWcjwwEoXge7Vlrdd781t/2ldccoO6T3NsFsZn8rqO0Nqd1N5ik13pUyoe1hv8m6Fa83mbiSjSbTt3O52Z8zGIbPgGFnQ69xBz6+NZ4F3bXCCmhXmGxqwy/w8cWXZwK7rHzrOVm3lYJ5f4R175rA47S7YNQF9b/Eaw0bPjKB646lkNEPJt0IA040QX9jQabWsOYt+Ph3ULLeBLan3GGOXfkqrH7LvObudBNQjvyeOV9bux2DCQ7WvQtfPgzbFpptDg8MOsVcY8hUE0y2RCxqgt9F/zbdmR0eGDrNdD0u/MZ8kXammO7GA6dA/mTT1buLZniEEB1LAtgkKysrY/bs2dx4442tfuwDDzzAddddR0pKM780J+jo5yrEwaS1JhiJUWNNi+IPW+tQlMpghKpAhMpAmMpAhKpghArrfnFVkD2VQYoqgvsdn5nI5bCRl+omJ9VFjs9FTqqb3FQ32T4nmSkuslJcVrBp7md4nTJ283D3xo2w6g047scmA7hzOVTsqNvvTjddCsEEbAOn1H25d3phw8ew8hUTGIRrTFA46nvQY0z9rE7VbpNZrdptMlW6iR9VvNkw9hITuOYObvvz0tpcq2gdlFnjI/duNbf3bjXZp4aU3XS79eWZzG759vr703pCzhEw8CQYfo7JkHZmmxfAB78y72vv8XDmH6DvBPOezf8j7FhiAtcTb4Exs0x2sCWiEVj+vDlH/LPiTDHB4KgLYNCpBxa0NqVwmenWOuDEAw8q96yBRY+Yz37uEPOeDpxiXqeWvg5CCNEMCWCTbMuWLcyYMYOVK1e2+rH5+fksWbKE3NyW/QLa0c9ViLYIRqIEQrF6FWn94SiBcJTKQISiygC7K4LsqV0H2VMRYG9NiJYO8XQ7bKR5HKR5nOT4XHRLd9MtzUNemptuaWYMZ26qG7fThsNmqtA6bDZrrXA6bPhc9uTP7RmLwid/hjEzTZc60XVVFcFfR8BRl8NZ99ffvmu5CWbLtkOfY8wX/Iw+TZ8rWAXfvQ/fvmwCpJjVlc/utjKcCUu8u7IrFdxpVtXZVBMs9xjVfDfF9hL213WdrLS6UlbFu1LuMWM1c44wXUdzB5tuo+605LervcWisPwF+O/vTPCXNQD2bjaZ2RNvgTGXtD1gCwfM++3ywZAzJVMphBAJOmwe2MPFbbfdxsaNGxk7diynn3463bp146WXXiIYDHL++efz29/+lurqai6++GIKCgqIRqPccccd7N69m8LCQk4++WRyc3OZN29eRz8VIdqkOhhhc3E1BXv97Cjzs2Ovnx1lNewo81NYFqC0ev/FNuw2RW6qi+7pHnpnehjXL5PsFBcpbjspTjspbgcpLjs+lwOvy06q20Gax2Gtu1AmdNM8+ORe2PIpXPlul60AKDDFkaIhU9gmUWoeHHGaWVrKnQpHXmgW/14TBKZ2N12QO+NnxOm1xjQe4j/C2Oww7lLTxfuLf5gfF47/KYy99MAzjU4PHPWD9mmnEEIcRg69APa920x3n/bU40iYdm+Tu++9915WrlzJsmXLmDt3Lq+88gqLFi1Ca80555zDggULKCoqolevXrz77rsAlJeXk5GRwV/+8hfmzZvX4gysEMkSCEfZUlLN5qJqqoIRXA6r8JDDZt02U7IUVQbZXFzNpuJqNhdXsbm4mt0VwXrn8jrt9M7y0jvTy+g+mfRM9+BzO2or03qcdjxOG16nHZ/bQbd0Nzk+9+Ex7+aKlwEFWz83lVTHzOzoFiVfLAqvXGX+Ng87C4afa8b/deU5PaNhWPyYGUvY3l1h49WBRefh8pkKwlNu6+iWCCHEYe/QC2A72Ny5c5k7dy7jxn3LikgAACAASURBVI0DoKqqivXr13PCCSdwyy238Mtf/pIZM2ZwwgkndHBLxeEoGtMUlvnZVFzNpiITfG4urmZTUTWF5f5WTaOW7XMxINfHCYPzGJDrY0Cuj75ZKfTO8pKV4kx+V9yuKFRjpgsZdynsWQtzf22KqHgzO7plyfXBr2D1m6Yr7Zf/MpmstF6mCuuIc6zCRQdx6pb2sPpN02X2nL93dEuEEEKIw8qhF8A2kyk9GLTW3H777Vx//fX77Fu6dClz5szh9ttv54wzzuDOO+/sgBaKQ5XWmspghLLquqleTLa0ik1FJkjdXFJNKFJX/CXN7WBAno/x+VkMzO3LgDwfA3N9pHuchKJ1FXNDkVjt7dw0NwNyfGSktOO0H4eLdXNMxdjRM814wEdPhnn3wPT/6+iWtVwsZsY5pvds2fFfPQJf/Qsm3gRT/2CmzfjufVNx9ev/mIqmKbkw9Y9mvs+u4qt/m3GdR5ze0S0RQgghDiuHXgDbAdLS0qisNJNdn3nmmdxxxx1ceumlpKamsmPHDpxOJ5FIhOzsbC677DJSU1N56qmn6j1WuhCLhrTWbCutYXlBOasKyymvCe9TAKkmZO6X+838o9FGKh7ZbYr+2SkMyPVx4pBcBualMjDXx4A8H3mpbsmUHkzfvmyqzPY/3nSfPeYa0w117KXQa2xHt27/Nn8KH95hpsw4/qdwyp3NzyH33Vx4/5cwZBqc8TuzzZtpuk2PmWkKF234ED7/G7x9s8nEZvY9OM/lQOxYCgWLYOqfunY3aCGEEKILkgC2HeTk5HD88cczatQopk2bxiWXXMKkSZMASE1N5dlnn2XDhg3ceuut2Gw2nE4nDz/8MADXXXcd06ZNo2fPnlLE6TAVjESp8EeoCITZsKeKFQVlrCgoZ0VBOeV+U4nUZbeR5XPWjh+NjyXtke7E47KT4XWSZc0lmpnirJ3uJSfVTZ8sL067fMnucNUlZt7IiTfWBT0n/z8zDcW7/wtXf9h5g6E9a+Gj35jMaXpvGHGeCTq3L4aLnoS0Hvs+ZtdKM+61+0i44LHGuwi7U2Hk+dDrKPjnsfDeL2HW7ANr69aF8MmfTJB97PVw3P+Y67Snr/5tqv6OvaR9zyuEEEKI/ZJpdLqYw+m5dnXl/jAFe2vYXuqnYG8NBXvNuqgySGXAzFlaEQjX69ILJmM6tHsaY/pmcGTvTEb3yWBojzQJQru6RY/CnFvgR5+ZwnBxy1+A16+Hs/9m5u7sTCp3w/w/wNdPm4Bt8s9g4g2mAu2Kl+Dtn5rtFz5u5pZMfNyjp4COwjUfQ0bv/V/rswdMkPz952D4jNa3dctnJnDdvMB0Se41zmR3fd3g5F/BuB80ny1uqcrd8NeRMP6HMP3PB34+IYQQQuxDptERop1FY9qaKsbPznI/hWV+CssD7Czzs7M8wI4yP5WBSL3HpLod9Mny0i3dQ9/sFNI8TtK9DtI9Tmv+Ugf9sn2M7JWOx9nFCtq0VTQM5dvNWMJD3bcvQ95w6D6q/vbR3zcB4kd3wbCzwZfTIc2rR2v49H749C8QDcIx18JJvwBfwlCH0RdDj9Hw0g/g6XNNNnnyzyESgOdngr8UrnqvZcErwKSbTFD83i/MnKktmTNUazMd0fw/wdbPzLQzZ/4Bjr4KXCkmQzz31/DOzfDlw3D63Wa+zQPpNr/0STNH67H71jkQQgghRPIlNYBVSk0F/gbYgce01vc22N8P+A+QaR1zm9Z6TjLbJERraK0pLA/w3a5K1u2urF1v2FNFsEHmNNvnomeGhz5ZKUwYkE3frBT6ZHnpm23WGV6pzLuP//7edEU9/1+ddzqZWAzC1S0LqJqydwts/wpOvXPf4EkpmH4f/GsyfHwXnPOPA2lt+1g/F/77Oxg6Hc74PeQMavy4bsPg2nnw9v+Y47d/BXaX6b47c3brxvXanXD2A/D4GTDvD6aoU3NKN8EbN8G2LyC1B0y912Swnd66Y/oeAz9831R+/vA38Pz3If8E85zaMuY4EoTFj8PgM5p+TYQQQgiRVEkLYJVSduCfwOlAAbBYKfWW1np1wmG/Bl7SWj+slBoBzAHy23I9rfUhHxx0te7eXU0oEmP9nkpWFVaw2lrW7KygMliXSe2R7mFIjzSOG5TD4G5p9M7y0jPDQ88ML17XYZI1bS/RMHzzrBkb+fqPQNk6XxVareHVH8KGj+EHr0OfRnuy7N+3L5v1kRc1vr/7CNM1d+GDMO5yE3h1pG+eAV8eXPy0CSyb406FCx43BZjev91kJ8/8Awyb3vrr9p0A468yVYtHf7/pIHPbl/D8LEDDtP+Doy4Hp6fxY5Uy0/UMmQpLn4L598Jjp5nKz+Oval37Vr0B1Xsk+yqEEEJ0oGRmYCcAG7TWmwCUUi8A5wKJAawG0q3bGUBhWy7k8XgoKSkhJyfnkA1itdaUlJTg8TTxJU00q2BvDVtLaqjwhyn3h6kIhGsLJ5XVmOJJ6/dUEo6aHwm8TjvDe6Zx7rheDOuRztAeaQzpliZTxzRl6xem6+fUP0H+8S17zHcfQE0xXPSUyWq9fr0JYo+8MKlNbZWv/wOrXgdXGjxzPlz+BvQ+unXn0BpWvGxV2O3X9HFTboOVr8K7P4fLXoPUvANre1tVF8O69+DYH+0/eI1TCiZca+Z53bMaxsxq+/VP/Q2seceMr732v/sWf/r2FXjjBsjoC5e+3PJMqN1p2njkhfDqtaZb8a4V5jPrcO3/8VrDVw9DzmAYeErrn5cQQggh2kUyA9jewPaE+wXAsQ2OuQuYq5T6CeADTmvsREqp64DrAPr12/cLYJ8+fSgoKKCoqOjAW92JeTwe+vTp09HN6BKqgxG+3FTCgu+KWLC+mM3F1fscY7cp0j0O0r1O+uf4OGloHiN6pjOiVzr5OT7stkPzx5B2t2w2vPU/JvM2/49w5Tste9w3z5qun8PONl0yn7sYXrvWBEOjLmhbW2pKTbdkTwaMPM+M0Wzrj1pF6+C922DgFNOt96kZVhD7pikQ1FK7VkDxOjjrL80f506DaX82Y0rvH2Km2hlxLgyb0fI5V9vD8hcgFjFFj1qr19gDnw7Im2nm837lh6bw1cQfme1aw4L7YN7vzWvz/WchJbsN58+CS16Ej++Gzx8wFZYvfnr/PxgULDFdo6ff13mrRQshhBCHgaRVIVZKXQScqbW+xrr/A2CC1vonCcf83GrD/UqpScDjwCitdazRk9J4FWIhakIRVhdWsGhLKQu+K2Lp1r2Eoxqv087EgdmcMDiPEb3SyfA6yfA6Sfc68bnsh2zG/qCIxeDj35ogYMCJJvv26f1w/QLoOab5x1bugr+MgOP/B067y2wLVcOzF5pxlBc+bqZXaY2SjfDcRVC2DXTMVMDNHmjOM+I8U/m3pe93OGC6mVYWwg1fmGliyrbBU2dBoAKueGv/zzHug/9npl255buWBVy7V5muqqvfNIEvCvpNhOHnmAJEmf1anhltLa3hoYkmmL7mo+Rco6XtePYC81m4aZHpzvz2T2H5bNO1+Jx/gMN94Nf59hV48yZTtXjmc00H39Ul8NaPTaXjn69p/2l5hBBCCFFPc1WIkxnATgLu0lqfad2/HUBr/ceEY1YBU7XW2637m4CJWus9TZ1XAlgRCEdZvbOCb625UlfuKGf9nkpi1kd5eM90ThySy4mD8xifn4XbIWNT212wynT5XfuOqfg6/f9MAPqXEWa84ff+3fzjP/urqbr746WQe0T98z57ARRY84uOOLdl7dm6EF6w5uSc9bzp5rn2bdP9d/OnVjA7yASzk27afyD53m2mu+isF2Ho1Lrte7eaIDZUBVe8XX86nMbEombKlV7jTLtaa89aWPOWCWZ3r7Q2KlNtN72XWTL6mHWadT+9p7nd1JjQ5hQshcdO6RxT+pRuNsH0gJMgXGOqDU/5lamG3J4/PBUugxcuhZoSOPdBk/3fu9mMs9220KyLvzPHnvC/phCXEEIIIZKqowJYB/AdcCqwA1gMXKK1XpVwzHvAi1rrp5RSw4GPgd66mUZJAHv4CUaifL21jM83FPP5xmJWFJQTtaLV3FQXR/bO4Mg+mRzZO4MxfTPolnYQxgmXboL/3gOTb95/ENNS375iApD+x7XP+ZKlvMBMk7J7lSnWc+yP6gKKOb+AJU/Az1aarGVjtIYHx5us2g/f33d/sNIEsTuWmkzbkRc3P3/nipdMFi2zH1zy0r5jIquLYY0VzG751AR/5z4IRzQ6YgG+mwuzL4IJ1zc+z2fpZhPEhv2mu3T3kU23bdN8M8XMhU/CqO81fVxLlGw0GcCKQqjYYS2FZglW7Hu8N9sKbHuaOUtbUlTp7ZtNF+JbvgNP+v6PT7ZP7zddfe0uOPefySvyVVUEL11uKhr78qDaGo7iyTTZ734TzRjmPhOk+7AQQghxEHRIAGtdeDrwAGaKnCe01vcope4Glmit37IqDz8KpGIKOv1Caz23uXNKAHvoi0RjrNlZyecbi/l8QzGLt5QSCMew2xSj+2QwaWAOY/pmMrpPBj3SPR3TDfjVa+Hbl8DuhjN+BxOuO7CsULAK/jzQzF1545dNB3/tJRY1U4K4Ulr3uB1LTfXXUI3JkA4+vf7+0k3w96OsTNUdjZ9j25fwxJlw7kMw7tLGjwlUWJlYq/vokReZaXYSx7RqDZ/8yYy7zT/BjGPcX2a1cJnJHBetNXObnn53/degchc8fLx5/a/5uOksZslGMyY2GjRjYpv6EeONm0z29Nb19ad3aW+BChPIVhZCxU5rbd3evdJkF29aBJl9mz5HqAbuHwrDzjLTGnUGkRDMuweGTjNBZLKvteDPpqt4PGDNHSoBqxBCCNEBOiyATQYJYA89pdUhvtm2l6+37eXrrWUsLyijJhQFYEj3VI4blMvkI3I5dmA2aZ5OUAV471b4+zgYO8tkbtZ/AEOmmQyRL6dt51z5GrxyFaDMOMdZL7RvN8mG3vqJCawufcVMXdISG+eZ4DU1z2Q6uw1v/LgXLoWtn8PPVjceIL95kxnj+b/rmh9LGAnBhg9h+fOw7n1TJKrbCBPIjjjXzBW64kUYc4np8tqSSrJgMqcf3w1fPgQ5R8D3HjGVhWMxePZ82PYVXDffzHHanJKN8OR0qNptAvnxV5t1vGpuOAD3DTZFmM5/uGVtS4aybfDPY2HgyTBrdtPHLX/BBPdXzml5JWkhhBBCiCSQAFZ0Ot8WlDN70Va+2lTKJqtCsN2mGNEznaP7ZzGuXyaTBubQLb0TThs051ZY8iTcvMJ0z/zq3/DhHabL5vcegYEntf6cL19puocefzPM/X9wzoNwVBuqwLbErpXwr8lgc5iumZe8YIowNWfd+6aLZc4RZiqZ1G5NH7vlc3hqOsz4q+m6mihYBfcNMd1pz32w5W2uKTVdgJe/YLKycSf/Gk68pW3B/qb58MaNJut60i9MYaSP72683U2p3AWLH4OvnzaBbEY/OPoKMy/p1i/g5SvM/LGDOnjalc//Bh/eCTNnmwxrY56aYbol/+Tr5P54IoQQQgixHxLAik4hGtN8tGY3j3+6mUVbSvG57EwalMvR/bM4ql8mo/tk4nV18oJL1cXw11Fw5AUm4xq3cwW8ejUUr4fJP4OTf9XySrFhP/x5EIy+CM76K/znbNi5HG78ovl5Q9vquYth+5fww7kmwNq7BS5+Boac0fjxq16HV68x3WQve23/3XS1hkdOMs/rxq/qd8H8+hlTzfWHc6Ffw1m1WqhkI6x+A7qPMtnqA+EvM/PXrnjR3B9+tnktWhvARcOw9l1Y8jhsXgA2J6TkANpUrW04l+nBFg3Dv0+CQDnc9NW+me/STaZXwSl3mB8EhBBCCCE6UHMBrAzuEUlXFYzw5OebOfm++Vz/zFJ2lPn59VnDWfirU3nsivHcMGUQxw7M6fzBK5hsayQAx/20/vaeo02306N+AJ/9xRTuiTU5G1R9G+dBuNpMk2KzwXn/BLTpatvSc7TU1i9Ml+fJPzNdZK+cA3lDTQXf1W/ue/zyF8x8nL3Hm7GeLZkGRimYeJOp3Lrx4/r7vnnWVAhuabflxuQMMmNsDzR4BTPn6PcegYueMhWKz/5727KPdqeZd/aKt+HHS8yY6GjIZHI7OniNt2/GX6GiwIwZbuib50DZYMysg982IYQQQohWkABWJIXWmpU7yrn77dVM+uPH/Pbt1eSmunjo0qP45NYpXHPCQNI7w3hWMFVny3fs/7hgFSx6xHTBzBuy736Xz1TNnfZnMwZ0Qwvn0VzzFngy6rrxZuWb6r6bF5juqe1Fa/jwN6bb84TrzTZfjgm6eh9lujEvS5jqZcmT8PqPIH8y/OA108aWGnm+uc7ChCx18XqT+R13WefrojryfBPEtiRA35/cwTD1D/DLzTDltgM/X3vpdywcdQV8+TDs+rZueywKy2bDoFMho3fHtU8IIYQQogUkgBXtqrDMz0PzN3DmAwuY8Y/PeObLLZw0JI/XbzyO1248nulH9sRh70QfuwX/Z6ZM+c/Z4N/b/LFf/wcCZSZ72ZyjrzJTtSx+dP/Xj4Rg3RwYOr1+l+OjLocjTjfjFos3NP7YUI0JRp6YCgUt6Fa/bo4ZPzrl9vrFlTwZZpxm/gnwxo9g8ePmvO/cbIoSXfKSCc5bw+GCCdfCpnlmuh0w2VdllyxfRzrtLvBmwTs/q8vub5xnqhYna8y1EEIIIUQ76kSRhOiqKgNhXlq8nVmPfMnxf/ovf35/HWkeJ787bxSLfnUaD15yFOP6ZXV0M/e14P/gv783maeybfDyVRCNNH5sJARfPGiCvD6Ndsev43DB0VfC+g/NnKHN2fKpGZc4/Jz625Uy2VyH2wSVsWjdvkC5mR/zgSPh/dvMeNnnLoQ9a5u+TjRiChTlDoGxjUxd4/KZQHXIVHj35+a8w8+B7z/X9ulfjr4KHF5T7TcaMdWEh5wJad3bdj5x4FKy4cx7oGAxfP2U2fbNM2a87pBpHdo0IYQQQoiWcHR0A0TXFIrEmL9uD28uK+SjNbsJRmLk56Rw86lDOG9cL/rntDJjd7DFg9fR34fzHjZdKN/6sakmPLWRMYLfvmyyVOf8o2XnP/pKWHCfKepzxu+bPm7NW+D0NV6lNr0nTL8PXrsGvvg7jLscvnoYvnoEguVwxGlmLGhaTzOv6jPnw9UfNF74afnzZu7Ti58BexP/7J0e+P6zpqiRssPUe5s+tiVSss1UQ988B32PNVV6x13W9vOJ9jH6+7DsOfjoLjPX6dp3Tba8pdMQCSGEEEJ0IKlCLFosFtMs2bqXN5bt4N0VOyn3h8nxuZgxuifnjuvNuL6ZqM42trExDYPXeJGd924zAWLDKWxiMXjoWLC74Ueftnz85kuXm3GsP1/TeBYzFoX7h5oxphc91fg5tDaVgtfOMV2MwzWmUu4J/wu9xtUdt2ulmZM0NQ9++AH4cuv2hf3wj6NNoHvNRwd3/GnxenhwvHntPOnmtWhpdWaRPMXr4eHjTPfx6iK44QvoPrKjWyWEEEIIATRfhVgysGK/CvbW8NKSAl5dWsCOMj9ep50zRnbnvLG9mTw4F2dnGtO6P00Fr2AypUVrzfjAnCOg/ySzfd0cU1H3gsdbF/wdc62p7Lvy1cYzj9sWmuChYffhRErBWX8xXZG7DYfJPzfVgxvqMQoueRGeOQ+evQCufAfcaWbfokfN/J7n//vgF0/KHQyDzzSVj8fMlOC1s8gdbMZyf/In80OIBK9CCCGE6CIkAysaFY7G+HjNHl5YvI1PvisCYPIRuXzvqN6cMaIHPncX/O2jueA1zr8XHj3VjDO9bj5k9IHHTjOB5k++bl2XWq3hoUlmHOt18/cNHt/7JSx9Cm7duO+8nG313Qfw/CzIPx4uedlM+fO3MWbc7mWvts81WmvbVyYbfdUcMwWO6BzCAZPdH/cDGD6jo1sjhBBCCFFLMrCixbaV1PDC4m28vLSAosogPdI9/OTkI7j4mL70yUrZ/wk6qy8e3H/wCqZC66wX4LFTTSB46p2wY4kZi9ra8aBKwTFXw5xbYMfS+sWfYjFY87YpINVewSuYIknnPQSvX2/GzmYPNJWTT/1N+12jtfodC7es67jri8Y5PSZrL4QQQgjRhUgAKwDYWx3iT++v5cUl21HAyUO7MWtCP6YMzetc0960RSQEn/zZTEvTXPAalzcELnwCZl8ML1wCKbltLz40ZiZ89FvTjTcxgC382nTrPeWOtp13f9esKYUPbjf3j7wIeo5u/+sIIYQQQghxkEkAe5iLxTQvL93Ove+tpTIQ4erjB3D1CQPomdHGqVM6o03zTNXeCdftP3iNG3w6nH43zP01TLyh7VPJuNNMQPn1f8z0JfHiSqvfBJsDhk5t23n3Z9KNJvO66FE4+f8l5xpCCCGEEEIcZBLAHsbW7Kzg12+sZOnWvUzIz+Z3541iaI+09r1I2A8254FNx3KgVr1uqq0OnNK6x036sZlmJLHab1sccw0sfhS+fhpO+LkZG7vmbRhwkumynCwn/wpO/EXHvvZCCCGEEEK0oy7eN1S0RVUwwu/eWc2Mf3zG5uJq7rtoDC9eP7H9g1et4ZEp8P4v2/e8rREJmnkuh53d+nkulTLdfluatW1Kt2GQfwIsedJMnbN7JezdDCOaqT7cXiR4FUIIIYQQh5CkfrtVSk0F/gbYgce01vc22P9X4GTrbgrQTWudmcw2He6WbCnlx7O/YXdlgFkT+vGLM4eSmdLKwK6lyraZaWnKC0x3XJcvOddpzsb/QrACRp5/8K+daMK1phLvdx9A4TegbDD0rI5tkxBCCCGEEF1M0gJYpZQd+CdwOlAALFZKvaW1Xh0/Rmv9s4TjfwIcYF9N0ZznF23jzjdX0jvTy2s3HMe4fknsvgpmnlOAUJXpMjtmZnKv15hVr5tuugNPOvjXTjT0LEjrZboSV+yEfsdBal7HtkkIIYQQQoguJpldiCcAG7TWm7TWIeAF4Nxmjp8FPJ/E9hy2wtEYd7yxkttf+5ZJg3J586bJyQ9eAbZ+Ae4MyOwPyzvgrQ0HYO0cGH422J0H//qJ7A4Yf5XJCBetOTjdh4UQQgghhDjEJDOA7Q1sT7hfYG3bh1KqPzAA+G8T+69TSi1RSi0pKipq94Yeyoqrglz62Fc88+VWrj9xIE9eeQwZKQcpmNu20MwBOmYWbPrEdCU+mDZ8BKHKju8+HHfUFaagFcCwGR3bFiGEEEIIIbqgZAawqpFtuoljZwKvaK2jje3UWj+itR6vtR6flyfdLltq5Y5yzn3wc5ZvL+NvM8dy+/Th2G2NvS1JUF0Mxd+ZKr5jZgIaVrx4cK4dt+p18GZD/okH97pNSesOR10OQ6ZBRqO/5QghhBBCCCGakcwiTgVA34T7fYDCJo6dCdyUxLYcdt5eXsitrywnK8XFKz86jiP7ZBzcBsTHv/Y/DrIHmDGfy56HyT831X2TLeyHde/B6Is6VyXeGX/p6BYIIYQQQgjRZSUzA7sYGKyUGqCUcmGC1LcaHqSUGgpkAQuT2JbDhtaaf3+ykZ88/w1H9s7grR9PPvjBK8DWhWB3182hOmYmlKyHHV+37PG6qWR9C63/EMLVnaf7sBBCCCGEEOKAJS2A1VpHgB8DHwBrgJe01quUUncrpRIr2MwCXtD6QCMWEYtpfv/uGv743lpmjO7Js9ccS16au2Mas+0LM4eqw7r+yPPA4YHls/f/2M0L4P5hsOXztl9/1euQkgv9J7f9HEIIIYQQQohOJZkZWLTWc7TWQ7TWg7TW91jb7tRav5VwzF1a69uS2Y7DQSgS4+YXl/H4Z5u56vh8/j5zHG6HvWMaE6yCnSvM+Nc4T4YpXPTtKxAJNv/YN2+Cql3w7s8hGm799UM18N37ptJvZ+o+LIQQQgghhDggSQ1gxcFRFYzww6cW89byQn45dRh3zhiBrS3Fmko3wcd3Q0VTQ5VbqGAR6Cj0n1R/+9hZECgzwWVTProLyrabsbJFa+Grf7f++uvnQrhGug8LIYQQQghxiJEAtosrqgwy85GFLNxUwn0XjeGGKYNQbSmStGcNPDEVPr0f/jkRvn667eNQty4EZYM+E+pvH3gypPU0xZwas/lTWPwoTLwBTr0TBp8J8/8IFTtbd/1Vr4EvD/of37b2CyGEEEIIITolCWC7sK0l1Vz4ry/YuKeaxy4fz4VH92nbiXYuhyenAwoueQl6HAlv/QSeOQ/2bm39+bYtNOfwpNffbrPD6Ithw4dQ1WA+31A1vPVjyBoAp9xhKhVPu9d0If7wjpZfO1gF382FEeea6wkhhBBCCCEOGRLAdlG7KwLMfORLKvxhZl97LCcP69a2E21fBE+dDS4fXDUHhpwJV7wNZ90PBUvgoUnw1SMQi7XsfJEQFCw20+Y0ZswsiEVg5Sv1t398N+zdAuf+E1wpZlv2QJh8M3z7ssnOtsT6DyDil+7DQgghhBBCHIIkgO2Cqq0xrxX+MM9ecyzj+mW17USbP4WnzwNfDlz1HuQMMtttNjjmGrhxIfSbCO/dCk9Nh+IN+z/nzmUQCew7/jWu23DoORaWJVQj3rrQjHWdcB3kN+j2O/lnkNkP5tzasoJOq16H1O71C0gJIYQQQgghDgkSwHYx0Zjmpy98w5qdFTx4yVGM7NXGOV7XfwTPXQiZfU3wmtl332My+8Flr8K5D8Ge1fDYqeDf2/x5t35h1s0FkGMvgV0rYPcqUzH4zZvMtU79zb7HOr0w9U9QtGb/BZ2ClWb+1xHnSfdhIYQQQgghDkESwHYx97y7ho/W7OGuc0a2vdvwmrfh+ZmQOwSunANpPZo+VikYdylc8Y6pIPzlw82fe9tCyDkCUptp26gLweY0Wdh590DpRjjnH+BObfz4odNg8Bkw/97mCzqtesNkf6X7sBBCCCGEEIckCWC7kKcXbuGJz808r5dPym/bSYrXw0tXQK9xZqyrL6dlgw0RowAAHwhJREFUj+s5GoafYwLYprKwsRhs+3L/3Xd9OWas7dfPwMJ/wvgfwsCTmj5eKZh6L0SD+xZ0CtWYQPjxM00RqOyB0PfYlj0nIYQQQgghRJciAWwXMW/tHu56axWnDe/Gr88a0fYTLXvOrL//LHgzW/fYk34JwYqms7BFa0yWtn8TBZwSjZkFwXLI6AOn373/43MGwfFWQactn8Gub+HdW+D+YfDGDVBdBKf9Fq7+0IzhFUIIIYQQQhxyHB3dALF/qwrL+fHsrxneM52/zRyH3daGeV7BZEhXvARHnApp3Vv/+B6j6rKwE28Ab4PiUS0Z/xo3+Aw48iIYfzW401p2/ck/g+UvwLMXmkrDdreZLufoK8ycr22Z/1YIIYQQQgjRZUiqqpPbVR7g6qeWkOZx8vgVx+BzH8BvDls+hYodMGZm28/RXBZ220JI6wlZ+fs/j8MFFzzWdLXixrhS4Jy/Q6+xpkvx/66FCx6F/MkSvAohhBBCCHEYkAxsJ6a15tZXllMRCPPyjybRI8NzYCdc8SK402Ho9Lafo6ksrNZmOpx+k5IbTA462SxCCCGEEEKIw45kYDuxj9bs4dP1xdx65tC2T5cTF6qB1W+aLrdO74GdK56FXfhQ3bayrVBZ2LLxr0IIIYQQQgjRBhLAdlLBSJR73l3NEd1SuWxi/wM/4dp3IVR1YN2H43qMMoHwV/+CmlKzbetCs27J+FchhBBCCCGEaAMJYDuppz7fwpaSGu6YMQKnvR3epuXPQ0Y/6NdOGdKGY2G3fQGeDOh2ABWShRBCCCGEEKIZSQ1glVJTlVLrlFIblFK3NXHMxUqp1UqpVUqp2clsT1dRVBnkH//dwCnDunHSkLwDP2HlLtg0D0Zf3H5TzHQfWT8Lu3Uh9J0oU9gIIYQQQgghkiZp0YZSyg78E5gGjABmKaVGNDhmMHA7cLzWeiRwc7La05XcP3cdgf/f3p1H2VXViR7//lJJhQwMgUSGDAQhqIEE0BBRu1sbp6BAVLQJD1RsuvP0Sctz6BZam+5Hq2uJvdrhiT7jrCBhaIfoi9A8xHYMBhQSINCkI5BKQAJUFYFUZfy9P+4tuCluVd0q69xbt/L9rFXr3r3PrnN/lXXWqfpl//Y+O3fzkTe+aHhOuPZ6yD3DUz5cqWcW9ubL4PH7B7ejsCRJkiQNUpHTZQuB9Zm5ITN3AMuBxb3G/DVwRWa2A2TmowXG0xTu2tTJNbdt5PyXz+boaZOH56R3LofpL4Gpc4bnfD16ZmFv/3qpPVzlyZIkSZJURZEJ7HRgY0W7rdxX6Vjg2Ij4ZUSsiohFBcYz4mUml/3oHqZMbOVvXl1Dsrny7+CGS2DPnr7HPHIX/GEtzB/m2dcer/xw6XXsfnDEScV8hiRJkiRR7HNgqz0MNKt8/hzgVcAM4OcRcXxmdux1ooilwFKAWbNmDX+kI8TKtY/wm98/wcfffDwHThjX/+DOTfCbZUDCmBZ43ceqj1uzHMaMhePPGvZ4gdIs7EvOh13bYWxrMZ8hSZIkSRSbwLYBMyvaM4DNVcasysydwO8j4j5KCe3qykGZuQxYBrBgwYLeSfCo0L1zN59YuY4XHrY/S06uIUlfey2QMPdN8Kv/DZOmwSsu2nvMnt2w5jqY8zqYdEghcQNwxmeLO7ckSZIklQ1YQhwRF0bElCGcezUwJyKOiohWYAmwoteY7wN/Xv6cqZRKijcM4bOa3ld+voFNHV384xnH0TKm2uR1hUy48xqY+VJ469fhuLfATZfCHb02cd7wU3jqkeHfvEmSJEmSGqCWNbCHAasj4tryY3EGyK5KMnMXcCFwI7AOuDYz746IyyLizPKwG4HHI+Ie4BbgbzPz8cH/GM3tkc5uvvDT/2LRcYfxsqNrmCl9ZA1sWQfzzy49tubN/wee/yr4wYVw3w3PjltzTenZrMfu00uLJUmSJI0SAyawmflRSmW9XwXOB+6PiE9ExNE1fO/KzDw2M4/OzI+X+y7NzBXl95mZH8jMuZk5LzOX/1E/TZNa9rMN7Ny9h79/Q42PzbnzGmhphePeXGqPHQ9nXwmHzYPrzoeHboXtT8G6H5bGjB1fWOySJEmSVC817UKcmQk8Uv7aBUwBro+IywuMbZ+wbccurrt9I6cdfzizDpk48Dfs3gVry+taJx78bP/4/eHc6+GAI+A7b4OffQp2boMTzikueEmSJEmqo1rWwL4vIm4HLgd+CczLzPcALwEK2tp23/HDOzeztXsX551yZG3fsOEWePrR6onp5Gnw9u+WHmnzy8/AlNmldbKSJEmSNArUMgM7FXhLZr4+M68r7xhMZu4BTi80ulEuM/nWrx/kBYfuz8mza9wn687lMGFKaQa2mimz4bzvwsSpsPC/Q21LliVJkiRpxKvlMTorgSd6GhGxPzA3M2/NzHWFRbYPuGNjB3dvfpJ/ftPx1LQ31vatcO//hRP/W//PXD3sePjgfdBS5FOSJEmSJKm+apmB/SLwVEX76XKf/khXrnqISa0tvPmk6bV9wz0rYFdXbY/FMXmVJEmSNMrUksBGeRMn4JnSYbOjP1L70zv44ZrNvOXFM5g8vsZ/zjuvhoOfDzNOLjY4SZIkSRqBaklgN5Q3chpX/roI2FB0YKPddbdvZMeuPbVv3tTZBg/8AuYvcV2rJEmSpH1SLQnsu4GXA5uANuClwNIigxrt9uxJrlz1EAtnH8wLDtsf2m6Da98JnZv6/qY11wIJ8/+ibnFKkiRJ0kgyYO1qZj4K1LDoUrX62f1beOiJbXzo9S8oday/Ge75Pjz4K1hyFcxcuPc3ZMKaa2DmKXDwUfUPWJIkSZJGgAET2IjYD7gAOA7Yr6c/M/+ywLhGtStXPcjUya0sOu6wUkd3R+nZra2T4BtvhDM+W9ppuMfDd8CWe+H0TzcmYEmSJEkaAWopIf42cBjweuA/gBnA1iKDGs3a2rfxk3sfZcnJs2gdW/7n72qHSdPgr38Cs06B778HbvwI7NldOn7nNdDSCse9uXGBS5IkSVKD1ZLAHpOZ/wA8nZnfBN4IzCs2rNHr6t88BMA5L531bGdXB+x3EEw8GM77LixcCr/+PHznL+Dpx+Gu6+HYRTBhSoOiliRJkqTGq+X5LTvLrx0RcTzwCDC7sIhGse27dnPN6o2c+sJDmX7QhGcPdHfAhINK71vGwRs+Bc+bCys/BFecDNser+3Zr5IkSZI0itUyA7ssIqYAHwVWAPcAnyw0qlHqhrse4bGndvD2l/V6dE5X+7MJbI8F74J3rCi9nzgVjnltfYKUJEmSpBGq3xnYiBgDPJmZ7cDPgOfXJapR6spVD3LkIRP502Om7n2gp4S4t9mvgP9xK+x4Csa21idISZIkSRqh+p2Bzcw9wIV1imVUu/8PW1n9QDvnvfRIxoyJvQ92d/S9vnXyNB+dI0mSJEnUVkJ8U0R8KCJmRsTBPV+1nDwiFkXEfRGxPiIurnL8/IjYEhF3lL/+atA/QZNYteFxAE6bd9jeB3Z2wa7u55YQS5IkSZL2UssmTj3Pe31vRV8yQDlxRLQAVwCvBdqA1RGxIjPv6TX0mswc9bO8a9o6OWRS696bN0GpfBiqlxBLkiRJkp4xYAKbmUOtX10IrM/MDQARsRxYTGkTqH3OmrZO5s04kIhe5cNd7aVXH5EjSZIkSf0aMIGNiHdU68/Mbw3wrdOBjRXtNuClVcadFRF/Bvwn8P7M3Nh7QEQsBZYCzJo1q/fhEW/bjl3c/+hWXn/coc892F2egbWEWJIkSZL6Vcsa2JMrvv4U+CfgzBq+L6r0Za/2D4HZmTkf+H/AN6udKDOXZeaCzFwwbdq0Gj56ZLln85PsSZg3o0qS2lNC7AysJEmSJPWrlhLiv6lsR8SBwLdrOHcbMLOiPQPY3Ovcj1c0v8wofb7smrZOAObPOPC5B3tKiF0DK0mSJEn9qmUGtrdtwJwaxq0G5kTEURHRCiwBVlQOiIjDK5pnAuuGEM+It3ZTJ4ceMJ5DD9jvuQctIZYkSZKkmtSyBvaHPFv6OwaYC1w70Pdl5q6IuBC4EWgBvpaZd0fEZcBtmbkCeF9EnAnsAp4Azh/STzHCrWnrYN70PhLUrg4gYHyV2VlJkiRJ0jNqeYzOv1S83wU8mJlttZw8M1cCK3v1XVrx/hLgklrO1ay2du9kw2NPs/jE6dUHdLXDfgfCmKFMhkuSJEnSvqOWBPYh4OHM7AaIiAkRMTszHyg0slHirk1Pkgnzqq1/hVIJseXDkiRJkjSgWqb9rgP2VLR3l/tUg7WbSmtc50/vI4Ht6nAHYkmSJEmqQS0J7NjM3NHTKL9vLS6k0WVNWyfTD5rAIZPHVx/Q1e4OxJIkSZJUg1oS2C3ljZYAiIjFwGPFhTS6rN3UWf3xOT0sIZYkSZKkmtSyBvbdwFUR8flyuw14R3EhjR4d23bw4OPbOPvkmX0P6mq3hFiSJEmSajBgApuZ/wWcEhGTgcjMrcWHNTqs3dQJwAkz+phhzSytgbWEWJIkSZIGNGAJcUR8IiIOysynMnNrREyJiI/VI7hmt6atlMAef0QfJcQ7noLc7QysJEmSJNWgljWwp2VmR08jM9uBNxQX0uixtq2T2YdM5MCJ46oP6GovvboGVpIkSZIGVEsC2xIRz2yhGxETgD621FWltZs6mddX+TCUyofBEmJJkiRJqkEtCeyVwM0RcUFEXADcBHyz2LCa32NPbWdTR1ffz3+F0g7EYAmxJEmSJNWglk2cLo+INcBrgABuAI4sOrBmt7a8/rXfR+hYQixJkiRJNatlBhbgEWAPcBbwamBdYRGNEmvaOomA4/qbgbWEWJIkSZJq1ucMbEQcCywBzgEeB66h9BidP69TbE1t7aYOjp42mcnj+5nkfmYG1hJiSZIkSRpIfyXE9wI/B87IzPUAEfH+ukQ1Cqxp6+RPjpna/6DuDhgzFlon1ScoSZIkSWpi/ZUQn0WpdPiWiPhyRLya0hpYDeAPT3bz6NbtzOtv/SuUSoj3OwjCf1ZJkiRJGkifCWxmfi8zzwZeCPwUeD9waER8MSJeV8vJI2JRRNwXEesj4uJ+xr01IjIiFgwy/hHpzo2lta3z+3uEDpRKiC0fliRJkqSaDLiJU2Y+nZlXZebpwAzgDqDPZLRHRLQAVwCnAXOBcyJibpVx+wPvA24dZOwj1tpNnbSMCeYefkD/A7s73IFYkiRJkmpU6y7EAGTmE5n5pcw8tYbhC4H1mbkhM3cAy4HFVcb9M3A50D2YWEayNW2dzHneZCa0tvQ/sKvDGVhJkiRJqtGgEthBmg5srGi3lfueEREnATMz80f9nSgilkbEbRFx25YtW4Y/0mGUmazd1Nn/8197dLX7CB1JkiRJqlGRCWy1nYnymYMRY4BPAx8c6ESZuSwzF2TmgmnTpg1jiMNvU0cXTzy9g3kDrX8FS4glSZIkaRCKTGDbgJkV7RnA5or2/sDxwE8j4gHgFGBFs2/ktKatE4ATBpqB3bMbup+0hFiSJEmSalRkArsamBMRR0VEK7AEWNFzMDM7M3NqZs7OzNnAKuDMzLytwJgKt6atk3EtwQsO27//gd2dQFpCLEmSJEk1KiyBzcxdwIXAjcA64NrMvDsiLouIM4v63EZbu6mDFx52AOPHDrCBU3fpUTuWEEuSJElSbcYWefLMXAms7NV3aR9jX1VkLPWQmaxp6+SME44YeHBXe+nVEmJJkiRJqkmRJcT7nLb2LrZ272L+9Fp2IC7PwFpCLEmSJEk1KXQGdl8z8+CJ/PYfXsu4lmobMPdiCbEkSZIkDYoJ7DA7eFJrbQMtIZYkSZKkQbGEuFEsIZYkSZKkQTGBbZTuDhg7Acbt1+hIJEmSJKkpmMA2Sle7618lSZIkaRBMYBulq8PyYUmSJEkaBBPYRunudAMnSZIkSRoEE9hGsYRYkiRJkgbFBLZRLCGWJEmSpEExgW2UrnZLiCVJkiRpEExgG2H3Ttj5tCXEkiRJkjQIJrCN0NVRerWEWJIkSZJqZgLbCF3tpVdLiCVJkiSpZiawjdBdnoG1hFiSJEmSalZoAhsRiyLivohYHxEXVzn+7ohYGxF3RMQvImJukfGMGD0lxM7ASpIkSVLNCktgI6IFuAI4DZgLnFMlQf1OZs7LzBOBy4F/LSqeEaWnhNg1sJIkSZJUsyJnYBcC6zNzQ2buAJYDiysHZOaTFc1JQBYYz8hhCbEkSZIkDdrYAs89HdhY0W4DXtp7UES8F/gA0AqcWu1EEbEUWAowa9asYQ+07pyBlSRJkqRBK3IGNqr0PWeGNTOvyMyjgQ8DH612osxclpkLMnPBtGnThjnMBujqgNb9oaXI/z+QJEmSpNGlyAS2DZhZ0Z4BbO5n/HLgTQXGM3J0d1g+LEmSJEmDVGQCuxqYExFHRUQrsARYUTkgIuZUNN8I3F9gPCNHV7sJrCRJkiQNUmE1rJm5KyIuBG4EWoCvZebdEXEZcFtmrgAujIjXADuBduCdRcUzonR1uP5VkiRJkgap0EWYmbkSWNmr79KK9xcV+fkjVncHTJ0z8DhJkiRJ0jOKLCFWX7raYcKURkchSZIkSU3FBLYRLCGWJEmSpEEzga23nV2we7szsJIkSZI0SCaw9dbVXnp1F2JJkiRJGhQT2Hrr6ii9WkIsSZIkSYNiAltvz8zAWkIsSZIkSYNhAltv3eUZWEuIJUmSJGlQTGDrzRJiSZIkSRoSE9h6s4RYkiRJkobEBLbeujuAgPEHNDoSSZIkSWoqJrD11tUB+x0IY/ynlyRJkqTBMIuqt652y4clSZIkaQhMYOutu8MdiCVJkiRpCExg662rwxlYSZIkSRoCE9h662r3ETqSJEmSNASFJrARsSgi7ouI9RFxcZXjH4iIeyJiTUTcHBFHFhnPiGAJsSRJkiQNSWEJbES0AFcApwFzgXMiYm6vYb8DFmTmfOB64PKi4hkRMi0hliRJkqQhKnIGdiGwPjM3ZOYOYDmwuHJAZt6SmdvKzVXAjALjabztWyF3W0IsSZIkSUNQZAI7HdhY0W4r9/XlAuDHBcbTeN0dpVdLiCVJkiRp0MYWeO6o0pdVB0acBywAXtnH8aXAUoBZs2YNV3z119VeerWEWJIkSZIGrcgZ2DZgZkV7BrC596CIeA3wEeDMzNxe7USZuSwzF2TmgmnTphUSbF10lWdgLSGWJEmSpEErMoFdDcyJiKMiohVYAqyoHBARJwFfopS8PlpgLCODJcSSJEmSNGSFJbCZuQu4ELgRWAdcm5l3R8RlEXFmedingMnAdRFxR0Ss6ON0o4MlxJIkSZI0ZEWugSUzVwIre/VdWvH+NUV+/ohjCbEkSZIkDVmRJcTqrasdxoyD1kmNjkSSJEmSmo4JbD11d5TWv0a1DZolSZIkSf0xga2nrg7LhyVJkiRpiExg66mr3Q2cJEmSJGmITGDrqaeEWJIkSZI0aCaw9WQJsSRJkiQNmQlsPXV1WEIsSZIkSUNkAlsve3bD9k5LiCVJkiRpiExg66W7s/RqCbEkSZIkDYkJbL10tZdeLSGWJEmSpCExga2X7o7SqyXEkiRJkjQkJrD1cs+K0uvkQxsbhyRJkiQ1KRPYevj1F+CXn4GT3g5HnNToaCRJkiSpKZnAFu2Oq+HGS+BFZ8Dpn4GIRkckSZIkSU3JBLZI966EH7wXjnolnPVVaBnb6IgkSZIkqWmZwBblgV/AdefD4SfAkqtg7PhGRyRJkiRJTa3QBDYiFkXEfRGxPiIurnL8zyLitxGxKyLeWmQsdfXwnXD1OTBlNpx7PYzfv9ERSZIkSVLTKyyBjYgW4ArgNGAucE5EzO017CHgfOA7RcVRd4+th2+/BfY7EN7+PZh0SKMjkiRJkqRRochFmQuB9Zm5ASAilgOLgXt6BmTmA+VjewqMo36e3AzfflPp/du/DwdOb2w8kiRJkjSKFFlCPB3YWNFuK/cNWkQsjYjbIuK2LVu2DEtwhRg3EZ43F877N5h6TKOjkSRJkqRRpcgEttrzYnIoJ8rMZZm5IDMXTJs27Y8Mq0ATDoJzr4UjTmx0JJIkSZI06hSZwLYBMyvaM4DNBX6eJEmSJGkUKzKBXQ3MiYijIqIVWAKsKPDzJEmSJEmjWGEJbGbuAi4EbgTWAddm5t0RcVlEnAkQESdHRBvwNuBLEXF3UfFIkiRJkppbkbsQk5krgZW9+i6teL+aUmmxJEmSJEn9KrKEWJIkSZKkYWMCK0mSJElqCiawkiRJkqSmYAIrSZIkSWoKkZmNjmFQImIL8GCj4xjAVOCxRgehEcvrQ/3x+tBAvEbUH68PDcRrRP0ZKdfHkZk5rdqBpktgm0FE3JaZCxodh0Ymrw/1x+tDA/EaUX+8PjQQrxH1pxmuD0uIJUmSJElNwQRWkiRJktQUTGCLsazRAWhE8/pQf7w+NBCvEfXH60MD8RpRf0b89eEaWEmSJElSU3AGVpIkSZLUFExgJUmSJElNwQR2GEXEooi4LyLWR8TFjY5HjRcRMyPilohYFxF3R8RF5f6DI+KmiLi//Dql0bGqcSKiJSJ+FxE/KrePiohby9fHNRHR2ugY1RgRcVBEXB8R95bvIy/z/qFKEfH+8u+XuyLi6ojYz3vIvisivhYRj0bEXRV9Ve8ZUfK58t+tayLixY2LXPXSxzXyqfLvmTUR8b2IOKji2CXla+S+iHh9Y6LemwnsMImIFuAK4DRgLnBORMxtbFQaAXYBH8zMFwGnAO8tXxcXAzdn5hzg5nJb+66LgHUV7U8Cny5fH+3ABQ2JSiPBZ4EbMvOFwAmUrhPvHwIgIqYD7wMWZObxQAuwBO8h+7JvAIt69fV1zzgNmFP+Wgp8sU4xqrG+wXOvkZuA4zNzPvCfwCUA5b9ZlwDHlb/nC+Wcp6FMYIfPQmB9Zm7IzB3AcmBxg2NSg2Xmw5n52/L7rZT++JxO6dr4ZnnYN4E3NSZCNVpEzADeCHyl3A7gVOD68hCvj31URBwA/BnwVYDM3JGZHXj/0N7GAhMiYiwwEXgY7yH7rMz8GfBEr+6+7hmLgW9lySrgoIg4vD6RqlGqXSOZ+e+ZuavcXAXMKL9fDCzPzO2Z+XtgPaWcp6FMYIfPdGBjRbut3CcBEBGzgZOAW4FDM/NhKCW5wPMaF5ka7DPA3wF7yu1DgI6KXyTeS/Zdzwe2AF8vl5h/JSIm4f1DZZm5CfgX4CFKiWsncDveQ7S3vu4Z/u2qav4S+HH5/Yi8Rkxgh09U6fMZRQIgIiYD/wb8z8x8stHxaGSIiNOBRzPz9sruKkO9l+ybxgIvBr6YmScBT2O5sCqU1zIuBo4CjgAmUSoL7c17iKrx9432EhEfobT87aqerirDGn6NmMAOnzZgZkV7BrC5QbFoBImIcZSS16sy87vl7j/0lOmUXx9tVHxqqFcAZ0bEA5SWHZxKaUb2oHI5IHgv2Ze1AW2ZeWu5fT2lhNb7h3q8Bvh9Zm7JzJ3Ad4GX4z1Ee+vrnuHfrnpGRLwTOB04NzN7ktQReY2YwA6f1cCc8s5/rZQWPK9ocExqsPJ6xq8C6zLzXysOrQDeWX7/TuAH9Y5NjZeZl2TmjMycTeme8ZPMPBe4BXhreZjXxz4qMx8BNkbEC8pdrwbuwfuHnvUQcEpETCz/vum5RryHqFJf94wVwDvKuxGfAnT2lBpr3xIRi4APA2dm5raKQyuAJRExPiKOorTh128aEWOleDbB1h8rIt5AafakBfhaZn68wSGpwSLiT4CfA2t5do3j31NaB3stMIvSHyBvy8zemy5oHxIRrwI+lJmnR8TzKc3IHgz8DjgvM7c3Mj41RkScSGmDr1ZgA/AuSv/57P1DAETE/wLOplT29zvgryitUfMesg+KiKuBVwFTgT8A/wh8nyr3jPJ/enye0u6y24B3ZeZtjYhb9dPHNXIJMB54vDxsVWa+uzz+I5TWxe6itBTux73PWW8msJIkSZKkpmAJsSRJkiSpKZjASpIkSZKaggmsJEmSJKkpmMBKkiRJkpqCCawkSZIkqSmYwEqSVAcRsTsi7qj4ungYzz07Iu4arvNJkjRSjW10AJIk7SO6MvPERgchSVIzcwZWkqQGiogHIuKTEfGb8tcx5f4jI+LmiFhTfp1V7j80Ir4XEXeWv15ePlVLRHw5Iu6OiH+PiAkN+6EkSSqICawkSfUxoVcJ8dkVx57MzIXA54HPlPs+D3wrM+cDVwGfK/d/DviPzDwBeDFwd7l/DnBFZh4HdABnFfzzSJJUd5GZjY5BkqRRLyKeyszJVfofAE7NzA0RMQ54JDMPiYjHgMMzc2e5/+HMnBoRW4AZmbm94hyzgZsyc065/WFgXGZ+rPifTJKk+nEGVpKkxss+3vc1pprtFe934z4XkqRRyARWkqTGO7vi9dfl978ClpTfnwv8ovz+ZuA9ABHREhEH1CtISZIazf+dlSSpPiZExB0V7Rsys+dROuMj4lZK/7F8TrnvfcDXIuJvgS3Au8r9FwHLIuICSjOt7wEeLjx6SZJGANfASpLUQOU1sAsy87FGxyJJ0khnCbEkSZIkqSk4AytJkiRJagrOwEqSJEmSmoIJrCRJkiSpKZjASpIkSZKaggmsJEmSJKkpmMBKkiRJkprC/wcMuE8b8fCiqQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1152x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#history plot for accyracy\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.plot(history_3.history['accuracy'])\n",
    "plt.plot(history_3.history['val_accuracy'])\n",
    "plt.title(\"Model Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend([\"train\", \"test\"], loc=\"upper left\")\n",
    "plt.show()\n",
    "\n",
    "# history plot for accuracy\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.plot(history_3.history[\"loss\"])\n",
    "plt.plot(history_3.history[\"val_loss\"])\n",
    "plt.title(\"Model Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend([\"train\", \"test\"], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 4s 438us/sample - loss: 0.4829 - accuracy: 0.8681\n",
      "[0.48287300192117694, 0.8681]\n"
     ]
    }
   ],
   "source": [
    "best_model_3 = tf.keras.models.load_model('/home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model3_70-0.87.hdf5')\n",
    "scores = best_model_3.evaluate(X_test, y_test, verbose=1)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model -4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BN-->ReLU-->Conv2D-->Dropout-->concat(input, output)-->(put in loop)\n",
    "\n",
    "def denseblock(input, num_filter, dropout_rate = 0.2):\n",
    "    global compression      # to keep the growth rate of number of filters\n",
    "    temp = input\n",
    "    for _ in range(l): \n",
    "        BatchNorm = layers.BatchNormalization()(temp)\n",
    "        relu = layers.Activation('relu')(BatchNorm)\n",
    "        Conv2D_7_7= layers.SeparableConv2D(int(num_filter*compression), (7,7), use_bias=False, padding='same')(relu)\n",
    "        #Conv2D_3_3 = layers.Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n",
    "        if dropout_rate>0:\n",
    "            Conv2D_7_7 = layers.Dropout(dropout_rate)(Conv2D_7_7)\n",
    "\n",
    "        #concat the input(temp) and output(conv2d_3_3) , in resnet we add but here we concat \n",
    "        concat = layers.Concatenate(axis=-1)([temp,Conv2D_7_7])\n",
    "        \n",
    "        #change the concat as input\n",
    "        temp = concat\n",
    "        \n",
    "    return temp\n",
    "\n",
    "#BN-->relu-->conv2d(1x1)-->dropout-->avg_pool\n",
    "def transition(input, num_filter, dropout_rate = 0.2):\n",
    "    global compression\n",
    "    BatchNorm = layers.BatchNormalization()(input)\n",
    "    relu = layers.Activation('relu')(BatchNorm)\n",
    "    #Conv2D_BottleNeck = layers.Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
    "    Conv2D_BottleNeck = layers.SeparableConvolution2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
    "    if dropout_rate>0:\n",
    "         Conv2D_BottleNeck = layers.Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
    "    avg = layers.AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
    "    return avg\n",
    "\n",
    "#BN-->relu-->avgpool-->flat-->softmax\n",
    "def output_layer(input):\n",
    "    global compression\n",
    "    BatchNorm = layers.BatchNormalization()(input)\n",
    "    relu = layers.Activation('relu')(BatchNorm)\n",
    "    AvgPooling = layers.AveragePooling2D(pool_size=(2,2))(relu)\n",
    "    flat = layers.Flatten()(AvgPooling)\n",
    "    output = layers.Dense(num_classes, activation='softmax')(flat)\n",
    "    return output\n",
    "\n",
    "# Hyperparameters\n",
    "l = 12\n",
    "num_filter = 32\n",
    "compression = 0.5\n",
    "dropout_rate = 0.2\n",
    "num_classes = 10\n",
    "\n",
    "input = layers.Input(shape=(input_size))\n",
    "First_Conv2D = layers.Conv2D(num_filter, (7,7), use_bias=False ,padding='same')(input)\n",
    "\n",
    "#First dense and transition block\n",
    "First_Block = denseblock(First_Conv2D, num_filter, dropout_rate)\n",
    "First_Transition = transition(First_Block, num_filter, dropout_rate)\n",
    "\n",
    "#Second dense and transition block\n",
    "Second_Block = denseblock(First_Transition, num_filter, dropout_rate)\n",
    "Second_Transition = transition(Second_Block, num_filter, dropout_rate)\n",
    "\n",
    "#Third dense and transition block\n",
    "Third_Block = denseblock(Second_Transition, num_filter, dropout_rate)\n",
    "Third_Transition = transition(Third_Block, num_filter, dropout_rate)\n",
    "\n",
    "#last dense and output block\n",
    "Last_Block = denseblock(Third_Transition,  num_filter, dropout_rate)\n",
    "output = output_layer(Last_Block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 32, 32, 32)   4704        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 32, 32, 32)   128         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 32, 32, 32)   0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_102 (Separable (None, 32, 32, 16)   2080        activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_153 (Dropout)           (None, 32, 32, 16)   0           separable_conv2d_102[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_144 (Concatenate)   (None, 32, 32, 48)   0           conv2d_54[0][0]                  \n",
      "                                                                 dropout_153[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 32, 32, 48)   192         concatenate_144[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 32, 32, 48)   0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_103 (Separable (None, 32, 32, 16)   3120        activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_154 (Dropout)           (None, 32, 32, 16)   0           separable_conv2d_103[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_145 (Concatenate)   (None, 32, 32, 64)   0           concatenate_144[0][0]            \n",
      "                                                                 dropout_154[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 32, 32, 64)   256         concatenate_145[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 32, 32, 64)   0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_104 (Separable (None, 32, 32, 16)   4160        activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_155 (Dropout)           (None, 32, 32, 16)   0           separable_conv2d_104[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_146 (Concatenate)   (None, 32, 32, 80)   0           concatenate_145[0][0]            \n",
      "                                                                 dropout_155[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 32, 32, 80)   320         concatenate_146[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 32, 32, 80)   0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_105 (Separable (None, 32, 32, 16)   5200        activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_156 (Dropout)           (None, 32, 32, 16)   0           separable_conv2d_105[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_147 (Concatenate)   (None, 32, 32, 96)   0           concatenate_146[0][0]            \n",
      "                                                                 dropout_156[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 32, 32, 96)   384         concatenate_147[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 32, 32, 96)   0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_106 (Separable (None, 32, 32, 16)   6240        activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_157 (Dropout)           (None, 32, 32, 16)   0           separable_conv2d_106[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_148 (Concatenate)   (None, 32, 32, 112)  0           concatenate_147[0][0]            \n",
      "                                                                 dropout_157[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 32, 32, 112)  448         concatenate_148[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 32, 32, 112)  0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_107 (Separable (None, 32, 32, 16)   7280        activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_158 (Dropout)           (None, 32, 32, 16)   0           separable_conv2d_107[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_149 (Concatenate)   (None, 32, 32, 128)  0           concatenate_148[0][0]            \n",
      "                                                                 dropout_158[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 32, 32, 128)  512         concatenate_149[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 32, 32, 128)  0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_108 (Separable (None, 32, 32, 16)   8320        activation_162[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_159 (Dropout)           (None, 32, 32, 16)   0           separable_conv2d_108[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_150 (Concatenate)   (None, 32, 32, 144)  0           concatenate_149[0][0]            \n",
      "                                                                 dropout_159[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 32, 32, 144)  576         concatenate_150[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 32, 32, 144)  0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_109 (Separable (None, 32, 32, 16)   9360        activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_160 (Dropout)           (None, 32, 32, 16)   0           separable_conv2d_109[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_151 (Concatenate)   (None, 32, 32, 160)  0           concatenate_150[0][0]            \n",
      "                                                                 dropout_160[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 32, 32, 160)  640         concatenate_151[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 32, 32, 160)  0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_110 (Separable (None, 32, 32, 16)   10400       activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_161 (Dropout)           (None, 32, 32, 16)   0           separable_conv2d_110[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_152 (Concatenate)   (None, 32, 32, 176)  0           concatenate_151[0][0]            \n",
      "                                                                 dropout_161[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 32, 32, 176)  704         concatenate_152[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 32, 32, 176)  0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_111 (Separable (None, 32, 32, 16)   11440       activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_162 (Dropout)           (None, 32, 32, 16)   0           separable_conv2d_111[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_153 (Concatenate)   (None, 32, 32, 192)  0           concatenate_152[0][0]            \n",
      "                                                                 dropout_162[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 32, 32, 192)  768         concatenate_153[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 32, 32, 192)  0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_112 (Separable (None, 32, 32, 16)   12480       activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_163 (Dropout)           (None, 32, 32, 16)   0           separable_conv2d_112[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_154 (Concatenate)   (None, 32, 32, 208)  0           concatenate_153[0][0]            \n",
      "                                                                 dropout_163[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 32, 32, 208)  832         concatenate_154[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 32, 32, 208)  0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_113 (Separable (None, 32, 32, 16)   13520       activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_164 (Dropout)           (None, 32, 32, 16)   0           separable_conv2d_113[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_155 (Concatenate)   (None, 32, 32, 224)  0           concatenate_154[0][0]            \n",
      "                                                                 dropout_164[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 32, 32, 224)  896         concatenate_155[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 32, 32, 224)  0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_114 (Separable (None, 32, 32, 16)   3808        activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_165 (Dropout)           (None, 32, 32, 16)   0           separable_conv2d_114[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_12 (AveragePo (None, 16, 16, 16)   0           dropout_165[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 16, 16, 16)   64          average_pooling2d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 16, 16, 16)   0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_115 (Separable (None, 16, 16, 16)   1040        activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_166 (Dropout)           (None, 16, 16, 16)   0           separable_conv2d_115[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_156 (Concatenate)   (None, 16, 16, 32)   0           average_pooling2d_12[0][0]       \n",
      "                                                                 dropout_166[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 16, 16, 32)   128         concatenate_156[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 16, 16, 32)   0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_116 (Separable (None, 16, 16, 16)   2080        activation_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_167 (Dropout)           (None, 16, 16, 16)   0           separable_conv2d_116[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_157 (Concatenate)   (None, 16, 16, 48)   0           concatenate_156[0][0]            \n",
      "                                                                 dropout_167[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 16, 16, 48)   192         concatenate_157[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 16, 16, 48)   0           batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_117 (Separable (None, 16, 16, 16)   3120        activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_168 (Dropout)           (None, 16, 16, 16)   0           separable_conv2d_117[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_158 (Concatenate)   (None, 16, 16, 64)   0           concatenate_157[0][0]            \n",
      "                                                                 dropout_168[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 16, 16, 64)   256         concatenate_158[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 16, 16, 64)   0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_118 (Separable (None, 16, 16, 16)   4160        activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_169 (Dropout)           (None, 16, 16, 16)   0           separable_conv2d_118[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_159 (Concatenate)   (None, 16, 16, 80)   0           concatenate_158[0][0]            \n",
      "                                                                 dropout_169[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 16, 16, 80)   320         concatenate_159[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 16, 16, 80)   0           batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_119 (Separable (None, 16, 16, 16)   5200        activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_170 (Dropout)           (None, 16, 16, 16)   0           separable_conv2d_119[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_160 (Concatenate)   (None, 16, 16, 96)   0           concatenate_159[0][0]            \n",
      "                                                                 dropout_170[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 16, 16, 96)   384         concatenate_160[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 16, 16, 96)   0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_120 (Separable (None, 16, 16, 16)   6240        activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_171 (Dropout)           (None, 16, 16, 16)   0           separable_conv2d_120[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_161 (Concatenate)   (None, 16, 16, 112)  0           concatenate_160[0][0]            \n",
      "                                                                 dropout_171[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 16, 16, 112)  448         concatenate_161[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 16, 16, 112)  0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_121 (Separable (None, 16, 16, 16)   7280        activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_172 (Dropout)           (None, 16, 16, 16)   0           separable_conv2d_121[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_162 (Concatenate)   (None, 16, 16, 128)  0           concatenate_161[0][0]            \n",
      "                                                                 dropout_172[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 16, 16, 128)  512         concatenate_162[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 16, 16, 128)  0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_122 (Separable (None, 16, 16, 16)   8320        activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_173 (Dropout)           (None, 16, 16, 16)   0           separable_conv2d_122[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_163 (Concatenate)   (None, 16, 16, 144)  0           concatenate_162[0][0]            \n",
      "                                                                 dropout_173[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 16, 16, 144)  576         concatenate_163[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 16, 16, 144)  0           batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_123 (Separable (None, 16, 16, 16)   9360        activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_174 (Dropout)           (None, 16, 16, 16)   0           separable_conv2d_123[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_164 (Concatenate)   (None, 16, 16, 160)  0           concatenate_163[0][0]            \n",
      "                                                                 dropout_174[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 16, 16, 160)  640         concatenate_164[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 16, 16, 160)  0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_124 (Separable (None, 16, 16, 16)   10400       activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_175 (Dropout)           (None, 16, 16, 16)   0           separable_conv2d_124[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_165 (Concatenate)   (None, 16, 16, 176)  0           concatenate_164[0][0]            \n",
      "                                                                 dropout_175[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, 16, 16, 176)  704         concatenate_165[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 16, 16, 176)  0           batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_125 (Separable (None, 16, 16, 16)   11440       activation_179[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_176 (Dropout)           (None, 16, 16, 16)   0           separable_conv2d_125[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_166 (Concatenate)   (None, 16, 16, 192)  0           concatenate_165[0][0]            \n",
      "                                                                 dropout_176[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 16, 16, 192)  768         concatenate_166[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 16, 16, 192)  0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_126 (Separable (None, 16, 16, 16)   12480       activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_177 (Dropout)           (None, 16, 16, 16)   0           separable_conv2d_126[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_167 (Concatenate)   (None, 16, 16, 208)  0           concatenate_166[0][0]            \n",
      "                                                                 dropout_177[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, 16, 16, 208)  832         concatenate_167[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 16, 16, 208)  0           batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_127 (Separable (None, 16, 16, 16)   3536        activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_178 (Dropout)           (None, 16, 16, 16)   0           separable_conv2d_127[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_13 (AveragePo (None, 8, 8, 16)     0           dropout_178[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, 8, 8, 16)     64          average_pooling2d_13[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 8, 8, 16)     0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_128 (Separable (None, 8, 8, 16)     1040        activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_179 (Dropout)           (None, 8, 8, 16)     0           separable_conv2d_128[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_168 (Concatenate)   (None, 8, 8, 32)     0           average_pooling2d_13[0][0]       \n",
      "                                                                 dropout_179[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, 8, 8, 32)     128         concatenate_168[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 8, 8, 32)     0           batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_129 (Separable (None, 8, 8, 16)     2080        activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_180 (Dropout)           (None, 8, 8, 16)     0           separable_conv2d_129[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_169 (Concatenate)   (None, 8, 8, 48)     0           concatenate_168[0][0]            \n",
      "                                                                 dropout_180[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, 8, 8, 48)     192         concatenate_169[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 8, 8, 48)     0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_130 (Separable (None, 8, 8, 16)     3120        activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_181 (Dropout)           (None, 8, 8, 16)     0           separable_conv2d_130[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_170 (Concatenate)   (None, 8, 8, 64)     0           concatenate_169[0][0]            \n",
      "                                                                 dropout_181[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, 8, 8, 64)     256         concatenate_170[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 8, 8, 64)     0           batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_131 (Separable (None, 8, 8, 16)     4160        activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_182 (Dropout)           (None, 8, 8, 16)     0           separable_conv2d_131[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_171 (Concatenate)   (None, 8, 8, 80)     0           concatenate_170[0][0]            \n",
      "                                                                 dropout_182[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, 8, 8, 80)     320         concatenate_171[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 8, 8, 80)     0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_132 (Separable (None, 8, 8, 16)     5200        activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_183 (Dropout)           (None, 8, 8, 16)     0           separable_conv2d_132[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_172 (Concatenate)   (None, 8, 8, 96)     0           concatenate_171[0][0]            \n",
      "                                                                 dropout_183[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 8, 8, 96)     384         concatenate_172[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 8, 8, 96)     0           batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_133 (Separable (None, 8, 8, 16)     6240        activation_187[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_184 (Dropout)           (None, 8, 8, 16)     0           separable_conv2d_133[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_173 (Concatenate)   (None, 8, 8, 112)    0           concatenate_172[0][0]            \n",
      "                                                                 dropout_184[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 8, 8, 112)    448         concatenate_173[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 8, 8, 112)    0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_134 (Separable (None, 8, 8, 16)     7280        activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_185 (Dropout)           (None, 8, 8, 16)     0           separable_conv2d_134[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_174 (Concatenate)   (None, 8, 8, 128)    0           concatenate_173[0][0]            \n",
      "                                                                 dropout_185[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 8, 8, 128)    512         concatenate_174[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 8, 8, 128)    0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_135 (Separable (None, 8, 8, 16)     8320        activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_186 (Dropout)           (None, 8, 8, 16)     0           separable_conv2d_135[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_175 (Concatenate)   (None, 8, 8, 144)    0           concatenate_174[0][0]            \n",
      "                                                                 dropout_186[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 8, 8, 144)    576         concatenate_175[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 8, 8, 144)    0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_136 (Separable (None, 8, 8, 16)     9360        activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_187 (Dropout)           (None, 8, 8, 16)     0           separable_conv2d_136[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_176 (Concatenate)   (None, 8, 8, 160)    0           concatenate_175[0][0]            \n",
      "                                                                 dropout_187[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 8, 8, 160)    640         concatenate_176[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 8, 8, 160)    0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_137 (Separable (None, 8, 8, 16)     10400       activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_188 (Dropout)           (None, 8, 8, 16)     0           separable_conv2d_137[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_177 (Concatenate)   (None, 8, 8, 176)    0           concatenate_176[0][0]            \n",
      "                                                                 dropout_188[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 8, 8, 176)    704         concatenate_177[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 8, 8, 176)    0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_138 (Separable (None, 8, 8, 16)     11440       activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_189 (Dropout)           (None, 8, 8, 16)     0           separable_conv2d_138[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_178 (Concatenate)   (None, 8, 8, 192)    0           concatenate_177[0][0]            \n",
      "                                                                 dropout_189[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 8, 8, 192)    768         concatenate_178[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 8, 8, 192)    0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_139 (Separable (None, 8, 8, 16)     12480       activation_193[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_190 (Dropout)           (None, 8, 8, 16)     0           separable_conv2d_139[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_179 (Concatenate)   (None, 8, 8, 208)    0           concatenate_178[0][0]            \n",
      "                                                                 dropout_190[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 8, 8, 208)    832         concatenate_179[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 8, 8, 208)    0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_140 (Separable (None, 8, 8, 16)     3536        activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_191 (Dropout)           (None, 8, 8, 16)     0           separable_conv2d_140[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_14 (AveragePo (None, 4, 4, 16)     0           dropout_191[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 4, 4, 16)     64          average_pooling2d_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 4, 4, 16)     0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_141 (Separable (None, 4, 4, 16)     1040        activation_195[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_192 (Dropout)           (None, 4, 4, 16)     0           separable_conv2d_141[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_180 (Concatenate)   (None, 4, 4, 32)     0           average_pooling2d_14[0][0]       \n",
      "                                                                 dropout_192[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, 4, 4, 32)     128         concatenate_180[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 4, 4, 32)     0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_142 (Separable (None, 4, 4, 16)     2080        activation_196[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_193 (Dropout)           (None, 4, 4, 16)     0           separable_conv2d_142[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_181 (Concatenate)   (None, 4, 4, 48)     0           concatenate_180[0][0]            \n",
      "                                                                 dropout_193[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 4, 4, 48)     192         concatenate_181[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 4, 4, 48)     0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_143 (Separable (None, 4, 4, 16)     3120        activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_194 (Dropout)           (None, 4, 4, 16)     0           separable_conv2d_143[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_182 (Concatenate)   (None, 4, 4, 64)     0           concatenate_181[0][0]            \n",
      "                                                                 dropout_194[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 4, 4, 64)     256         concatenate_182[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, 4, 4, 64)     0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_144 (Separable (None, 4, 4, 16)     4160        activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_195 (Dropout)           (None, 4, 4, 16)     0           separable_conv2d_144[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_183 (Concatenate)   (None, 4, 4, 80)     0           concatenate_182[0][0]            \n",
      "                                                                 dropout_195[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 4, 4, 80)     320         concatenate_183[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 4, 4, 80)     0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_145 (Separable (None, 4, 4, 16)     5200        activation_199[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_196 (Dropout)           (None, 4, 4, 16)     0           separable_conv2d_145[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_184 (Concatenate)   (None, 4, 4, 96)     0           concatenate_183[0][0]            \n",
      "                                                                 dropout_196[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 4, 4, 96)     384         concatenate_184[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 4, 4, 96)     0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_146 (Separable (None, 4, 4, 16)     6240        activation_200[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_197 (Dropout)           (None, 4, 4, 16)     0           separable_conv2d_146[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_185 (Concatenate)   (None, 4, 4, 112)    0           concatenate_184[0][0]            \n",
      "                                                                 dropout_197[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 4, 4, 112)    448         concatenate_185[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, 4, 4, 112)    0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_147 (Separable (None, 4, 4, 16)     7280        activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_198 (Dropout)           (None, 4, 4, 16)     0           separable_conv2d_147[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_186 (Concatenate)   (None, 4, 4, 128)    0           concatenate_185[0][0]            \n",
      "                                                                 dropout_198[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 4, 4, 128)    512         concatenate_186[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, 4, 4, 128)    0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_148 (Separable (None, 4, 4, 16)     8320        activation_202[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_199 (Dropout)           (None, 4, 4, 16)     0           separable_conv2d_148[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_187 (Concatenate)   (None, 4, 4, 144)    0           concatenate_186[0][0]            \n",
      "                                                                 dropout_199[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 4, 4, 144)    576         concatenate_187[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, 4, 4, 144)    0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_149 (Separable (None, 4, 4, 16)     9360        activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_200 (Dropout)           (None, 4, 4, 16)     0           separable_conv2d_149[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_188 (Concatenate)   (None, 4, 4, 160)    0           concatenate_187[0][0]            \n",
      "                                                                 dropout_200[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchN (None, 4, 4, 160)    640         concatenate_188[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_204 (Activation)     (None, 4, 4, 160)    0           batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_150 (Separable (None, 4, 4, 16)     10400       activation_204[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_201 (Dropout)           (None, 4, 4, 16)     0           separable_conv2d_150[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_189 (Concatenate)   (None, 4, 4, 176)    0           concatenate_188[0][0]            \n",
      "                                                                 dropout_201[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, 4, 4, 176)    704         concatenate_189[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_205 (Activation)     (None, 4, 4, 176)    0           batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_151 (Separable (None, 4, 4, 16)     11440       activation_205[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_202 (Dropout)           (None, 4, 4, 16)     0           separable_conv2d_151[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_190 (Concatenate)   (None, 4, 4, 192)    0           concatenate_189[0][0]            \n",
      "                                                                 dropout_202[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchN (None, 4, 4, 192)    768         concatenate_190[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_206 (Activation)     (None, 4, 4, 192)    0           batch_normalization_206[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_152 (Separable (None, 4, 4, 16)     12480       activation_206[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_203 (Dropout)           (None, 4, 4, 16)     0           separable_conv2d_152[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_191 (Concatenate)   (None, 4, 4, 208)    0           concatenate_190[0][0]            \n",
      "                                                                 dropout_203[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchN (None, 4, 4, 208)    832         concatenate_191[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_207 (Activation)     (None, 4, 4, 208)    0           batch_normalization_207[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_15 (AveragePo (None, 2, 2, 208)    0           activation_207[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 832)          0           average_pooling2d_15[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           8330        flatten_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 385,002\n",
      "Trainable params: 372,938\n",
      "Non-trainable params: 12,064\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_4 = tf.keras.models.Model(inputs=[input], outputs=[output])\n",
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 195 steps, validate on 10000 samples\n",
      "Epoch 1/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 1.7070 - accuracy: 0.3639\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.10000, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model4_01-0.10.hdf5\n",
      "195/195 [==============================] - 70s 359ms/step - loss: 1.7059 - accuracy: 0.3643 - val_loss: 2.3413 - val_accuracy: 0.1000\n",
      "Epoch 2/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 1.3666 - accuracy: 0.5033\n",
      "Epoch 00002: val_accuracy improved from 0.10000 to 0.19030, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model4_02-0.19.hdf5\n",
      "195/195 [==============================] - 59s 301ms/step - loss: 1.3661 - accuracy: 0.5034 - val_loss: 2.2503 - val_accuracy: 0.1903\n",
      "Epoch 3/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 1.1866 - accuracy: 0.5744\n",
      "Epoch 00003: val_accuracy improved from 0.19030 to 0.44100, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model4_03-0.44.hdf5\n",
      "195/195 [==============================] - 59s 301ms/step - loss: 1.1869 - accuracy: 0.5743 - val_loss: 1.9132 - val_accuracy: 0.4410\n",
      "Epoch 4/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 1.0686 - accuracy: 0.6165\n",
      "Epoch 00004: val_accuracy improved from 0.44100 to 0.48850, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model4_04-0.49.hdf5\n",
      "195/195 [==============================] - 59s 301ms/step - loss: 1.0680 - accuracy: 0.6166 - val_loss: 2.1404 - val_accuracy: 0.4885\n",
      "Epoch 5/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.9866 - accuracy: 0.6485\n",
      "Epoch 00005: val_accuracy improved from 0.48850 to 0.62000, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model4_05-0.62.hdf5\n",
      "195/195 [==============================] - 59s 301ms/step - loss: 0.9866 - accuracy: 0.6484 - val_loss: 1.2004 - val_accuracy: 0.6200\n",
      "Epoch 6/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.9110 - accuracy: 0.6794\n",
      "Epoch 00006: val_accuracy did not improve from 0.62000\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.9108 - accuracy: 0.6794 - val_loss: 1.5936 - val_accuracy: 0.5615\n",
      "Epoch 7/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.8595 - accuracy: 0.6966\n",
      "Epoch 00007: val_accuracy improved from 0.62000 to 0.65450, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model4_07-0.65.hdf5\n",
      "195/195 [==============================] - 59s 301ms/step - loss: 0.8598 - accuracy: 0.6964 - val_loss: 1.1688 - val_accuracy: 0.6545\n",
      "Epoch 8/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.8077 - accuracy: 0.7151\n",
      "Epoch 00008: val_accuracy did not improve from 0.65450\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.8076 - accuracy: 0.7152 - val_loss: 1.9574 - val_accuracy: 0.5217\n",
      "Epoch 9/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.7670 - accuracy: 0.7304\n",
      "Epoch 00009: val_accuracy improved from 0.65450 to 0.70890, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model4_09-0.71.hdf5\n",
      "195/195 [==============================] - 59s 301ms/step - loss: 0.7668 - accuracy: 0.7304 - val_loss: 0.9380 - val_accuracy: 0.7089\n",
      "Epoch 10/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.7375 - accuracy: 0.7394\n",
      "Epoch 00010: val_accuracy did not improve from 0.70890\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.7381 - accuracy: 0.7393 - val_loss: 2.8126 - val_accuracy: 0.4757\n",
      "Epoch 11/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.7033 - accuracy: 0.7523\n",
      "Epoch 00011: val_accuracy improved from 0.70890 to 0.73420, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model4_11-0.73.hdf5\n",
      "195/195 [==============================] - 59s 301ms/step - loss: 0.7030 - accuracy: 0.7523 - val_loss: 0.8638 - val_accuracy: 0.7342\n",
      "Epoch 12/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.6767 - accuracy: 0.7622\n",
      "Epoch 00012: val_accuracy did not improve from 0.73420\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.6764 - accuracy: 0.7623 - val_loss: 1.4645 - val_accuracy: 0.6306\n",
      "Epoch 13/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.6520 - accuracy: 0.7728\n",
      "Epoch 00013: val_accuracy did not improve from 0.73420\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.6517 - accuracy: 0.7731 - val_loss: 1.1560 - val_accuracy: 0.6718\n",
      "Epoch 14/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.6347 - accuracy: 0.7785\n",
      "Epoch 00014: val_accuracy did not improve from 0.73420\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.6350 - accuracy: 0.7784 - val_loss: 1.1602 - val_accuracy: 0.6892\n",
      "Epoch 15/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.6167 - accuracy: 0.7845\n",
      "Epoch 00015: val_accuracy did not improve from 0.73420\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.6167 - accuracy: 0.7845 - val_loss: 1.3772 - val_accuracy: 0.6478\n",
      "Epoch 16/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.5980 - accuracy: 0.7921\n",
      "Epoch 00016: val_accuracy did not improve from 0.73420\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.5975 - accuracy: 0.7923 - val_loss: 1.0045 - val_accuracy: 0.7176\n",
      "Epoch 17/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.5810 - accuracy: 0.7972\n",
      "Epoch 00017: val_accuracy did not improve from 0.73420\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.5808 - accuracy: 0.7973 - val_loss: 1.4011 - val_accuracy: 0.6322\n",
      "Epoch 18/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.5676 - accuracy: 0.8023\n",
      "Epoch 00018: val_accuracy did not improve from 0.73420\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.5677 - accuracy: 0.8023 - val_loss: 1.0604 - val_accuracy: 0.7087\n",
      "Epoch 19/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.5529 - accuracy: 0.8073\n",
      "Epoch 00019: val_accuracy improved from 0.73420 to 0.74620, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model4_19-0.75.hdf5\n",
      "195/195 [==============================] - 59s 301ms/step - loss: 0.5527 - accuracy: 0.8075 - val_loss: 0.8668 - val_accuracy: 0.7462\n",
      "Epoch 20/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.5429 - accuracy: 0.8106\n",
      "Epoch 00020: val_accuracy did not improve from 0.74620\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.5430 - accuracy: 0.8106 - val_loss: 0.8953 - val_accuracy: 0.7378\n",
      "Epoch 21/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.5328 - accuracy: 0.8126\n",
      "Epoch 00021: val_accuracy did not improve from 0.74620\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.5326 - accuracy: 0.8127 - val_loss: 1.0524 - val_accuracy: 0.7157\n",
      "Epoch 22/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.5231 - accuracy: 0.8184\n",
      "Epoch 00022: val_accuracy did not improve from 0.74620\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.5239 - accuracy: 0.8180 - val_loss: 1.0577 - val_accuracy: 0.7269\n",
      "Epoch 23/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.5083 - accuracy: 0.8210\n",
      "Epoch 00023: val_accuracy did not improve from 0.74620\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.5085 - accuracy: 0.8212 - val_loss: 1.1614 - val_accuracy: 0.7007\n",
      "Epoch 24/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.5025 - accuracy: 0.8272\n",
      "Epoch 00024: val_accuracy improved from 0.74620 to 0.76850, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model4_24-0.77.hdf5\n",
      "195/195 [==============================] - 59s 301ms/step - loss: 0.5025 - accuracy: 0.8273 - val_loss: 0.7614 - val_accuracy: 0.7685\n",
      "Epoch 25/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.4883 - accuracy: 0.8285\n",
      "Epoch 00025: val_accuracy did not improve from 0.76850\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.4886 - accuracy: 0.8283 - val_loss: 0.8801 - val_accuracy: 0.7589\n",
      "Epoch 26/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.4774 - accuracy: 0.8336\n",
      "Epoch 00026: val_accuracy improved from 0.76850 to 0.79270, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model4_26-0.79.hdf5\n",
      "195/195 [==============================] - 59s 301ms/step - loss: 0.4771 - accuracy: 0.8336 - val_loss: 0.7050 - val_accuracy: 0.7927\n",
      "Epoch 27/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.4795 - accuracy: 0.8326\n",
      "Epoch 00027: val_accuracy did not improve from 0.79270\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.4795 - accuracy: 0.8327 - val_loss: 1.1469 - val_accuracy: 0.7176\n",
      "Epoch 28/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.4654 - accuracy: 0.8384\n",
      "Epoch 00028: val_accuracy did not improve from 0.79270\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.4654 - accuracy: 0.8384 - val_loss: 1.2111 - val_accuracy: 0.7168\n",
      "Epoch 29/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.4614 - accuracy: 0.8398\n",
      "Epoch 00029: val_accuracy did not improve from 0.79270\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.4619 - accuracy: 0.8396 - val_loss: 0.7486 - val_accuracy: 0.7850\n",
      "Epoch 30/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.4497 - accuracy: 0.8432\n",
      "Epoch 00030: val_accuracy improved from 0.79270 to 0.79300, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model4_30-0.79.hdf5\n",
      "195/195 [==============================] - 59s 301ms/step - loss: 0.4493 - accuracy: 0.8433 - val_loss: 0.7231 - val_accuracy: 0.7930\n",
      "Epoch 31/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.4472 - accuracy: 0.8442\n",
      "Epoch 00031: val_accuracy did not improve from 0.79300\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.4471 - accuracy: 0.8444 - val_loss: 0.8326 - val_accuracy: 0.7646\n",
      "Epoch 32/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.4424 - accuracy: 0.8449\n",
      "Epoch 00032: val_accuracy did not improve from 0.79300\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.4422 - accuracy: 0.8449 - val_loss: 1.0786 - val_accuracy: 0.7239\n",
      "Epoch 33/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.4374 - accuracy: 0.8469\n",
      "Epoch 00033: val_accuracy improved from 0.79300 to 0.80390, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model4_33-0.80.hdf5\n",
      "195/195 [==============================] - 59s 301ms/step - loss: 0.4377 - accuracy: 0.8469 - val_loss: 0.6970 - val_accuracy: 0.8039\n",
      "Epoch 34/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.4279 - accuracy: 0.8509\n",
      "Epoch 00034: val_accuracy did not improve from 0.80390\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.4280 - accuracy: 0.8509 - val_loss: 1.1122 - val_accuracy: 0.7356\n",
      "Epoch 35/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.4265 - accuracy: 0.8507\n",
      "Epoch 00035: val_accuracy did not improve from 0.80390\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.4261 - accuracy: 0.8507 - val_loss: 0.9059 - val_accuracy: 0.7630\n",
      "Epoch 36/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.4150 - accuracy: 0.8539\n",
      "Epoch 00036: val_accuracy did not improve from 0.80390\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.4151 - accuracy: 0.8539 - val_loss: 1.1688 - val_accuracy: 0.7184\n",
      "Epoch 37/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.4095 - accuracy: 0.8566\n",
      "Epoch 00037: val_accuracy improved from 0.80390 to 0.80720, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model4_37-0.81.hdf5\n",
      "195/195 [==============================] - 59s 301ms/step - loss: 0.4094 - accuracy: 0.8567 - val_loss: 0.6776 - val_accuracy: 0.8072\n",
      "Epoch 38/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.4063 - accuracy: 0.8573\n",
      "Epoch 00038: val_accuracy improved from 0.80720 to 0.81510, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model4_38-0.82.hdf5\n",
      "195/195 [==============================] - 59s 301ms/step - loss: 0.4062 - accuracy: 0.8573 - val_loss: 0.6534 - val_accuracy: 0.8151\n",
      "Epoch 39/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.4013 - accuracy: 0.8591\n",
      "Epoch 00039: val_accuracy did not improve from 0.81510\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.4013 - accuracy: 0.8591 - val_loss: 0.8656 - val_accuracy: 0.7855\n",
      "Epoch 40/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.3940 - accuracy: 0.8613\n",
      "Epoch 00040: val_accuracy did not improve from 0.81510\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.3940 - accuracy: 0.8612 - val_loss: 0.8044 - val_accuracy: 0.7890\n",
      "Epoch 41/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.3918 - accuracy: 0.8624\n",
      "Epoch 00041: val_accuracy did not improve from 0.81510\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.3922 - accuracy: 0.8621 - val_loss: 1.1655 - val_accuracy: 0.7376\n",
      "Epoch 42/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.3905 - accuracy: 0.8637\n",
      "Epoch 00042: val_accuracy did not improve from 0.81510\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.3907 - accuracy: 0.8635 - val_loss: 0.6769 - val_accuracy: 0.8106\n",
      "Epoch 43/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8653\n",
      "Epoch 00043: val_accuracy did not improve from 0.81510\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.3825 - accuracy: 0.8655 - val_loss: 0.8867 - val_accuracy: 0.7758\n",
      "Epoch 44/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.3794 - accuracy: 0.8673\n",
      "Epoch 00044: val_accuracy did not improve from 0.81510\n",
      "195/195 [==============================] - 58s 299ms/step - loss: 0.3797 - accuracy: 0.8674 - val_loss: 0.6781 - val_accuracy: 0.8115\n",
      "Epoch 45/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.3766 - accuracy: 0.8672\n",
      "Epoch 00045: val_accuracy did not improve from 0.81510\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.3766 - accuracy: 0.8672 - val_loss: 0.8694 - val_accuracy: 0.7861\n",
      "Epoch 46/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.3701 - accuracy: 0.8698\n",
      "Epoch 00046: val_accuracy did not improve from 0.81510\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.3699 - accuracy: 0.8699 - val_loss: 1.1198 - val_accuracy: 0.7407\n",
      "Epoch 47/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.3703 - accuracy: 0.8698\n",
      "Epoch 00047: val_accuracy did not improve from 0.81510\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.3700 - accuracy: 0.8699 - val_loss: 0.7218 - val_accuracy: 0.8016\n",
      "Epoch 48/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.3670 - accuracy: 0.8714\n",
      "Epoch 00048: val_accuracy did not improve from 0.81510\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.3672 - accuracy: 0.8714 - val_loss: 0.7497 - val_accuracy: 0.8040\n",
      "Epoch 49/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.3571 - accuracy: 0.8752\n",
      "Epoch 00049: val_accuracy improved from 0.81510 to 0.82350, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model4_49-0.82.hdf5\n",
      "195/195 [==============================] - 59s 301ms/step - loss: 0.3571 - accuracy: 0.8751 - val_loss: 0.6711 - val_accuracy: 0.8235\n",
      "Epoch 50/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.3542 - accuracy: 0.8739\n",
      "Epoch 00050: val_accuracy did not improve from 0.82350\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.3541 - accuracy: 0.8739 - val_loss: 0.7510 - val_accuracy: 0.8079\n",
      "Epoch 51/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.3522 - accuracy: 0.8754\n",
      "Epoch 00051: val_accuracy improved from 0.82350 to 0.83610, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model4_51-0.84.hdf5\n",
      "195/195 [==============================] - 59s 301ms/step - loss: 0.3524 - accuracy: 0.8754 - val_loss: 0.5678 - val_accuracy: 0.8361\n",
      "Epoch 52/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.3508 - accuracy: 0.8760\n",
      "Epoch 00052: val_accuracy did not improve from 0.83610\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.3508 - accuracy: 0.8760 - val_loss: 0.7490 - val_accuracy: 0.8012\n",
      "Epoch 53/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.3455 - accuracy: 0.8780\n",
      "Epoch 00053: val_accuracy did not improve from 0.83610\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.3456 - accuracy: 0.8781 - val_loss: 0.7325 - val_accuracy: 0.8150\n",
      "Epoch 54/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.3437 - accuracy: 0.8782\n",
      "Epoch 00054: val_accuracy did not improve from 0.83610\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.3435 - accuracy: 0.8782 - val_loss: 0.6157 - val_accuracy: 0.8282\n",
      "Epoch 55/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.3383 - accuracy: 0.8809\n",
      "Epoch 00055: val_accuracy did not improve from 0.83610\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.3381 - accuracy: 0.8810 - val_loss: 0.7196 - val_accuracy: 0.8118\n",
      "Epoch 56/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.3415 - accuracy: 0.8801\n",
      "Epoch 00056: val_accuracy did not improve from 0.83610\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.3416 - accuracy: 0.8800 - val_loss: 0.9316 - val_accuracy: 0.7835\n",
      "Epoch 57/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.3349 - accuracy: 0.8812\n",
      "Epoch 00057: val_accuracy did not improve from 0.83610\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.3346 - accuracy: 0.8813 - val_loss: 1.0981 - val_accuracy: 0.7480\n",
      "Epoch 58/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.3320 - accuracy: 0.8827\n",
      "Epoch 00058: val_accuracy did not improve from 0.83610\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.3318 - accuracy: 0.8828 - val_loss: 0.7190 - val_accuracy: 0.8167\n",
      "Epoch 59/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.3301 - accuracy: 0.8842\n",
      "Epoch 00059: val_accuracy did not improve from 0.83610\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.3297 - accuracy: 0.8842 - val_loss: 0.8712 - val_accuracy: 0.7893\n",
      "Epoch 60/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.3267 - accuracy: 0.8835\n",
      "Epoch 00060: val_accuracy did not improve from 0.83610\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.3266 - accuracy: 0.8836 - val_loss: 0.8914 - val_accuracy: 0.7858\n",
      "Epoch 61/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.3261 - accuracy: 0.8850\n",
      "Epoch 00061: val_accuracy did not improve from 0.83610\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.3258 - accuracy: 0.8851 - val_loss: 0.6456 - val_accuracy: 0.8250\n",
      "Epoch 62/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.3209 - accuracy: 0.8865\n",
      "Epoch 00062: val_accuracy did not improve from 0.83610\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.3210 - accuracy: 0.8865 - val_loss: 0.6300 - val_accuracy: 0.8296\n",
      "Epoch 63/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.3216 - accuracy: 0.8856\n",
      "Epoch 00063: val_accuracy did not improve from 0.83610\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.3212 - accuracy: 0.8857 - val_loss: 0.6779 - val_accuracy: 0.8112\n",
      "Epoch 64/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.3155 - accuracy: 0.8876\n",
      "Epoch 00064: val_accuracy did not improve from 0.83610\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.3154 - accuracy: 0.8876 - val_loss: 0.7649 - val_accuracy: 0.8134\n",
      "Epoch 65/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.3082 - accuracy: 0.8911\n",
      "Epoch 00065: val_accuracy did not improve from 0.83610\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.3090 - accuracy: 0.8909 - val_loss: 0.9613 - val_accuracy: 0.7889\n",
      "Epoch 66/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.3109 - accuracy: 0.8895\n",
      "Epoch 00066: val_accuracy did not improve from 0.83610\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.3115 - accuracy: 0.8893 - val_loss: 0.6972 - val_accuracy: 0.8156\n",
      "Epoch 67/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.3104 - accuracy: 0.8899\n",
      "Epoch 00067: val_accuracy did not improve from 0.83610\n",
      "\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.3105 - accuracy: 0.8899 - val_loss: 0.9667 - val_accuracy: 0.7855\n",
      "Epoch 68/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2654 - accuracy: 0.9045\n",
      "Epoch 00068: val_accuracy improved from 0.83610 to 0.86340, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model4_68-0.86.hdf5\n",
      "195/195 [==============================] - 59s 301ms/step - loss: 0.2658 - accuracy: 0.9044 - val_loss: 0.4823 - val_accuracy: 0.8634\n",
      "Epoch 69/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2482 - accuracy: 0.9120\n",
      "Epoch 00069: val_accuracy improved from 0.86340 to 0.86590, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model4_69-0.87.hdf5\n",
      "195/195 [==============================] - 59s 301ms/step - loss: 0.2480 - accuracy: 0.9121 - val_loss: 0.4892 - val_accuracy: 0.8659\n",
      "Epoch 70/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2426 - accuracy: 0.9132\n",
      "Epoch 00070: val_accuracy did not improve from 0.86590\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.2424 - accuracy: 0.9133 - val_loss: 0.4795 - val_accuracy: 0.8637\n",
      "Epoch 71/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2418 - accuracy: 0.9133\n",
      "Epoch 00071: val_accuracy did not improve from 0.86590\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.2415 - accuracy: 0.9134 - val_loss: 0.5331 - val_accuracy: 0.8573\n",
      "Epoch 72/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2363 - accuracy: 0.9162\n",
      "Epoch 00072: val_accuracy did not improve from 0.86590\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.2360 - accuracy: 0.9162 - val_loss: 0.5086 - val_accuracy: 0.8637\n",
      "Epoch 73/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2360 - accuracy: 0.9164\n",
      "Epoch 00073: val_accuracy did not improve from 0.86590\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.2360 - accuracy: 0.9165 - val_loss: 0.5293 - val_accuracy: 0.8612\n",
      "Epoch 74/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2334 - accuracy: 0.9181\n",
      "Epoch 00074: val_accuracy did not improve from 0.86590\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.2332 - accuracy: 0.9182 - val_loss: 0.5277 - val_accuracy: 0.8602\n",
      "Epoch 75/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2312 - accuracy: 0.9174\n",
      "Epoch 00075: val_accuracy improved from 0.86590 to 0.86890, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model4_75-0.87.hdf5\n",
      "195/195 [==============================] - 59s 301ms/step - loss: 0.2314 - accuracy: 0.9174 - val_loss: 0.4848 - val_accuracy: 0.8689\n",
      "Epoch 76/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2255 - accuracy: 0.9198\n",
      "Epoch 00076: val_accuracy did not improve from 0.86890\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.2257 - accuracy: 0.9198 - val_loss: 0.5205 - val_accuracy: 0.8607\n",
      "Epoch 77/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2259 - accuracy: 0.9200\n",
      "Epoch 00077: val_accuracy did not improve from 0.86890\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.2256 - accuracy: 0.9200 - val_loss: 0.5112 - val_accuracy: 0.8644\n",
      "Epoch 78/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2261 - accuracy: 0.9203\n",
      "Epoch 00078: val_accuracy improved from 0.86890 to 0.87080, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model4_78-0.87.hdf5\n",
      "195/195 [==============================] - 59s 301ms/step - loss: 0.2260 - accuracy: 0.9204 - val_loss: 0.4802 - val_accuracy: 0.8708\n",
      "Epoch 79/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2258 - accuracy: 0.9193\n",
      "Epoch 00079: val_accuracy did not improve from 0.87080\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.2260 - accuracy: 0.9192 - val_loss: 0.5028 - val_accuracy: 0.8660\n",
      "Epoch 80/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2245 - accuracy: 0.9203\n",
      "Epoch 00080: val_accuracy improved from 0.87080 to 0.87160, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model4_80-0.87.hdf5\n",
      "195/195 [==============================] - 59s 301ms/step - loss: 0.2247 - accuracy: 0.9203 - val_loss: 0.4873 - val_accuracy: 0.8716\n",
      "Epoch 81/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2219 - accuracy: 0.9209\n",
      "Epoch 00081: val_accuracy did not improve from 0.87160\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.2218 - accuracy: 0.9209 - val_loss: 0.5059 - val_accuracy: 0.8672\n",
      "Epoch 82/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2209 - accuracy: 0.9214\n",
      "Epoch 00082: val_accuracy did not improve from 0.87160\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.2209 - accuracy: 0.9214 - val_loss: 0.4989 - val_accuracy: 0.8686\n",
      "Epoch 83/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2227 - accuracy: 0.9212\n",
      "Epoch 00083: val_accuracy did not improve from 0.87160\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.2224 - accuracy: 0.9213 - val_loss: 0.5171 - val_accuracy: 0.8645\n",
      "Epoch 84/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2201 - accuracy: 0.9219\n",
      "Epoch 00084: val_accuracy did not improve from 0.87160\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.2202 - accuracy: 0.9220 - val_loss: 0.4935 - val_accuracy: 0.8711\n",
      "Epoch 85/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2187 - accuracy: 0.9222\n",
      "Epoch 00085: val_accuracy did not improve from 0.87160\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.2188 - accuracy: 0.9221 - val_loss: 0.5030 - val_accuracy: 0.8680\n",
      "Epoch 86/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2159 - accuracy: 0.9217\n",
      "Epoch 00086: val_accuracy did not improve from 0.87160\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.2162 - accuracy: 0.9216 - val_loss: 0.5246 - val_accuracy: 0.8655\n",
      "Epoch 87/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2202 - accuracy: 0.9222\n",
      "Epoch 00087: val_accuracy did not improve from 0.87160\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.2201 - accuracy: 0.9222 - val_loss: 0.5086 - val_accuracy: 0.8635\n",
      "Epoch 88/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2198 - accuracy: 0.9213\n",
      "Epoch 00088: val_accuracy did not improve from 0.87160\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.2200 - accuracy: 0.9212 - val_loss: 0.5080 - val_accuracy: 0.8695\n",
      "Epoch 89/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2152 - accuracy: 0.9224\n",
      "Epoch 00089: val_accuracy did not improve from 0.87160\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.2150 - accuracy: 0.9224 - val_loss: 0.5341 - val_accuracy: 0.8611\n",
      "Epoch 90/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2167 - accuracy: 0.9217\n",
      "Epoch 00090: val_accuracy did not improve from 0.87160\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.2169 - accuracy: 0.9218 - val_loss: 0.5030 - val_accuracy: 0.8675\n",
      "Epoch 91/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2169 - accuracy: 0.9234\n",
      "Epoch 00091: val_accuracy did not improve from 0.87160\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.2168 - accuracy: 0.9234 - val_loss: 0.5199 - val_accuracy: 0.8657\n",
      "Epoch 92/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2134 - accuracy: 0.9233\n",
      "Epoch 00092: val_accuracy did not improve from 0.87160\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.2128 - accuracy: 0.9236 - val_loss: 0.5178 - val_accuracy: 0.8633\n",
      "Epoch 93/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2140 - accuracy: 0.9238\n",
      "Epoch 00093: val_accuracy did not improve from 0.87160\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.2139 - accuracy: 0.9239 - val_loss: 0.5139 - val_accuracy: 0.8652\n",
      "Epoch 94/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2125 - accuracy: 0.9242\n",
      "Epoch 00094: val_accuracy did not improve from 0.87160\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.2127 - accuracy: 0.9241 - val_loss: 0.5276 - val_accuracy: 0.8646\n",
      "Epoch 95/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2139 - accuracy: 0.9230\n",
      "Epoch 00095: val_accuracy did not improve from 0.87160\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.2136 - accuracy: 0.9231 - val_loss: 0.5513 - val_accuracy: 0.8597\n",
      "Epoch 96/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2139 - accuracy: 0.9249\n",
      "Epoch 00096: val_accuracy did not improve from 0.87160\n",
      "\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.2138 - accuracy: 0.9250 - val_loss: 0.4776 - val_accuracy: 0.8710\n",
      "Epoch 97/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2061 - accuracy: 0.9265\n",
      "Epoch 00097: val_accuracy did not improve from 0.87160\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.2068 - accuracy: 0.9263 - val_loss: 0.5014 - val_accuracy: 0.8693\n",
      "Epoch 98/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2035 - accuracy: 0.9262\n",
      "Epoch 00098: val_accuracy did not improve from 0.87160\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.2036 - accuracy: 0.9261 - val_loss: 0.5089 - val_accuracy: 0.8675\n",
      "Epoch 99/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2038 - accuracy: 0.9263\n",
      "Epoch 00099: val_accuracy did not improve from 0.87160\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.2036 - accuracy: 0.9264 - val_loss: 0.5057 - val_accuracy: 0.8687\n",
      "Epoch 100/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2046 - accuracy: 0.9265\n",
      "Epoch 00100: val_accuracy did not improve from 0.87160\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.2046 - accuracy: 0.9265 - val_loss: 0.5033 - val_accuracy: 0.8694\n",
      "Epoch 101/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2084 - accuracy: 0.9248\n",
      "Epoch 00101: val_accuracy did not improve from 0.87160\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.2083 - accuracy: 0.9248 - val_loss: 0.5015 - val_accuracy: 0.8692\n",
      "Epoch 102/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2031 - accuracy: 0.9265\n",
      "Epoch 00102: val_accuracy did not improve from 0.87160\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.2035 - accuracy: 0.9264 - val_loss: 0.5028 - val_accuracy: 0.8675\n",
      "Epoch 103/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2034 - accuracy: 0.9260\n",
      "Epoch 00103: val_accuracy did not improve from 0.87160\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.2036 - accuracy: 0.9260 - val_loss: 0.4995 - val_accuracy: 0.8694\n",
      "Epoch 104/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2068 - accuracy: 0.9257\n",
      "Epoch 00104: val_accuracy did not improve from 0.87160\n",
      "195/195 [==============================] - 58s 297ms/step - loss: 0.2067 - accuracy: 0.9258 - val_loss: 0.5052 - val_accuracy: 0.8681\n",
      "Epoch 105/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.1997 - accuracy: 0.9285\n",
      "Epoch 00105: val_accuracy did not improve from 0.87160\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.1996 - accuracy: 0.9285 - val_loss: 0.4970 - val_accuracy: 0.8693\n",
      "Epoch 106/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2010 - accuracy: 0.9282\n",
      "Epoch 00106: val_accuracy did not improve from 0.87160\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.2009 - accuracy: 0.9283 - val_loss: 0.5043 - val_accuracy: 0.8687\n",
      "Epoch 107/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2033 - accuracy: 0.9276\n",
      "Epoch 00107: val_accuracy did not improve from 0.87160\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.2033 - accuracy: 0.9275 - val_loss: 0.5058 - val_accuracy: 0.8691\n",
      "Epoch 108/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2052 - accuracy: 0.9271\n",
      "Epoch 00108: val_accuracy did not improve from 0.87160\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.2054 - accuracy: 0.9271 - val_loss: 0.5037 - val_accuracy: 0.8693\n",
      "Epoch 109/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2053 - accuracy: 0.9273\n",
      "Epoch 00109: val_accuracy did not improve from 0.87160\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.2052 - accuracy: 0.9272 - val_loss: 0.5083 - val_accuracy: 0.8674\n",
      "Epoch 110/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2042 - accuracy: 0.9278\n",
      "Epoch 00110: val_accuracy did not improve from 0.87160\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.2043 - accuracy: 0.9278 - val_loss: 0.5007 - val_accuracy: 0.8695\n",
      "Epoch 111/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2026 - accuracy: 0.9277\n",
      "Epoch 00111: val_accuracy did not improve from 0.87160\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.2028 - accuracy: 0.9276 - val_loss: 0.5015 - val_accuracy: 0.8693\n",
      "Epoch 112/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.1986 - accuracy: 0.9288\n",
      "Epoch 00112: val_accuracy did not improve from 0.87160\n",
      "\n",
      "Epoch 00112: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.1986 - accuracy: 0.9288 - val_loss: 0.4992 - val_accuracy: 0.8702\n",
      "Epoch 113/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2035 - accuracy: 0.9259\n",
      "Epoch 00113: val_accuracy did not improve from 0.87160\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.2035 - accuracy: 0.9259 - val_loss: 0.5008 - val_accuracy: 0.8696\n",
      "Epoch 114/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2050 - accuracy: 0.9258\n",
      "Epoch 00114: val_accuracy did not improve from 0.87160\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.2047 - accuracy: 0.9259 - val_loss: 0.5029 - val_accuracy: 0.8694\n",
      "Epoch 115/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2030 - accuracy: 0.9261\n",
      "Epoch 00115: val_accuracy did not improve from 0.87160\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.2029 - accuracy: 0.9262 - val_loss: 0.5032 - val_accuracy: 0.8692\n",
      "Epoch 116/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2024 - accuracy: 0.9281\n",
      "Epoch 00116: val_accuracy did not improve from 0.87160\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.2022 - accuracy: 0.9281 - val_loss: 0.5033 - val_accuracy: 0.8690\n",
      "Epoch 117/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2003 - accuracy: 0.9288\n",
      "Epoch 00117: val_accuracy did not improve from 0.87160\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.2003 - accuracy: 0.9288 - val_loss: 0.5030 - val_accuracy: 0.8694\n",
      "Epoch 118/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2015 - accuracy: 0.9259\n",
      "Epoch 00118: val_accuracy did not improve from 0.87160\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.2018 - accuracy: 0.9259 - val_loss: 0.5023 - val_accuracy: 0.8689\n",
      "Epoch 119/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2014 - accuracy: 0.9274\n",
      "Epoch 00119: val_accuracy did not improve from 0.87160\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.2014 - accuracy: 0.9273 - val_loss: 0.5032 - val_accuracy: 0.8689\n",
      "Epoch 120/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.1993 - accuracy: 0.9284\n",
      "Epoch 00120: val_accuracy did not improve from 0.87160\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.1995 - accuracy: 0.9284 - val_loss: 0.5026 - val_accuracy: 0.8690\n",
      "Epoch 121/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2035 - accuracy: 0.9273\n",
      "Epoch 00121: val_accuracy did not improve from 0.87160\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.2033 - accuracy: 0.9274 - val_loss: 0.5038 - val_accuracy: 0.8691\n",
      "Epoch 122/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2032 - accuracy: 0.9267\n",
      "Epoch 00122: val_accuracy did not improve from 0.87160\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.2031 - accuracy: 0.9267 - val_loss: 0.5021 - val_accuracy: 0.8689\n",
      "Epoch 123/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2034 - accuracy: 0.9276\n",
      "Epoch 00123: val_accuracy did not improve from 0.87160\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.2038 - accuracy: 0.9274 - val_loss: 0.5026 - val_accuracy: 0.8691\n",
      "Epoch 124/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2046 - accuracy: 0.9264\n",
      "Epoch 00124: val_accuracy did not improve from 0.87160\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.2047 - accuracy: 0.9263 - val_loss: 0.5015 - val_accuracy: 0.8693\n",
      "Epoch 125/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2022 - accuracy: 0.9271\n",
      "Epoch 00125: val_accuracy did not improve from 0.87160\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.2022 - accuracy: 0.9271 - val_loss: 0.5024 - val_accuracy: 0.8689\n",
      "Epoch 126/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2028 - accuracy: 0.9281\n",
      "Epoch 00126: val_accuracy did not improve from 0.87160\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.2027 - accuracy: 0.9282 - val_loss: 0.5033 - val_accuracy: 0.8689\n",
      "Epoch 127/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2030 - accuracy: 0.9271\n",
      "Epoch 00127: val_accuracy did not improve from 0.87160\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.2027 - accuracy: 0.9273 - val_loss: 0.5031 - val_accuracy: 0.8690\n",
      "Epoch 128/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.1997 - accuracy: 0.9286\n",
      "Epoch 00128: val_accuracy did not improve from 0.87160\n",
      "\n",
      "Epoch 00128: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "195/195 [==============================] - 58s 298ms/step - loss: 0.1997 - accuracy: 0.9286 - val_loss: 0.5039 - val_accuracy: 0.8688\n",
      "Epoch 129/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2047 - accuracy: 0.9263\n",
      "Epoch 00129: val_accuracy did not improve from 0.87160\n",
      "195/195 [==============================] - 58s 297ms/step - loss: 0.2046 - accuracy: 0.9264 - val_loss: 0.5036 - val_accuracy: 0.8690\n",
      "Epoch 130/300\n",
      "194/195 [============================>.] - ETA: 0s - loss: 0.2025 - accuracy: 0.9284\n",
      "Epoch 00130: val_accuracy did not improve from 0.87160\n",
      "195/195 [==============================] - 58s 297ms/step - loss: 0.2025 - accuracy: 0.9284 - val_loss: 0.5010 - val_accuracy: 0.8690\n"
     ]
    }
   ],
   "source": [
    "model_4.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "patience = 50\n",
    "base_path = '/home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/'\n",
    "checkpoint_file_name = base_path + 'CIFAR_model4' + '_{epoch:02d}-{val_accuracy:.2f}.hdf5'\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(checkpoint_file_name, monitor='val_accuracy', verbose=1, save_best_only=True)\n",
    "early_stop = EarlyStopping('val_accuracy', mode='max', patience = patience)\n",
    "reduce_LR = ReduceLROnPlateau(monitor='val_accuracy', mode='max', factor=0.1, patience=int(patience/3), verbose=1)\n",
    "\n",
    "callbacks = [model_checkpoint, early_stop, reduce_LR]\n",
    "\n",
    "epochs = 300\n",
    "batch_size = 256\n",
    "\n",
    "#https://keras.io/api/preprocessing/image/#flow-method\n",
    "\n",
    "history_4 = model_4.fit(data_generator.flow(X_train, y_train, batch_size),\n",
    "                    steps_per_epoch = int(len(X_train)/batch_size),\n",
    "                    epochs = epochs,\n",
    "                    callbacks = callbacks,\n",
    "                    validation_data = (X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#history plot for accyracy\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.plot(history_3.history['accuracy'])\n",
    "plt.plot(history_3.history['val_accuracy'])\n",
    "plt.title(\"Model Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend([\"train\", \"test\"], loc=\"upper left\")\n",
    "plt.show()\n",
    "\n",
    "# history plot for accuracy\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.plot(history_3.history[\"loss\"])\n",
    "plt.plot(history_3.history[\"val_loss\"])\n",
    "plt.title(\"Model Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend([\"train\", \"test\"], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 4s 432us/sample - loss: 0.4873 - accuracy: 0.8716\n",
      "[0.487310631595552, 0.8716]\n"
     ]
    }
   ],
   "source": [
    "best_model_4 = tf.keras.models.load_model('/home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model4_80-0.87.hdf5')\n",
    "scores = best_model_4.evaluate(X_test, y_test, verbose=1)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model -5:\n",
    "- dropout = 0.2\n",
    "- compression = 0.3\n",
    "- using conv instead of fully connected layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BN-->ReLU-->Conv2D-->Dropout-->concat(input, output)-->(put in loop)\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "num_classes = 10\n",
    "\n",
    "def denseblock(input, num_filter, dropout_rate):\n",
    "    global compression      # to keep the growth rate of number of filters\n",
    "    temp = input\n",
    "    for _ in range(l): \n",
    "        BatchNorm = layers.BatchNormalization()(temp)\n",
    "        relu = layers.Activation('relu')(BatchNorm)\n",
    "        Conv2D_7_7= layers.SeparableConv2D(int(num_filter*compression), (7,7), use_bias=False, padding='same')(relu)\n",
    "        if dropout_rate>0:\n",
    "            Conv2D_7_7 = layers.Dropout(dropout_rate)(Conv2D_7_7)\n",
    "\n",
    "        #concat the input(temp) and output(conv2d_7_7) , in resnet we add but here we concat \n",
    "        concat = layers.Concatenate(axis=-1)([temp,Conv2D_7_7])\n",
    "        \n",
    "        #change the concat as input\n",
    "        temp = concat\n",
    "        \n",
    "    return temp\n",
    "\n",
    "#BN-->relu-->conv2d(1x1)-->dropout-->avg_pool\n",
    "def transition(input, num_filter, dropout_rate):\n",
    "    global compression\n",
    "    BatchNorm = layers.BatchNormalization()(input)\n",
    "    relu = layers.Activation('relu')(BatchNorm)\n",
    "    Conv2D_BottleNeck = layers.SeparableConvolution2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
    "    if dropout_rate>0:\n",
    "         Conv2D_BottleNeck = layers.Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
    "    avg = layers.AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
    "    return avg\n",
    "\n",
    "#BN-->relu-->avgpool-->flat-->softmax\n",
    "def output_layer(input):\n",
    "    global compression\n",
    "    BatchNorm = layers.BatchNormalization()(input)\n",
    "    relu = layers.Activation('relu')(BatchNorm)\n",
    "    AvgPooling = layers.AveragePooling2D(pool_size=(2,2))(relu)\n",
    "    conv_op = layers.SeparableConvolution2D(num_classes, (2,2), padding='valid')(AvgPooling)\n",
    "    flat = layers.Flatten()(conv_op)\n",
    "    output = layers.Dense(num_classes, activation='softmax')(flat)\n",
    "    return output\n",
    "\n",
    "# Hyperparameters\n",
    "l = 21\n",
    "num_filter = 48\n",
    "compression = 0.3\n",
    "dropout_rate = 0.2\n",
    "num_classes = 10\n",
    "\n",
    "input = layers.Input(shape=(input_size))\n",
    "First_Conv2D = layers.Conv2D(num_filter, (7,7), use_bias=False ,padding='same')(input)\n",
    "\n",
    "#First dense and transition block\n",
    "First_Block = denseblock(First_Conv2D, num_filter, dropout_rate)\n",
    "First_Transition = transition(First_Block, num_filter, dropout_rate)\n",
    "\n",
    "#Second dense and transition block\n",
    "Second_Block = denseblock(First_Transition, num_filter, dropout_rate)\n",
    "Second_Transition = transition(Second_Block, num_filter, dropout_rate)\n",
    "\n",
    "#Third dense and transition block\n",
    "Third_Block = denseblock(Second_Transition, num_filter, dropout_rate)\n",
    "Third_Transition = transition(Third_Block, num_filter, dropout_rate)\n",
    "\n",
    "#last dense and output block\n",
    "Last_Block = denseblock(Third_Transition,  num_filter, dropout_rate)\n",
    "output = output_layer(Last_Block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_20\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_24 (InputLayer)           [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 32, 32, 48)   7056        input_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2476 (Batch (None, 32, 32, 48)   192         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2476 (Activation)    (None, 32, 32, 48)   0           batch_normalization_2476[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2463 (Separabl (None, 32, 32, 14)   3024        activation_2476[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1339 (Dropout)          (None, 32, 32, 14)   0           separable_conv2d_2463[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2384 (Concatenate)  (None, 32, 32, 62)   0           conv2d_32[0][0]                  \n",
      "                                                                 dropout_1339[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2477 (Batch (None, 32, 32, 62)   248         concatenate_2384[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2477 (Activation)    (None, 32, 32, 62)   0           batch_normalization_2477[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2464 (Separabl (None, 32, 32, 14)   3906        activation_2477[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1340 (Dropout)          (None, 32, 32, 14)   0           separable_conv2d_2464[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2385 (Concatenate)  (None, 32, 32, 76)   0           concatenate_2384[0][0]           \n",
      "                                                                 dropout_1340[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2478 (Batch (None, 32, 32, 76)   304         concatenate_2385[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2478 (Activation)    (None, 32, 32, 76)   0           batch_normalization_2478[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2465 (Separabl (None, 32, 32, 14)   4788        activation_2478[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1341 (Dropout)          (None, 32, 32, 14)   0           separable_conv2d_2465[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2386 (Concatenate)  (None, 32, 32, 90)   0           concatenate_2385[0][0]           \n",
      "                                                                 dropout_1341[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2479 (Batch (None, 32, 32, 90)   360         concatenate_2386[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2479 (Activation)    (None, 32, 32, 90)   0           batch_normalization_2479[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2466 (Separabl (None, 32, 32, 14)   5670        activation_2479[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1342 (Dropout)          (None, 32, 32, 14)   0           separable_conv2d_2466[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2387 (Concatenate)  (None, 32, 32, 104)  0           concatenate_2386[0][0]           \n",
      "                                                                 dropout_1342[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2480 (Batch (None, 32, 32, 104)  416         concatenate_2387[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2480 (Activation)    (None, 32, 32, 104)  0           batch_normalization_2480[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2467 (Separabl (None, 32, 32, 14)   6552        activation_2480[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1343 (Dropout)          (None, 32, 32, 14)   0           separable_conv2d_2467[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2388 (Concatenate)  (None, 32, 32, 118)  0           concatenate_2387[0][0]           \n",
      "                                                                 dropout_1343[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2481 (Batch (None, 32, 32, 118)  472         concatenate_2388[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2481 (Activation)    (None, 32, 32, 118)  0           batch_normalization_2481[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2468 (Separabl (None, 32, 32, 14)   7434        activation_2481[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1344 (Dropout)          (None, 32, 32, 14)   0           separable_conv2d_2468[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2389 (Concatenate)  (None, 32, 32, 132)  0           concatenate_2388[0][0]           \n",
      "                                                                 dropout_1344[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2482 (Batch (None, 32, 32, 132)  528         concatenate_2389[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2482 (Activation)    (None, 32, 32, 132)  0           batch_normalization_2482[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2469 (Separabl (None, 32, 32, 14)   8316        activation_2482[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1345 (Dropout)          (None, 32, 32, 14)   0           separable_conv2d_2469[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2390 (Concatenate)  (None, 32, 32, 146)  0           concatenate_2389[0][0]           \n",
      "                                                                 dropout_1345[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2483 (Batch (None, 32, 32, 146)  584         concatenate_2390[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2483 (Activation)    (None, 32, 32, 146)  0           batch_normalization_2483[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2470 (Separabl (None, 32, 32, 14)   9198        activation_2483[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1346 (Dropout)          (None, 32, 32, 14)   0           separable_conv2d_2470[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2391 (Concatenate)  (None, 32, 32, 160)  0           concatenate_2390[0][0]           \n",
      "                                                                 dropout_1346[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2484 (Batch (None, 32, 32, 160)  640         concatenate_2391[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2484 (Activation)    (None, 32, 32, 160)  0           batch_normalization_2484[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2471 (Separabl (None, 32, 32, 14)   10080       activation_2484[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1347 (Dropout)          (None, 32, 32, 14)   0           separable_conv2d_2471[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2392 (Concatenate)  (None, 32, 32, 174)  0           concatenate_2391[0][0]           \n",
      "                                                                 dropout_1347[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2485 (Batch (None, 32, 32, 174)  696         concatenate_2392[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2485 (Activation)    (None, 32, 32, 174)  0           batch_normalization_2485[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2472 (Separabl (None, 32, 32, 14)   10962       activation_2485[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1348 (Dropout)          (None, 32, 32, 14)   0           separable_conv2d_2472[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2393 (Concatenate)  (None, 32, 32, 188)  0           concatenate_2392[0][0]           \n",
      "                                                                 dropout_1348[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2486 (Batch (None, 32, 32, 188)  752         concatenate_2393[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2486 (Activation)    (None, 32, 32, 188)  0           batch_normalization_2486[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2473 (Separabl (None, 32, 32, 14)   11844       activation_2486[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1349 (Dropout)          (None, 32, 32, 14)   0           separable_conv2d_2473[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2394 (Concatenate)  (None, 32, 32, 202)  0           concatenate_2393[0][0]           \n",
      "                                                                 dropout_1349[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2487 (Batch (None, 32, 32, 202)  808         concatenate_2394[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2487 (Activation)    (None, 32, 32, 202)  0           batch_normalization_2487[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2474 (Separabl (None, 32, 32, 14)   12726       activation_2487[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1350 (Dropout)          (None, 32, 32, 14)   0           separable_conv2d_2474[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2395 (Concatenate)  (None, 32, 32, 216)  0           concatenate_2394[0][0]           \n",
      "                                                                 dropout_1350[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2488 (Batch (None, 32, 32, 216)  864         concatenate_2395[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2488 (Activation)    (None, 32, 32, 216)  0           batch_normalization_2488[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2475 (Separabl (None, 32, 32, 14)   13608       activation_2488[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1351 (Dropout)          (None, 32, 32, 14)   0           separable_conv2d_2475[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2396 (Concatenate)  (None, 32, 32, 230)  0           concatenate_2395[0][0]           \n",
      "                                                                 dropout_1351[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2489 (Batch (None, 32, 32, 230)  920         concatenate_2396[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2489 (Activation)    (None, 32, 32, 230)  0           batch_normalization_2489[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2476 (Separabl (None, 32, 32, 14)   14490       activation_2489[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1352 (Dropout)          (None, 32, 32, 14)   0           separable_conv2d_2476[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2397 (Concatenate)  (None, 32, 32, 244)  0           concatenate_2396[0][0]           \n",
      "                                                                 dropout_1352[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2490 (Batch (None, 32, 32, 244)  976         concatenate_2397[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2490 (Activation)    (None, 32, 32, 244)  0           batch_normalization_2490[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2477 (Separabl (None, 32, 32, 14)   15372       activation_2490[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1353 (Dropout)          (None, 32, 32, 14)   0           separable_conv2d_2477[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2398 (Concatenate)  (None, 32, 32, 258)  0           concatenate_2397[0][0]           \n",
      "                                                                 dropout_1353[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2491 (Batch (None, 32, 32, 258)  1032        concatenate_2398[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2491 (Activation)    (None, 32, 32, 258)  0           batch_normalization_2491[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2478 (Separabl (None, 32, 32, 14)   16254       activation_2491[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1354 (Dropout)          (None, 32, 32, 14)   0           separable_conv2d_2478[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2399 (Concatenate)  (None, 32, 32, 272)  0           concatenate_2398[0][0]           \n",
      "                                                                 dropout_1354[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2492 (Batch (None, 32, 32, 272)  1088        concatenate_2399[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2492 (Activation)    (None, 32, 32, 272)  0           batch_normalization_2492[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2479 (Separabl (None, 32, 32, 14)   17136       activation_2492[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1355 (Dropout)          (None, 32, 32, 14)   0           separable_conv2d_2479[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2400 (Concatenate)  (None, 32, 32, 286)  0           concatenate_2399[0][0]           \n",
      "                                                                 dropout_1355[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2493 (Batch (None, 32, 32, 286)  1144        concatenate_2400[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2493 (Activation)    (None, 32, 32, 286)  0           batch_normalization_2493[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2480 (Separabl (None, 32, 32, 14)   18018       activation_2493[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1356 (Dropout)          (None, 32, 32, 14)   0           separable_conv2d_2480[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2401 (Concatenate)  (None, 32, 32, 300)  0           concatenate_2400[0][0]           \n",
      "                                                                 dropout_1356[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2494 (Batch (None, 32, 32, 300)  1200        concatenate_2401[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2494 (Activation)    (None, 32, 32, 300)  0           batch_normalization_2494[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2481 (Separabl (None, 32, 32, 14)   18900       activation_2494[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1357 (Dropout)          (None, 32, 32, 14)   0           separable_conv2d_2481[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2402 (Concatenate)  (None, 32, 32, 314)  0           concatenate_2401[0][0]           \n",
      "                                                                 dropout_1357[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2495 (Batch (None, 32, 32, 314)  1256        concatenate_2402[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2495 (Activation)    (None, 32, 32, 314)  0           batch_normalization_2495[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2482 (Separabl (None, 32, 32, 14)   19782       activation_2495[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1358 (Dropout)          (None, 32, 32, 14)   0           separable_conv2d_2482[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2403 (Concatenate)  (None, 32, 32, 328)  0           concatenate_2402[0][0]           \n",
      "                                                                 dropout_1358[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2496 (Batch (None, 32, 32, 328)  1312        concatenate_2403[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2496 (Activation)    (None, 32, 32, 328)  0           batch_normalization_2496[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2483 (Separabl (None, 32, 32, 14)   20664       activation_2496[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1359 (Dropout)          (None, 32, 32, 14)   0           separable_conv2d_2483[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2404 (Concatenate)  (None, 32, 32, 342)  0           concatenate_2403[0][0]           \n",
      "                                                                 dropout_1359[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2497 (Batch (None, 32, 32, 342)  1368        concatenate_2404[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2497 (Activation)    (None, 32, 32, 342)  0           batch_normalization_2497[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2484 (Separabl (None, 32, 32, 14)   5130        activation_2497[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1360 (Dropout)          (None, 32, 32, 14)   0           separable_conv2d_2484[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_92 (AveragePo (None, 16, 16, 14)   0           dropout_1360[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2498 (Batch (None, 16, 16, 14)   56          average_pooling2d_92[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_2498 (Activation)    (None, 16, 16, 14)   0           batch_normalization_2498[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2485 (Separabl (None, 16, 16, 14)   882         activation_2498[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1361 (Dropout)          (None, 16, 16, 14)   0           separable_conv2d_2485[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2405 (Concatenate)  (None, 16, 16, 28)   0           average_pooling2d_92[0][0]       \n",
      "                                                                 dropout_1361[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2499 (Batch (None, 16, 16, 28)   112         concatenate_2405[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2499 (Activation)    (None, 16, 16, 28)   0           batch_normalization_2499[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2486 (Separabl (None, 16, 16, 14)   1764        activation_2499[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1362 (Dropout)          (None, 16, 16, 14)   0           separable_conv2d_2486[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2406 (Concatenate)  (None, 16, 16, 42)   0           concatenate_2405[0][0]           \n",
      "                                                                 dropout_1362[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2500 (Batch (None, 16, 16, 42)   168         concatenate_2406[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2500 (Activation)    (None, 16, 16, 42)   0           batch_normalization_2500[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2487 (Separabl (None, 16, 16, 14)   2646        activation_2500[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1363 (Dropout)          (None, 16, 16, 14)   0           separable_conv2d_2487[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2407 (Concatenate)  (None, 16, 16, 56)   0           concatenate_2406[0][0]           \n",
      "                                                                 dropout_1363[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2501 (Batch (None, 16, 16, 56)   224         concatenate_2407[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2501 (Activation)    (None, 16, 16, 56)   0           batch_normalization_2501[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2488 (Separabl (None, 16, 16, 14)   3528        activation_2501[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1364 (Dropout)          (None, 16, 16, 14)   0           separable_conv2d_2488[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2408 (Concatenate)  (None, 16, 16, 70)   0           concatenate_2407[0][0]           \n",
      "                                                                 dropout_1364[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2502 (Batch (None, 16, 16, 70)   280         concatenate_2408[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2502 (Activation)    (None, 16, 16, 70)   0           batch_normalization_2502[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2489 (Separabl (None, 16, 16, 14)   4410        activation_2502[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1365 (Dropout)          (None, 16, 16, 14)   0           separable_conv2d_2489[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2409 (Concatenate)  (None, 16, 16, 84)   0           concatenate_2408[0][0]           \n",
      "                                                                 dropout_1365[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2503 (Batch (None, 16, 16, 84)   336         concatenate_2409[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2503 (Activation)    (None, 16, 16, 84)   0           batch_normalization_2503[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2490 (Separabl (None, 16, 16, 14)   5292        activation_2503[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1366 (Dropout)          (None, 16, 16, 14)   0           separable_conv2d_2490[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2410 (Concatenate)  (None, 16, 16, 98)   0           concatenate_2409[0][0]           \n",
      "                                                                 dropout_1366[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2504 (Batch (None, 16, 16, 98)   392         concatenate_2410[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2504 (Activation)    (None, 16, 16, 98)   0           batch_normalization_2504[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2491 (Separabl (None, 16, 16, 14)   6174        activation_2504[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1367 (Dropout)          (None, 16, 16, 14)   0           separable_conv2d_2491[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2411 (Concatenate)  (None, 16, 16, 112)  0           concatenate_2410[0][0]           \n",
      "                                                                 dropout_1367[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2505 (Batch (None, 16, 16, 112)  448         concatenate_2411[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2505 (Activation)    (None, 16, 16, 112)  0           batch_normalization_2505[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2492 (Separabl (None, 16, 16, 14)   7056        activation_2505[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1368 (Dropout)          (None, 16, 16, 14)   0           separable_conv2d_2492[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2412 (Concatenate)  (None, 16, 16, 126)  0           concatenate_2411[0][0]           \n",
      "                                                                 dropout_1368[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2506 (Batch (None, 16, 16, 126)  504         concatenate_2412[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2506 (Activation)    (None, 16, 16, 126)  0           batch_normalization_2506[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2493 (Separabl (None, 16, 16, 14)   7938        activation_2506[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1369 (Dropout)          (None, 16, 16, 14)   0           separable_conv2d_2493[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2413 (Concatenate)  (None, 16, 16, 140)  0           concatenate_2412[0][0]           \n",
      "                                                                 dropout_1369[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2507 (Batch (None, 16, 16, 140)  560         concatenate_2413[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2507 (Activation)    (None, 16, 16, 140)  0           batch_normalization_2507[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2494 (Separabl (None, 16, 16, 14)   8820        activation_2507[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1370 (Dropout)          (None, 16, 16, 14)   0           separable_conv2d_2494[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2414 (Concatenate)  (None, 16, 16, 154)  0           concatenate_2413[0][0]           \n",
      "                                                                 dropout_1370[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2508 (Batch (None, 16, 16, 154)  616         concatenate_2414[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2508 (Activation)    (None, 16, 16, 154)  0           batch_normalization_2508[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2495 (Separabl (None, 16, 16, 14)   9702        activation_2508[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1371 (Dropout)          (None, 16, 16, 14)   0           separable_conv2d_2495[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2415 (Concatenate)  (None, 16, 16, 168)  0           concatenate_2414[0][0]           \n",
      "                                                                 dropout_1371[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2509 (Batch (None, 16, 16, 168)  672         concatenate_2415[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2509 (Activation)    (None, 16, 16, 168)  0           batch_normalization_2509[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2496 (Separabl (None, 16, 16, 14)   10584       activation_2509[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1372 (Dropout)          (None, 16, 16, 14)   0           separable_conv2d_2496[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2416 (Concatenate)  (None, 16, 16, 182)  0           concatenate_2415[0][0]           \n",
      "                                                                 dropout_1372[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2510 (Batch (None, 16, 16, 182)  728         concatenate_2416[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2510 (Activation)    (None, 16, 16, 182)  0           batch_normalization_2510[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2497 (Separabl (None, 16, 16, 14)   11466       activation_2510[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1373 (Dropout)          (None, 16, 16, 14)   0           separable_conv2d_2497[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2417 (Concatenate)  (None, 16, 16, 196)  0           concatenate_2416[0][0]           \n",
      "                                                                 dropout_1373[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2511 (Batch (None, 16, 16, 196)  784         concatenate_2417[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2511 (Activation)    (None, 16, 16, 196)  0           batch_normalization_2511[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2498 (Separabl (None, 16, 16, 14)   12348       activation_2511[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1374 (Dropout)          (None, 16, 16, 14)   0           separable_conv2d_2498[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2418 (Concatenate)  (None, 16, 16, 210)  0           concatenate_2417[0][0]           \n",
      "                                                                 dropout_1374[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2512 (Batch (None, 16, 16, 210)  840         concatenate_2418[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2512 (Activation)    (None, 16, 16, 210)  0           batch_normalization_2512[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2499 (Separabl (None, 16, 16, 14)   13230       activation_2512[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1375 (Dropout)          (None, 16, 16, 14)   0           separable_conv2d_2499[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2419 (Concatenate)  (None, 16, 16, 224)  0           concatenate_2418[0][0]           \n",
      "                                                                 dropout_1375[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2513 (Batch (None, 16, 16, 224)  896         concatenate_2419[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2513 (Activation)    (None, 16, 16, 224)  0           batch_normalization_2513[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2500 (Separabl (None, 16, 16, 14)   14112       activation_2513[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1376 (Dropout)          (None, 16, 16, 14)   0           separable_conv2d_2500[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2420 (Concatenate)  (None, 16, 16, 238)  0           concatenate_2419[0][0]           \n",
      "                                                                 dropout_1376[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2514 (Batch (None, 16, 16, 238)  952         concatenate_2420[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2514 (Activation)    (None, 16, 16, 238)  0           batch_normalization_2514[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2501 (Separabl (None, 16, 16, 14)   14994       activation_2514[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1377 (Dropout)          (None, 16, 16, 14)   0           separable_conv2d_2501[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2421 (Concatenate)  (None, 16, 16, 252)  0           concatenate_2420[0][0]           \n",
      "                                                                 dropout_1377[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2515 (Batch (None, 16, 16, 252)  1008        concatenate_2421[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2515 (Activation)    (None, 16, 16, 252)  0           batch_normalization_2515[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2502 (Separabl (None, 16, 16, 14)   15876       activation_2515[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1378 (Dropout)          (None, 16, 16, 14)   0           separable_conv2d_2502[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2422 (Concatenate)  (None, 16, 16, 266)  0           concatenate_2421[0][0]           \n",
      "                                                                 dropout_1378[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2516 (Batch (None, 16, 16, 266)  1064        concatenate_2422[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2516 (Activation)    (None, 16, 16, 266)  0           batch_normalization_2516[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2503 (Separabl (None, 16, 16, 14)   16758       activation_2516[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1379 (Dropout)          (None, 16, 16, 14)   0           separable_conv2d_2503[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2423 (Concatenate)  (None, 16, 16, 280)  0           concatenate_2422[0][0]           \n",
      "                                                                 dropout_1379[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2517 (Batch (None, 16, 16, 280)  1120        concatenate_2423[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2517 (Activation)    (None, 16, 16, 280)  0           batch_normalization_2517[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2504 (Separabl (None, 16, 16, 14)   17640       activation_2517[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1380 (Dropout)          (None, 16, 16, 14)   0           separable_conv2d_2504[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2424 (Concatenate)  (None, 16, 16, 294)  0           concatenate_2423[0][0]           \n",
      "                                                                 dropout_1380[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2518 (Batch (None, 16, 16, 294)  1176        concatenate_2424[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2518 (Activation)    (None, 16, 16, 294)  0           batch_normalization_2518[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2505 (Separabl (None, 16, 16, 14)   18522       activation_2518[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1381 (Dropout)          (None, 16, 16, 14)   0           separable_conv2d_2505[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2425 (Concatenate)  (None, 16, 16, 308)  0           concatenate_2424[0][0]           \n",
      "                                                                 dropout_1381[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2519 (Batch (None, 16, 16, 308)  1232        concatenate_2425[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2519 (Activation)    (None, 16, 16, 308)  0           batch_normalization_2519[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2506 (Separabl (None, 16, 16, 14)   4620        activation_2519[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1382 (Dropout)          (None, 16, 16, 14)   0           separable_conv2d_2506[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_93 (AveragePo (None, 8, 8, 14)     0           dropout_1382[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2520 (Batch (None, 8, 8, 14)     56          average_pooling2d_93[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_2520 (Activation)    (None, 8, 8, 14)     0           batch_normalization_2520[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2507 (Separabl (None, 8, 8, 14)     882         activation_2520[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1383 (Dropout)          (None, 8, 8, 14)     0           separable_conv2d_2507[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2426 (Concatenate)  (None, 8, 8, 28)     0           average_pooling2d_93[0][0]       \n",
      "                                                                 dropout_1383[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2521 (Batch (None, 8, 8, 28)     112         concatenate_2426[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2521 (Activation)    (None, 8, 8, 28)     0           batch_normalization_2521[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2508 (Separabl (None, 8, 8, 14)     1764        activation_2521[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1384 (Dropout)          (None, 8, 8, 14)     0           separable_conv2d_2508[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2427 (Concatenate)  (None, 8, 8, 42)     0           concatenate_2426[0][0]           \n",
      "                                                                 dropout_1384[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2522 (Batch (None, 8, 8, 42)     168         concatenate_2427[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2522 (Activation)    (None, 8, 8, 42)     0           batch_normalization_2522[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2509 (Separabl (None, 8, 8, 14)     2646        activation_2522[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1385 (Dropout)          (None, 8, 8, 14)     0           separable_conv2d_2509[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2428 (Concatenate)  (None, 8, 8, 56)     0           concatenate_2427[0][0]           \n",
      "                                                                 dropout_1385[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2523 (Batch (None, 8, 8, 56)     224         concatenate_2428[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2523 (Activation)    (None, 8, 8, 56)     0           batch_normalization_2523[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2510 (Separabl (None, 8, 8, 14)     3528        activation_2523[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1386 (Dropout)          (None, 8, 8, 14)     0           separable_conv2d_2510[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2429 (Concatenate)  (None, 8, 8, 70)     0           concatenate_2428[0][0]           \n",
      "                                                                 dropout_1386[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2524 (Batch (None, 8, 8, 70)     280         concatenate_2429[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2524 (Activation)    (None, 8, 8, 70)     0           batch_normalization_2524[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2511 (Separabl (None, 8, 8, 14)     4410        activation_2524[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1387 (Dropout)          (None, 8, 8, 14)     0           separable_conv2d_2511[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2430 (Concatenate)  (None, 8, 8, 84)     0           concatenate_2429[0][0]           \n",
      "                                                                 dropout_1387[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2525 (Batch (None, 8, 8, 84)     336         concatenate_2430[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2525 (Activation)    (None, 8, 8, 84)     0           batch_normalization_2525[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2512 (Separabl (None, 8, 8, 14)     5292        activation_2525[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1388 (Dropout)          (None, 8, 8, 14)     0           separable_conv2d_2512[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2431 (Concatenate)  (None, 8, 8, 98)     0           concatenate_2430[0][0]           \n",
      "                                                                 dropout_1388[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2526 (Batch (None, 8, 8, 98)     392         concatenate_2431[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2526 (Activation)    (None, 8, 8, 98)     0           batch_normalization_2526[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2513 (Separabl (None, 8, 8, 14)     6174        activation_2526[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1389 (Dropout)          (None, 8, 8, 14)     0           separable_conv2d_2513[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2432 (Concatenate)  (None, 8, 8, 112)    0           concatenate_2431[0][0]           \n",
      "                                                                 dropout_1389[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2527 (Batch (None, 8, 8, 112)    448         concatenate_2432[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2527 (Activation)    (None, 8, 8, 112)    0           batch_normalization_2527[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2514 (Separabl (None, 8, 8, 14)     7056        activation_2527[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1390 (Dropout)          (None, 8, 8, 14)     0           separable_conv2d_2514[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2433 (Concatenate)  (None, 8, 8, 126)    0           concatenate_2432[0][0]           \n",
      "                                                                 dropout_1390[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2528 (Batch (None, 8, 8, 126)    504         concatenate_2433[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2528 (Activation)    (None, 8, 8, 126)    0           batch_normalization_2528[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2515 (Separabl (None, 8, 8, 14)     7938        activation_2528[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1391 (Dropout)          (None, 8, 8, 14)     0           separable_conv2d_2515[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2434 (Concatenate)  (None, 8, 8, 140)    0           concatenate_2433[0][0]           \n",
      "                                                                 dropout_1391[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2529 (Batch (None, 8, 8, 140)    560         concatenate_2434[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2529 (Activation)    (None, 8, 8, 140)    0           batch_normalization_2529[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2516 (Separabl (None, 8, 8, 14)     8820        activation_2529[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1392 (Dropout)          (None, 8, 8, 14)     0           separable_conv2d_2516[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2435 (Concatenate)  (None, 8, 8, 154)    0           concatenate_2434[0][0]           \n",
      "                                                                 dropout_1392[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2530 (Batch (None, 8, 8, 154)    616         concatenate_2435[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2530 (Activation)    (None, 8, 8, 154)    0           batch_normalization_2530[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2517 (Separabl (None, 8, 8, 14)     9702        activation_2530[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1393 (Dropout)          (None, 8, 8, 14)     0           separable_conv2d_2517[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2436 (Concatenate)  (None, 8, 8, 168)    0           concatenate_2435[0][0]           \n",
      "                                                                 dropout_1393[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2531 (Batch (None, 8, 8, 168)    672         concatenate_2436[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2531 (Activation)    (None, 8, 8, 168)    0           batch_normalization_2531[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2518 (Separabl (None, 8, 8, 14)     10584       activation_2531[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1394 (Dropout)          (None, 8, 8, 14)     0           separable_conv2d_2518[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2437 (Concatenate)  (None, 8, 8, 182)    0           concatenate_2436[0][0]           \n",
      "                                                                 dropout_1394[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2532 (Batch (None, 8, 8, 182)    728         concatenate_2437[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2532 (Activation)    (None, 8, 8, 182)    0           batch_normalization_2532[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2519 (Separabl (None, 8, 8, 14)     11466       activation_2532[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1395 (Dropout)          (None, 8, 8, 14)     0           separable_conv2d_2519[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2438 (Concatenate)  (None, 8, 8, 196)    0           concatenate_2437[0][0]           \n",
      "                                                                 dropout_1395[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2533 (Batch (None, 8, 8, 196)    784         concatenate_2438[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2533 (Activation)    (None, 8, 8, 196)    0           batch_normalization_2533[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2520 (Separabl (None, 8, 8, 14)     12348       activation_2533[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1396 (Dropout)          (None, 8, 8, 14)     0           separable_conv2d_2520[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2439 (Concatenate)  (None, 8, 8, 210)    0           concatenate_2438[0][0]           \n",
      "                                                                 dropout_1396[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2534 (Batch (None, 8, 8, 210)    840         concatenate_2439[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2534 (Activation)    (None, 8, 8, 210)    0           batch_normalization_2534[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2521 (Separabl (None, 8, 8, 14)     13230       activation_2534[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1397 (Dropout)          (None, 8, 8, 14)     0           separable_conv2d_2521[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2440 (Concatenate)  (None, 8, 8, 224)    0           concatenate_2439[0][0]           \n",
      "                                                                 dropout_1397[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2535 (Batch (None, 8, 8, 224)    896         concatenate_2440[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2535 (Activation)    (None, 8, 8, 224)    0           batch_normalization_2535[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2522 (Separabl (None, 8, 8, 14)     14112       activation_2535[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1398 (Dropout)          (None, 8, 8, 14)     0           separable_conv2d_2522[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2441 (Concatenate)  (None, 8, 8, 238)    0           concatenate_2440[0][0]           \n",
      "                                                                 dropout_1398[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2536 (Batch (None, 8, 8, 238)    952         concatenate_2441[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2536 (Activation)    (None, 8, 8, 238)    0           batch_normalization_2536[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2523 (Separabl (None, 8, 8, 14)     14994       activation_2536[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1399 (Dropout)          (None, 8, 8, 14)     0           separable_conv2d_2523[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2442 (Concatenate)  (None, 8, 8, 252)    0           concatenate_2441[0][0]           \n",
      "                                                                 dropout_1399[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2537 (Batch (None, 8, 8, 252)    1008        concatenate_2442[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2537 (Activation)    (None, 8, 8, 252)    0           batch_normalization_2537[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2524 (Separabl (None, 8, 8, 14)     15876       activation_2537[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1400 (Dropout)          (None, 8, 8, 14)     0           separable_conv2d_2524[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2443 (Concatenate)  (None, 8, 8, 266)    0           concatenate_2442[0][0]           \n",
      "                                                                 dropout_1400[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2538 (Batch (None, 8, 8, 266)    1064        concatenate_2443[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2538 (Activation)    (None, 8, 8, 266)    0           batch_normalization_2538[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2525 (Separabl (None, 8, 8, 14)     16758       activation_2538[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1401 (Dropout)          (None, 8, 8, 14)     0           separable_conv2d_2525[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2444 (Concatenate)  (None, 8, 8, 280)    0           concatenate_2443[0][0]           \n",
      "                                                                 dropout_1401[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2539 (Batch (None, 8, 8, 280)    1120        concatenate_2444[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2539 (Activation)    (None, 8, 8, 280)    0           batch_normalization_2539[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2526 (Separabl (None, 8, 8, 14)     17640       activation_2539[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1402 (Dropout)          (None, 8, 8, 14)     0           separable_conv2d_2526[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2445 (Concatenate)  (None, 8, 8, 294)    0           concatenate_2444[0][0]           \n",
      "                                                                 dropout_1402[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2540 (Batch (None, 8, 8, 294)    1176        concatenate_2445[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2540 (Activation)    (None, 8, 8, 294)    0           batch_normalization_2540[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2527 (Separabl (None, 8, 8, 14)     18522       activation_2540[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1403 (Dropout)          (None, 8, 8, 14)     0           separable_conv2d_2527[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2446 (Concatenate)  (None, 8, 8, 308)    0           concatenate_2445[0][0]           \n",
      "                                                                 dropout_1403[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2541 (Batch (None, 8, 8, 308)    1232        concatenate_2446[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2541 (Activation)    (None, 8, 8, 308)    0           batch_normalization_2541[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2528 (Separabl (None, 8, 8, 14)     4620        activation_2541[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1404 (Dropout)          (None, 8, 8, 14)     0           separable_conv2d_2528[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_94 (AveragePo (None, 4, 4, 14)     0           dropout_1404[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2542 (Batch (None, 4, 4, 14)     56          average_pooling2d_94[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_2542 (Activation)    (None, 4, 4, 14)     0           batch_normalization_2542[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2529 (Separabl (None, 4, 4, 14)     882         activation_2542[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1405 (Dropout)          (None, 4, 4, 14)     0           separable_conv2d_2529[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2447 (Concatenate)  (None, 4, 4, 28)     0           average_pooling2d_94[0][0]       \n",
      "                                                                 dropout_1405[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2543 (Batch (None, 4, 4, 28)     112         concatenate_2447[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2543 (Activation)    (None, 4, 4, 28)     0           batch_normalization_2543[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2530 (Separabl (None, 4, 4, 14)     1764        activation_2543[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1406 (Dropout)          (None, 4, 4, 14)     0           separable_conv2d_2530[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2448 (Concatenate)  (None, 4, 4, 42)     0           concatenate_2447[0][0]           \n",
      "                                                                 dropout_1406[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2544 (Batch (None, 4, 4, 42)     168         concatenate_2448[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2544 (Activation)    (None, 4, 4, 42)     0           batch_normalization_2544[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2531 (Separabl (None, 4, 4, 14)     2646        activation_2544[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1407 (Dropout)          (None, 4, 4, 14)     0           separable_conv2d_2531[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2449 (Concatenate)  (None, 4, 4, 56)     0           concatenate_2448[0][0]           \n",
      "                                                                 dropout_1407[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2545 (Batch (None, 4, 4, 56)     224         concatenate_2449[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2545 (Activation)    (None, 4, 4, 56)     0           batch_normalization_2545[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2532 (Separabl (None, 4, 4, 14)     3528        activation_2545[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1408 (Dropout)          (None, 4, 4, 14)     0           separable_conv2d_2532[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2450 (Concatenate)  (None, 4, 4, 70)     0           concatenate_2449[0][0]           \n",
      "                                                                 dropout_1408[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2546 (Batch (None, 4, 4, 70)     280         concatenate_2450[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2546 (Activation)    (None, 4, 4, 70)     0           batch_normalization_2546[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2533 (Separabl (None, 4, 4, 14)     4410        activation_2546[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1409 (Dropout)          (None, 4, 4, 14)     0           separable_conv2d_2533[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2451 (Concatenate)  (None, 4, 4, 84)     0           concatenate_2450[0][0]           \n",
      "                                                                 dropout_1409[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2547 (Batch (None, 4, 4, 84)     336         concatenate_2451[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2547 (Activation)    (None, 4, 4, 84)     0           batch_normalization_2547[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2534 (Separabl (None, 4, 4, 14)     5292        activation_2547[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1410 (Dropout)          (None, 4, 4, 14)     0           separable_conv2d_2534[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2452 (Concatenate)  (None, 4, 4, 98)     0           concatenate_2451[0][0]           \n",
      "                                                                 dropout_1410[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2548 (Batch (None, 4, 4, 98)     392         concatenate_2452[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2548 (Activation)    (None, 4, 4, 98)     0           batch_normalization_2548[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2535 (Separabl (None, 4, 4, 14)     6174        activation_2548[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1411 (Dropout)          (None, 4, 4, 14)     0           separable_conv2d_2535[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2453 (Concatenate)  (None, 4, 4, 112)    0           concatenate_2452[0][0]           \n",
      "                                                                 dropout_1411[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2549 (Batch (None, 4, 4, 112)    448         concatenate_2453[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2549 (Activation)    (None, 4, 4, 112)    0           batch_normalization_2549[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2536 (Separabl (None, 4, 4, 14)     7056        activation_2549[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1412 (Dropout)          (None, 4, 4, 14)     0           separable_conv2d_2536[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2454 (Concatenate)  (None, 4, 4, 126)    0           concatenate_2453[0][0]           \n",
      "                                                                 dropout_1412[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2550 (Batch (None, 4, 4, 126)    504         concatenate_2454[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2550 (Activation)    (None, 4, 4, 126)    0           batch_normalization_2550[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2537 (Separabl (None, 4, 4, 14)     7938        activation_2550[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1413 (Dropout)          (None, 4, 4, 14)     0           separable_conv2d_2537[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2455 (Concatenate)  (None, 4, 4, 140)    0           concatenate_2454[0][0]           \n",
      "                                                                 dropout_1413[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2551 (Batch (None, 4, 4, 140)    560         concatenate_2455[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2551 (Activation)    (None, 4, 4, 140)    0           batch_normalization_2551[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2538 (Separabl (None, 4, 4, 14)     8820        activation_2551[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1414 (Dropout)          (None, 4, 4, 14)     0           separable_conv2d_2538[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2456 (Concatenate)  (None, 4, 4, 154)    0           concatenate_2455[0][0]           \n",
      "                                                                 dropout_1414[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2552 (Batch (None, 4, 4, 154)    616         concatenate_2456[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2552 (Activation)    (None, 4, 4, 154)    0           batch_normalization_2552[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2539 (Separabl (None, 4, 4, 14)     9702        activation_2552[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1415 (Dropout)          (None, 4, 4, 14)     0           separable_conv2d_2539[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2457 (Concatenate)  (None, 4, 4, 168)    0           concatenate_2456[0][0]           \n",
      "                                                                 dropout_1415[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2553 (Batch (None, 4, 4, 168)    672         concatenate_2457[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2553 (Activation)    (None, 4, 4, 168)    0           batch_normalization_2553[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2540 (Separabl (None, 4, 4, 14)     10584       activation_2553[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1416 (Dropout)          (None, 4, 4, 14)     0           separable_conv2d_2540[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2458 (Concatenate)  (None, 4, 4, 182)    0           concatenate_2457[0][0]           \n",
      "                                                                 dropout_1416[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2554 (Batch (None, 4, 4, 182)    728         concatenate_2458[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2554 (Activation)    (None, 4, 4, 182)    0           batch_normalization_2554[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2541 (Separabl (None, 4, 4, 14)     11466       activation_2554[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1417 (Dropout)          (None, 4, 4, 14)     0           separable_conv2d_2541[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2459 (Concatenate)  (None, 4, 4, 196)    0           concatenate_2458[0][0]           \n",
      "                                                                 dropout_1417[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2555 (Batch (None, 4, 4, 196)    784         concatenate_2459[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2555 (Activation)    (None, 4, 4, 196)    0           batch_normalization_2555[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2542 (Separabl (None, 4, 4, 14)     12348       activation_2555[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1418 (Dropout)          (None, 4, 4, 14)     0           separable_conv2d_2542[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2460 (Concatenate)  (None, 4, 4, 210)    0           concatenate_2459[0][0]           \n",
      "                                                                 dropout_1418[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2556 (Batch (None, 4, 4, 210)    840         concatenate_2460[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2556 (Activation)    (None, 4, 4, 210)    0           batch_normalization_2556[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2543 (Separabl (None, 4, 4, 14)     13230       activation_2556[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1419 (Dropout)          (None, 4, 4, 14)     0           separable_conv2d_2543[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2461 (Concatenate)  (None, 4, 4, 224)    0           concatenate_2460[0][0]           \n",
      "                                                                 dropout_1419[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2557 (Batch (None, 4, 4, 224)    896         concatenate_2461[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2557 (Activation)    (None, 4, 4, 224)    0           batch_normalization_2557[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2544 (Separabl (None, 4, 4, 14)     14112       activation_2557[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1420 (Dropout)          (None, 4, 4, 14)     0           separable_conv2d_2544[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2462 (Concatenate)  (None, 4, 4, 238)    0           concatenate_2461[0][0]           \n",
      "                                                                 dropout_1420[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2558 (Batch (None, 4, 4, 238)    952         concatenate_2462[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2558 (Activation)    (None, 4, 4, 238)    0           batch_normalization_2558[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2545 (Separabl (None, 4, 4, 14)     14994       activation_2558[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1421 (Dropout)          (None, 4, 4, 14)     0           separable_conv2d_2545[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2463 (Concatenate)  (None, 4, 4, 252)    0           concatenate_2462[0][0]           \n",
      "                                                                 dropout_1421[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2559 (Batch (None, 4, 4, 252)    1008        concatenate_2463[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2559 (Activation)    (None, 4, 4, 252)    0           batch_normalization_2559[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2546 (Separabl (None, 4, 4, 14)     15876       activation_2559[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1422 (Dropout)          (None, 4, 4, 14)     0           separable_conv2d_2546[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2464 (Concatenate)  (None, 4, 4, 266)    0           concatenate_2463[0][0]           \n",
      "                                                                 dropout_1422[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2560 (Batch (None, 4, 4, 266)    1064        concatenate_2464[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2560 (Activation)    (None, 4, 4, 266)    0           batch_normalization_2560[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2547 (Separabl (None, 4, 4, 14)     16758       activation_2560[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1423 (Dropout)          (None, 4, 4, 14)     0           separable_conv2d_2547[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2465 (Concatenate)  (None, 4, 4, 280)    0           concatenate_2464[0][0]           \n",
      "                                                                 dropout_1423[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2561 (Batch (None, 4, 4, 280)    1120        concatenate_2465[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2561 (Activation)    (None, 4, 4, 280)    0           batch_normalization_2561[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2548 (Separabl (None, 4, 4, 14)     17640       activation_2561[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1424 (Dropout)          (None, 4, 4, 14)     0           separable_conv2d_2548[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2466 (Concatenate)  (None, 4, 4, 294)    0           concatenate_2465[0][0]           \n",
      "                                                                 dropout_1424[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2562 (Batch (None, 4, 4, 294)    1176        concatenate_2466[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2562 (Activation)    (None, 4, 4, 294)    0           batch_normalization_2562[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2549 (Separabl (None, 4, 4, 14)     18522       activation_2562[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1425 (Dropout)          (None, 4, 4, 14)     0           separable_conv2d_2549[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2467 (Concatenate)  (None, 4, 4, 308)    0           concatenate_2466[0][0]           \n",
      "                                                                 dropout_1425[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2563 (Batch (None, 4, 4, 308)    1232        concatenate_2467[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2563 (Activation)    (None, 4, 4, 308)    0           batch_normalization_2563[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_95 (AveragePo (None, 2, 2, 308)    0           activation_2563[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2550 (Separabl (None, 1, 1, 10)     4322        average_pooling2d_95[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "flatten_15 (Flatten)            (None, 10)           0           separable_conv2d_2550[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 10)           110         flatten_15[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 945,472\n",
      "Trainable params: 915,640\n",
      "Non-trainable params: 29,832\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_5 = tf.keras.models.Model(inputs=[input], outputs=[output])\n",
    "model_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 390 steps, validate on 10000 samples\n",
      "Epoch 1/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 1.7504 - accuracy: 0.3315\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.22800, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model5_01-0.23.hdf5\n",
      "390/390 [==============================] - 156s 401ms/step - loss: 1.7500 - accuracy: 0.3316 - val_loss: 2.3646 - val_accuracy: 0.2280\n",
      "Epoch 2/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 1.3674 - accuracy: 0.4987\n",
      "Epoch 00002: val_accuracy improved from 0.22800 to 0.30130, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model5_02-0.30.hdf5\n",
      "390/390 [==============================] - 136s 349ms/step - loss: 1.3671 - accuracy: 0.4989 - val_loss: 3.2475 - val_accuracy: 0.3013\n",
      "Epoch 3/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 1.1433 - accuracy: 0.5880\n",
      "Epoch 00003: val_accuracy improved from 0.30130 to 0.41590, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model5_03-0.42.hdf5\n",
      "390/390 [==============================] - 136s 349ms/step - loss: 1.1434 - accuracy: 0.5881 - val_loss: 2.5937 - val_accuracy: 0.4159\n",
      "Epoch 4/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 1.0125 - accuracy: 0.6385\n",
      "Epoch 00004: val_accuracy improved from 0.41590 to 0.57930, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model5_04-0.58.hdf5\n",
      "390/390 [==============================] - 136s 349ms/step - loss: 1.0122 - accuracy: 0.6385 - val_loss: 1.4217 - val_accuracy: 0.5793\n",
      "Epoch 5/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.9161 - accuracy: 0.6739\n",
      "Epoch 00005: val_accuracy improved from 0.57930 to 0.61120, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model5_05-0.61.hdf5\n",
      "390/390 [==============================] - 136s 349ms/step - loss: 0.9160 - accuracy: 0.6739 - val_loss: 1.3084 - val_accuracy: 0.6112\n",
      "Epoch 6/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.8343 - accuracy: 0.7069\n",
      "Epoch 00006: val_accuracy improved from 0.61120 to 0.62680, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model5_06-0.63.hdf5\n",
      "390/390 [==============================] - 136s 349ms/step - loss: 0.8343 - accuracy: 0.7069 - val_loss: 1.3066 - val_accuracy: 0.6268\n",
      "Epoch 7/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.7774 - accuracy: 0.7297\n",
      "Epoch 00007: val_accuracy did not improve from 0.62680\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.7776 - accuracy: 0.7296 - val_loss: 2.7267 - val_accuracy: 0.4788\n",
      "Epoch 8/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.7255 - accuracy: 0.7453\n",
      "Epoch 00008: val_accuracy improved from 0.62680 to 0.65880, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model5_08-0.66.hdf5\n",
      "390/390 [==============================] - 136s 350ms/step - loss: 0.7254 - accuracy: 0.7452 - val_loss: 1.2443 - val_accuracy: 0.6588\n",
      "Epoch 9/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.6863 - accuracy: 0.7620\n",
      "Epoch 00009: val_accuracy improved from 0.65880 to 0.71540, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model5_09-0.72.hdf5\n",
      "390/390 [==============================] - 136s 349ms/step - loss: 0.6860 - accuracy: 0.7621 - val_loss: 0.9944 - val_accuracy: 0.7154\n",
      "Epoch 10/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.6442 - accuracy: 0.7771\n",
      "Epoch 00010: val_accuracy did not improve from 0.71540\n",
      "390/390 [==============================] - 135s 346ms/step - loss: 0.6442 - accuracy: 0.7772 - val_loss: 2.1131 - val_accuracy: 0.5154\n",
      "Epoch 11/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.6251 - accuracy: 0.7823\n",
      "Epoch 00011: val_accuracy improved from 0.71540 to 0.74050, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model5_11-0.74.hdf5\n",
      "390/390 [==============================] - 136s 349ms/step - loss: 0.6253 - accuracy: 0.7823 - val_loss: 0.8934 - val_accuracy: 0.7405\n",
      "Epoch 12/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5946 - accuracy: 0.7925\n",
      "Epoch 00012: val_accuracy improved from 0.74050 to 0.74180, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model5_12-0.74.hdf5\n",
      "390/390 [==============================] - 136s 349ms/step - loss: 0.5945 - accuracy: 0.7925 - val_loss: 0.8817 - val_accuracy: 0.7418\n",
      "Epoch 13/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5669 - accuracy: 0.8030\n",
      "Epoch 00013: val_accuracy did not improve from 0.74180\n",
      "390/390 [==============================] - 135s 346ms/step - loss: 0.5668 - accuracy: 0.8030 - val_loss: 1.1154 - val_accuracy: 0.7084\n",
      "Epoch 14/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5533 - accuracy: 0.8072\n",
      "Epoch 00014: val_accuracy improved from 0.74180 to 0.77990, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model5_14-0.78.hdf5\n",
      "390/390 [==============================] - 136s 349ms/step - loss: 0.5532 - accuracy: 0.8072 - val_loss: 0.7306 - val_accuracy: 0.7799\n",
      "Epoch 15/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5356 - accuracy: 0.8134\n",
      "Epoch 00015: val_accuracy did not improve from 0.77990\n",
      "390/390 [==============================] - 135s 346ms/step - loss: 0.5359 - accuracy: 0.8134 - val_loss: 0.8631 - val_accuracy: 0.7554\n",
      "Epoch 16/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5176 - accuracy: 0.8205\n",
      "Epoch 00016: val_accuracy did not improve from 0.77990\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.5176 - accuracy: 0.8206 - val_loss: 0.8329 - val_accuracy: 0.7669\n",
      "Epoch 17/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5048 - accuracy: 0.8245\n",
      "Epoch 00017: val_accuracy did not improve from 0.77990\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.5050 - accuracy: 0.8245 - val_loss: 0.8937 - val_accuracy: 0.7489\n",
      "Epoch 18/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.4842 - accuracy: 0.8322\n",
      "Epoch 00018: val_accuracy did not improve from 0.77990\n",
      "390/390 [==============================] - 135s 346ms/step - loss: 0.4845 - accuracy: 0.8321 - val_loss: 0.7822 - val_accuracy: 0.7752\n",
      "Epoch 19/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.4731 - accuracy: 0.8352\n",
      "Epoch 00019: val_accuracy did not improve from 0.77990\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.4740 - accuracy: 0.8350 - val_loss: 0.9793 - val_accuracy: 0.7411\n",
      "Epoch 20/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.4562 - accuracy: 0.8389\n",
      "Epoch 00020: val_accuracy did not improve from 0.77990\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.4564 - accuracy: 0.8387 - val_loss: 1.3204 - val_accuracy: 0.6897\n",
      "Epoch 21/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.4459 - accuracy: 0.8457\n",
      "Epoch 00021: val_accuracy improved from 0.77990 to 0.78290, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model5_21-0.78.hdf5\n",
      "390/390 [==============================] - 136s 350ms/step - loss: 0.4460 - accuracy: 0.8455 - val_loss: 0.7568 - val_accuracy: 0.7829\n",
      "Epoch 22/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.4319 - accuracy: 0.8502\n",
      "Epoch 00022: val_accuracy did not improve from 0.78290\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.4321 - accuracy: 0.8501 - val_loss: 0.9390 - val_accuracy: 0.7539\n",
      "Epoch 23/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.4252 - accuracy: 0.8521\n",
      "Epoch 00023: val_accuracy improved from 0.78290 to 0.78860, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model5_23-0.79.hdf5\n",
      "390/390 [==============================] - 136s 349ms/step - loss: 0.4254 - accuracy: 0.8521 - val_loss: 0.7675 - val_accuracy: 0.7886\n",
      "Epoch 24/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.4141 - accuracy: 0.8549\n",
      "Epoch 00024: val_accuracy improved from 0.78860 to 0.79390, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model5_24-0.79.hdf5\n",
      "390/390 [==============================] - 136s 349ms/step - loss: 0.4142 - accuracy: 0.8548 - val_loss: 0.7512 - val_accuracy: 0.7939\n",
      "Epoch 25/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.4040 - accuracy: 0.8593\n",
      "Epoch 00025: val_accuracy improved from 0.79390 to 0.81740, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model5_25-0.82.hdf5\n",
      "390/390 [==============================] - 136s 350ms/step - loss: 0.4041 - accuracy: 0.8593 - val_loss: 0.6412 - val_accuracy: 0.8174\n",
      "Epoch 26/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.3986 - accuracy: 0.8614\n",
      "Epoch 00026: val_accuracy did not improve from 0.81740\n",
      "390/390 [==============================] - 135s 346ms/step - loss: 0.3988 - accuracy: 0.8614 - val_loss: 1.0172 - val_accuracy: 0.7459\n",
      "Epoch 27/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8657\n",
      "Epoch 00027: val_accuracy did not improve from 0.81740\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.3837 - accuracy: 0.8658 - val_loss: 1.0873 - val_accuracy: 0.7225\n",
      "Epoch 28/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.3809 - accuracy: 0.8669\n",
      "Epoch 00028: val_accuracy improved from 0.81740 to 0.81910, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model5_28-0.82.hdf5\n",
      "390/390 [==============================] - 136s 350ms/step - loss: 0.3807 - accuracy: 0.8671 - val_loss: 0.6226 - val_accuracy: 0.8191\n",
      "Epoch 29/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.3718 - accuracy: 0.8699\n",
      "Epoch 00029: val_accuracy did not improve from 0.81910\n",
      "390/390 [==============================] - 135s 346ms/step - loss: 0.3719 - accuracy: 0.8699 - val_loss: 0.8904 - val_accuracy: 0.7752\n",
      "Epoch 30/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.3669 - accuracy: 0.8716\n",
      "Epoch 00030: val_accuracy did not improve from 0.81910\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.3669 - accuracy: 0.8716 - val_loss: 0.7723 - val_accuracy: 0.7989\n",
      "Epoch 31/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.3615 - accuracy: 0.8746\n",
      "Epoch 00031: val_accuracy did not improve from 0.81910\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.3614 - accuracy: 0.8746 - val_loss: 0.6521 - val_accuracy: 0.8153\n",
      "Epoch 32/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.3501 - accuracy: 0.8779\n",
      "Epoch 00032: val_accuracy did not improve from 0.81910\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.3500 - accuracy: 0.8779 - val_loss: 0.6707 - val_accuracy: 0.8131\n",
      "Epoch 33/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.3462 - accuracy: 0.8785\n",
      "Epoch 00033: val_accuracy did not improve from 0.81910\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.3460 - accuracy: 0.8786 - val_loss: 0.7479 - val_accuracy: 0.7991\n",
      "Epoch 34/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.3364 - accuracy: 0.8807\n",
      "Epoch 00034: val_accuracy did not improve from 0.81910\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.3367 - accuracy: 0.8807 - val_loss: 0.8278 - val_accuracy: 0.7911\n",
      "Epoch 35/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.3383 - accuracy: 0.8822\n",
      "Epoch 00035: val_accuracy did not improve from 0.81910\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.3384 - accuracy: 0.8821 - val_loss: 1.0773 - val_accuracy: 0.7542\n",
      "Epoch 36/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.3266 - accuracy: 0.8842\n",
      "Epoch 00036: val_accuracy did not improve from 0.81910\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.3267 - accuracy: 0.8842 - val_loss: 0.8458 - val_accuracy: 0.7917\n",
      "Epoch 37/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.3233 - accuracy: 0.8864\n",
      "Epoch 00037: val_accuracy did not improve from 0.81910\n",
      "390/390 [==============================] - 135s 346ms/step - loss: 0.3232 - accuracy: 0.8864 - val_loss: 1.1717 - val_accuracy: 0.7484\n",
      "Epoch 38/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.3153 - accuracy: 0.8904\n",
      "Epoch 00038: val_accuracy did not improve from 0.81910\n",
      "390/390 [==============================] - 135s 346ms/step - loss: 0.3151 - accuracy: 0.8904 - val_loss: 0.9669 - val_accuracy: 0.7775\n",
      "Epoch 39/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.3130 - accuracy: 0.8904\n",
      "Epoch 00039: val_accuracy did not improve from 0.81910\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.3132 - accuracy: 0.8904 - val_loss: 0.9023 - val_accuracy: 0.7860\n",
      "Epoch 40/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.3064 - accuracy: 0.8922\n",
      "Epoch 00040: val_accuracy improved from 0.81910 to 0.83030, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model5_40-0.83.hdf5\n",
      "390/390 [==============================] - 136s 350ms/step - loss: 0.3063 - accuracy: 0.8923 - val_loss: 0.6351 - val_accuracy: 0.8303\n",
      "Epoch 41/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.3006 - accuracy: 0.8934\n",
      "Epoch 00041: val_accuracy did not improve from 0.83030\n",
      "390/390 [==============================] - 135s 346ms/step - loss: 0.3008 - accuracy: 0.8933 - val_loss: 0.8391 - val_accuracy: 0.7941\n",
      "Epoch 42/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.2982 - accuracy: 0.8949\n",
      "Epoch 00042: val_accuracy improved from 0.83030 to 0.83730, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model5_42-0.84.hdf5\n",
      "390/390 [==============================] - 136s 349ms/step - loss: 0.2983 - accuracy: 0.8949 - val_loss: 0.6109 - val_accuracy: 0.8373\n",
      "Epoch 43/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.2919 - accuracy: 0.8967\n",
      "Epoch 00043: val_accuracy did not improve from 0.83730\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.2916 - accuracy: 0.8968 - val_loss: 0.7076 - val_accuracy: 0.8122\n",
      "Epoch 44/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.2868 - accuracy: 0.8986\n",
      "Epoch 00044: val_accuracy did not improve from 0.83730\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.2867 - accuracy: 0.8987 - val_loss: 0.9944 - val_accuracy: 0.7681\n",
      "Epoch 45/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.2853 - accuracy: 0.8989\n",
      "Epoch 00045: val_accuracy improved from 0.83730 to 0.83780, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model5_45-0.84.hdf5\n",
      "390/390 [==============================] - 136s 349ms/step - loss: 0.2853 - accuracy: 0.8989 - val_loss: 0.6084 - val_accuracy: 0.8378\n",
      "Epoch 46/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.2780 - accuracy: 0.9024\n",
      "Epoch 00046: val_accuracy improved from 0.83780 to 0.84870, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model5_46-0.85.hdf5\n",
      "390/390 [==============================] - 136s 349ms/step - loss: 0.2780 - accuracy: 0.9024 - val_loss: 0.5594 - val_accuracy: 0.8487\n",
      "Epoch 47/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.2783 - accuracy: 0.9028\n",
      "Epoch 00047: val_accuracy did not improve from 0.84870\n",
      "390/390 [==============================] - 135s 346ms/step - loss: 0.2781 - accuracy: 0.9028 - val_loss: 0.8282 - val_accuracy: 0.8057\n",
      "Epoch 48/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.2725 - accuracy: 0.9053\n",
      "Epoch 00048: val_accuracy did not improve from 0.84870\n",
      "390/390 [==============================] - 135s 346ms/step - loss: 0.2731 - accuracy: 0.9052 - val_loss: 0.6938 - val_accuracy: 0.8179\n",
      "Epoch 49/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.2669 - accuracy: 0.9069\n",
      "Epoch 00049: val_accuracy did not improve from 0.84870\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.2668 - accuracy: 0.9069 - val_loss: 0.6449 - val_accuracy: 0.8359\n",
      "Epoch 50/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.2633 - accuracy: 0.9072\n",
      "Epoch 00050: val_accuracy did not improve from 0.84870\n",
      "390/390 [==============================] - 135s 346ms/step - loss: 0.2632 - accuracy: 0.9073 - val_loss: 0.8866 - val_accuracy: 0.8046\n",
      "Epoch 51/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.2622 - accuracy: 0.9066\n",
      "Epoch 00051: val_accuracy did not improve from 0.84870\n",
      "390/390 [==============================] - 135s 346ms/step - loss: 0.2622 - accuracy: 0.9066 - val_loss: 0.8214 - val_accuracy: 0.8092\n",
      "Epoch 52/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.2595 - accuracy: 0.9074\n",
      "Epoch 00052: val_accuracy did not improve from 0.84870\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.2594 - accuracy: 0.9074 - val_loss: 0.8079 - val_accuracy: 0.8077\n",
      "Epoch 53/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.2511 - accuracy: 0.9123\n",
      "Epoch 00053: val_accuracy did not improve from 0.84870\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.2511 - accuracy: 0.9123 - val_loss: 0.9002 - val_accuracy: 0.7969\n",
      "Epoch 54/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.2515 - accuracy: 0.9117\n",
      "Epoch 00054: val_accuracy did not improve from 0.84870\n",
      "390/390 [==============================] - 135s 346ms/step - loss: 0.2516 - accuracy: 0.9117 - val_loss: 0.6637 - val_accuracy: 0.8340\n",
      "Epoch 55/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.2464 - accuracy: 0.9133\n",
      "Epoch 00055: val_accuracy did not improve from 0.84870\n",
      "390/390 [==============================] - 136s 347ms/step - loss: 0.2464 - accuracy: 0.9133 - val_loss: 0.8131 - val_accuracy: 0.8097\n",
      "Epoch 56/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.2462 - accuracy: 0.9137\n",
      "Epoch 00056: val_accuracy did not improve from 0.84870\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.2464 - accuracy: 0.9136 - val_loss: 0.6043 - val_accuracy: 0.8413\n",
      "Epoch 57/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.2449 - accuracy: 0.9135\n",
      "Epoch 00057: val_accuracy did not improve from 0.84870\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.2449 - accuracy: 0.9135 - val_loss: 0.8142 - val_accuracy: 0.8151\n",
      "Epoch 58/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.2384 - accuracy: 0.9164\n",
      "Epoch 00058: val_accuracy did not improve from 0.84870\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.2388 - accuracy: 0.9163 - val_loss: 0.6324 - val_accuracy: 0.8385\n",
      "Epoch 59/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.2323 - accuracy: 0.9178\n",
      "Epoch 00059: val_accuracy improved from 0.84870 to 0.84920, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model5_59-0.85.hdf5\n",
      "390/390 [==============================] - 136s 348ms/step - loss: 0.2324 - accuracy: 0.9178 - val_loss: 0.5738 - val_accuracy: 0.8492\n",
      "Epoch 60/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.2327 - accuracy: 0.9179\n",
      "Epoch 00060: val_accuracy did not improve from 0.84920\n",
      "390/390 [==============================] - 135s 346ms/step - loss: 0.2325 - accuracy: 0.9179 - val_loss: 0.7680 - val_accuracy: 0.8197\n",
      "Epoch 61/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.2295 - accuracy: 0.9193\n",
      "Epoch 00061: val_accuracy did not improve from 0.84920\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.2296 - accuracy: 0.9193 - val_loss: 0.7218 - val_accuracy: 0.8255\n",
      "Epoch 62/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.2295 - accuracy: 0.9200\n",
      "Epoch 00062: val_accuracy did not improve from 0.84920\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.2295 - accuracy: 0.9200 - val_loss: 0.7827 - val_accuracy: 0.8194\n",
      "Epoch 63/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.2216 - accuracy: 0.9221\n",
      "Epoch 00063: val_accuracy improved from 0.84920 to 0.86040, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model5_63-0.86.hdf5\n",
      "390/390 [==============================] - 136s 349ms/step - loss: 0.2217 - accuracy: 0.9221 - val_loss: 0.5561 - val_accuracy: 0.8604\n",
      "Epoch 64/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.2215 - accuracy: 0.9226\n",
      "Epoch 00064: val_accuracy did not improve from 0.86040\n",
      "390/390 [==============================] - 135s 346ms/step - loss: 0.2215 - accuracy: 0.9227 - val_loss: 0.7433 - val_accuracy: 0.8266\n",
      "Epoch 65/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.2196 - accuracy: 0.9216\n",
      "Epoch 00065: val_accuracy did not improve from 0.86040\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.2195 - accuracy: 0.9216 - val_loss: 0.6962 - val_accuracy: 0.8417\n",
      "Epoch 66/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.2181 - accuracy: 0.9217\n",
      "Epoch 00066: val_accuracy did not improve from 0.86040\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.2181 - accuracy: 0.9217 - val_loss: 0.5255 - val_accuracy: 0.8593\n",
      "Epoch 67/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.2160 - accuracy: 0.9228\n",
      "Epoch 00067: val_accuracy did not improve from 0.86040\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.2160 - accuracy: 0.9228 - val_loss: 0.8274 - val_accuracy: 0.8146\n",
      "Epoch 68/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.2127 - accuracy: 0.9250\n",
      "Epoch 00068: val_accuracy did not improve from 0.86040\n",
      "390/390 [==============================] - 135s 346ms/step - loss: 0.2127 - accuracy: 0.9251 - val_loss: 0.8970 - val_accuracy: 0.7974\n",
      "Epoch 69/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.2093 - accuracy: 0.9258\n",
      "Epoch 00069: val_accuracy did not improve from 0.86040\n",
      "390/390 [==============================] - 135s 346ms/step - loss: 0.2094 - accuracy: 0.9258 - val_loss: 0.7490 - val_accuracy: 0.8222\n",
      "Epoch 70/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.2079 - accuracy: 0.9262\n",
      "Epoch 00070: val_accuracy improved from 0.86040 to 0.86540, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model5_70-0.87.hdf5\n",
      "390/390 [==============================] - 136s 349ms/step - loss: 0.2077 - accuracy: 0.9262 - val_loss: 0.5319 - val_accuracy: 0.8654\n",
      "Epoch 71/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.2056 - accuracy: 0.9275\n",
      "Epoch 00071: val_accuracy did not improve from 0.86540\n",
      "390/390 [==============================] - 135s 346ms/step - loss: 0.2055 - accuracy: 0.9276 - val_loss: 0.7056 - val_accuracy: 0.8340\n",
      "Epoch 72/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.2037 - accuracy: 0.9278\n",
      "Epoch 00072: val_accuracy did not improve from 0.86540\n",
      "390/390 [==============================] - 135s 346ms/step - loss: 0.2038 - accuracy: 0.9278 - val_loss: 0.6550 - val_accuracy: 0.8428\n",
      "Epoch 73/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1998 - accuracy: 0.9295\n",
      "Epoch 00073: val_accuracy did not improve from 0.86540\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.1997 - accuracy: 0.9295 - val_loss: 0.7607 - val_accuracy: 0.8217\n",
      "Epoch 74/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1994 - accuracy: 0.9293\n",
      "Epoch 00074: val_accuracy did not improve from 0.86540\n",
      "390/390 [==============================] - 135s 346ms/step - loss: 0.1995 - accuracy: 0.9293 - val_loss: 0.5658 - val_accuracy: 0.8615\n",
      "Epoch 75/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1976 - accuracy: 0.9299\n",
      "Epoch 00075: val_accuracy improved from 0.86540 to 0.86740, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model5_75-0.87.hdf5\n",
      "390/390 [==============================] - 136s 350ms/step - loss: 0.1975 - accuracy: 0.9299 - val_loss: 0.5567 - val_accuracy: 0.8674\n",
      "Epoch 76/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1907 - accuracy: 0.9325\n",
      "Epoch 00076: val_accuracy did not improve from 0.86740\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.1906 - accuracy: 0.9325 - val_loss: 0.5900 - val_accuracy: 0.8640\n",
      "Epoch 77/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1913 - accuracy: 0.9317\n",
      "Epoch 00077: val_accuracy did not improve from 0.86740\n",
      "390/390 [==============================] - 135s 346ms/step - loss: 0.1912 - accuracy: 0.9317 - val_loss: 0.7853 - val_accuracy: 0.8285\n",
      "Epoch 78/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1943 - accuracy: 0.9305\n",
      "Epoch 00078: val_accuracy did not improve from 0.86740\n",
      "390/390 [==============================] - 135s 346ms/step - loss: 0.1941 - accuracy: 0.9305 - val_loss: 0.8347 - val_accuracy: 0.8214\n",
      "Epoch 79/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1904 - accuracy: 0.9321\n",
      "Epoch 00079: val_accuracy did not improve from 0.86740\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.1904 - accuracy: 0.9321 - val_loss: 0.6842 - val_accuracy: 0.8546\n",
      "Epoch 80/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1905 - accuracy: 0.9324\n",
      "Epoch 00080: val_accuracy did not improve from 0.86740\n",
      "390/390 [==============================] - 135s 346ms/step - loss: 0.1906 - accuracy: 0.9324 - val_loss: 0.7611 - val_accuracy: 0.8312\n",
      "Epoch 81/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1864 - accuracy: 0.9337\n",
      "Epoch 00081: val_accuracy did not improve from 0.86740\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.1863 - accuracy: 0.9337 - val_loss: 0.5795 - val_accuracy: 0.8579\n",
      "Epoch 82/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1832 - accuracy: 0.9345\n",
      "Epoch 00082: val_accuracy did not improve from 0.86740\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.1832 - accuracy: 0.9344 - val_loss: 0.6056 - val_accuracy: 0.8547\n",
      "Epoch 83/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1780 - accuracy: 0.9364\n",
      "Epoch 00083: val_accuracy did not improve from 0.86740\n",
      "390/390 [==============================] - 135s 346ms/step - loss: 0.1780 - accuracy: 0.9364 - val_loss: 0.7099 - val_accuracy: 0.8408\n",
      "Epoch 84/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1774 - accuracy: 0.9365\n",
      "Epoch 00084: val_accuracy did not improve from 0.86740\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.1776 - accuracy: 0.9364 - val_loss: 0.8617 - val_accuracy: 0.8185\n",
      "Epoch 85/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1784 - accuracy: 0.9380\n",
      "Epoch 00085: val_accuracy did not improve from 0.86740\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.1784 - accuracy: 0.9380 - val_loss: 0.5710 - val_accuracy: 0.8667\n",
      "Epoch 86/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1809 - accuracy: 0.9349\n",
      "Epoch 00086: val_accuracy did not improve from 0.86740\n",
      "390/390 [==============================] - 135s 346ms/step - loss: 0.1809 - accuracy: 0.9349 - val_loss: 0.7086 - val_accuracy: 0.8446\n",
      "Epoch 87/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1765 - accuracy: 0.9363\n",
      "Epoch 00087: val_accuracy improved from 0.86740 to 0.87590, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model5_87-0.88.hdf5\n",
      "390/390 [==============================] - 136s 349ms/step - loss: 0.1766 - accuracy: 0.9362 - val_loss: 0.5157 - val_accuracy: 0.8759\n",
      "Epoch 88/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1737 - accuracy: 0.9378\n",
      "Epoch 00088: val_accuracy did not improve from 0.87590\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.1737 - accuracy: 0.9379 - val_loss: 0.6484 - val_accuracy: 0.8519\n",
      "Epoch 89/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1694 - accuracy: 0.9401\n",
      "Epoch 00089: val_accuracy did not improve from 0.87590\n",
      "390/390 [==============================] - 135s 346ms/step - loss: 0.1695 - accuracy: 0.9401 - val_loss: 0.5067 - val_accuracy: 0.8738\n",
      "Epoch 90/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1695 - accuracy: 0.9403\n",
      "Epoch 00090: val_accuracy did not improve from 0.87590\n",
      "390/390 [==============================] - 135s 346ms/step - loss: 0.1693 - accuracy: 0.9403 - val_loss: 0.7201 - val_accuracy: 0.8429\n",
      "Epoch 91/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1711 - accuracy: 0.9394\n",
      "Epoch 00091: val_accuracy did not improve from 0.87590\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.1712 - accuracy: 0.9394 - val_loss: 0.5750 - val_accuracy: 0.8631\n",
      "Epoch 92/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1710 - accuracy: 0.9390\n",
      "Epoch 00092: val_accuracy did not improve from 0.87590\n",
      "390/390 [==============================] - 135s 346ms/step - loss: 0.1711 - accuracy: 0.9390 - val_loss: 0.6479 - val_accuracy: 0.8540\n",
      "Epoch 93/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1673 - accuracy: 0.9399\n",
      "Epoch 00093: val_accuracy did not improve from 0.87590\n",
      "390/390 [==============================] - 135s 346ms/step - loss: 0.1674 - accuracy: 0.9398 - val_loss: 0.6256 - val_accuracy: 0.8624\n",
      "Epoch 94/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1638 - accuracy: 0.9416\n",
      "Epoch 00094: val_accuracy did not improve from 0.87590\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.1640 - accuracy: 0.9415 - val_loss: 0.6470 - val_accuracy: 0.8616\n",
      "Epoch 95/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1665 - accuracy: 0.9409\n",
      "Epoch 00095: val_accuracy did not improve from 0.87590\n",
      "390/390 [==============================] - 135s 346ms/step - loss: 0.1664 - accuracy: 0.9408 - val_loss: 0.5145 - val_accuracy: 0.8746\n",
      "Epoch 96/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1627 - accuracy: 0.9419\n",
      "Epoch 00096: val_accuracy did not improve from 0.87590\n",
      "390/390 [==============================] - 135s 346ms/step - loss: 0.1628 - accuracy: 0.9419 - val_loss: 0.7455 - val_accuracy: 0.8394\n",
      "Epoch 97/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1622 - accuracy: 0.9427\n",
      "Epoch 00097: val_accuracy did not improve from 0.87590\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.1623 - accuracy: 0.9427 - val_loss: 0.5512 - val_accuracy: 0.8722\n",
      "Epoch 98/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1611 - accuracy: 0.9422\n",
      "Epoch 00098: val_accuracy did not improve from 0.87590\n",
      "390/390 [==============================] - 135s 346ms/step - loss: 0.1613 - accuracy: 0.9421 - val_loss: 0.7458 - val_accuracy: 0.8387\n",
      "Epoch 99/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1568 - accuracy: 0.9436\n",
      "Epoch 00099: val_accuracy did not improve from 0.87590\n",
      "390/390 [==============================] - 135s 346ms/step - loss: 0.1567 - accuracy: 0.9436 - val_loss: 0.7160 - val_accuracy: 0.8471\n",
      "Epoch 100/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1551 - accuracy: 0.9456\n",
      "Epoch 00100: val_accuracy did not improve from 0.87590\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.1551 - accuracy: 0.9455 - val_loss: 0.8331 - val_accuracy: 0.8279\n",
      "Epoch 101/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1580 - accuracy: 0.9440\n",
      "Epoch 00101: val_accuracy did not improve from 0.87590\n",
      "390/390 [==============================] - 135s 346ms/step - loss: 0.1583 - accuracy: 0.9440 - val_loss: 0.7311 - val_accuracy: 0.8441\n",
      "Epoch 102/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1513 - accuracy: 0.9472\n",
      "Epoch 00102: val_accuracy did not improve from 0.87590\n",
      "390/390 [==============================] - 135s 346ms/step - loss: 0.1512 - accuracy: 0.9472 - val_loss: 0.6692 - val_accuracy: 0.8583\n",
      "Epoch 103/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1545 - accuracy: 0.9451\n",
      "Epoch 00103: val_accuracy did not improve from 0.87590\n",
      "\n",
      "Epoch 00103: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.1543 - accuracy: 0.9452 - val_loss: 0.6255 - val_accuracy: 0.8603\n",
      "Epoch 104/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1180 - accuracy: 0.9588\n",
      "Epoch 00104: val_accuracy improved from 0.87590 to 0.89080, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model5_104-0.89.hdf5\n",
      "390/390 [==============================] - 136s 349ms/step - loss: 0.1180 - accuracy: 0.9588 - val_loss: 0.4858 - val_accuracy: 0.8908\n",
      "Epoch 105/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1009 - accuracy: 0.9637\n",
      "Epoch 00105: val_accuracy did not improve from 0.89080\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.1008 - accuracy: 0.9637 - val_loss: 0.4950 - val_accuracy: 0.8906\n",
      "Epoch 106/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0979 - accuracy: 0.9653\n",
      "Epoch 00106: val_accuracy improved from 0.89080 to 0.89100, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model5_106-0.89.hdf5\n",
      "390/390 [==============================] - 136s 350ms/step - loss: 0.0979 - accuracy: 0.9653 - val_loss: 0.5031 - val_accuracy: 0.8910\n",
      "Epoch 107/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0912 - accuracy: 0.9671\n",
      "Epoch 00107: val_accuracy did not improve from 0.89100\n",
      "390/390 [==============================] - 135s 346ms/step - loss: 0.0913 - accuracy: 0.9671 - val_loss: 0.5264 - val_accuracy: 0.8891\n",
      "Epoch 108/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0850 - accuracy: 0.9702\n",
      "Epoch 00108: val_accuracy did not improve from 0.89100\n",
      "390/390 [==============================] - 135s 346ms/step - loss: 0.0850 - accuracy: 0.9703 - val_loss: 0.5278 - val_accuracy: 0.8897\n",
      "Epoch 109/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0852 - accuracy: 0.9699\n",
      "Epoch 00109: val_accuracy did not improve from 0.89100\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0853 - accuracy: 0.9699 - val_loss: 0.5183 - val_accuracy: 0.8910\n",
      "Epoch 110/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0859 - accuracy: 0.9699\n",
      "Epoch 00110: val_accuracy did not improve from 0.89100\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0859 - accuracy: 0.9700 - val_loss: 0.5395 - val_accuracy: 0.8886\n",
      "Epoch 111/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0830 - accuracy: 0.9701\n",
      "Epoch 00111: val_accuracy did not improve from 0.89100\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0829 - accuracy: 0.9702 - val_loss: 0.5458 - val_accuracy: 0.8909\n",
      "Epoch 112/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0806 - accuracy: 0.9720\n",
      "Epoch 00112: val_accuracy improved from 0.89100 to 0.89150, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model5_112-0.89.hdf5\n",
      "390/390 [==============================] - 136s 350ms/step - loss: 0.0806 - accuracy: 0.9720 - val_loss: 0.5410 - val_accuracy: 0.8915\n",
      "Epoch 113/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0809 - accuracy: 0.9711\n",
      "Epoch 00113: val_accuracy did not improve from 0.89150\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0812 - accuracy: 0.9710 - val_loss: 0.5522 - val_accuracy: 0.8909\n",
      "Epoch 114/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0790 - accuracy: 0.9719\n",
      "Epoch 00114: val_accuracy improved from 0.89150 to 0.89180, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model5_114-0.89.hdf5\n",
      "390/390 [==============================] - 136s 349ms/step - loss: 0.0790 - accuracy: 0.9719 - val_loss: 0.5481 - val_accuracy: 0.8918\n",
      "Epoch 115/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0768 - accuracy: 0.9733\n",
      "Epoch 00115: val_accuracy did not improve from 0.89180\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0770 - accuracy: 0.9734 - val_loss: 0.5404 - val_accuracy: 0.8915\n",
      "Epoch 116/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0781 - accuracy: 0.9723\n",
      "Epoch 00116: val_accuracy did not improve from 0.89180\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0780 - accuracy: 0.9724 - val_loss: 0.5824 - val_accuracy: 0.8865\n",
      "Epoch 117/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0797 - accuracy: 0.9721\n",
      "Epoch 00117: val_accuracy did not improve from 0.89180\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0798 - accuracy: 0.9720 - val_loss: 0.5693 - val_accuracy: 0.8873\n",
      "Epoch 118/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0773 - accuracy: 0.9722\n",
      "Epoch 00118: val_accuracy did not improve from 0.89180\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0775 - accuracy: 0.9721 - val_loss: 0.5688 - val_accuracy: 0.8904\n",
      "Epoch 119/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0734 - accuracy: 0.9744\n",
      "Epoch 00119: val_accuracy did not improve from 0.89180\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0734 - accuracy: 0.9745 - val_loss: 0.5809 - val_accuracy: 0.8889\n",
      "Epoch 120/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0755 - accuracy: 0.9727\n",
      "Epoch 00120: val_accuracy did not improve from 0.89180\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0755 - accuracy: 0.9727 - val_loss: 0.5653 - val_accuracy: 0.8902\n",
      "Epoch 121/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0716 - accuracy: 0.9742\n",
      "Epoch 00121: val_accuracy did not improve from 0.89180\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0716 - accuracy: 0.9742 - val_loss: 0.5992 - val_accuracy: 0.8856\n",
      "Epoch 122/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0735 - accuracy: 0.9730\n",
      "Epoch 00122: val_accuracy did not improve from 0.89180\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0735 - accuracy: 0.9730 - val_loss: 0.6007 - val_accuracy: 0.8868\n",
      "Epoch 123/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0697 - accuracy: 0.9752\n",
      "Epoch 00123: val_accuracy did not improve from 0.89180\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0698 - accuracy: 0.9751 - val_loss: 0.6243 - val_accuracy: 0.8824\n",
      "Epoch 124/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0709 - accuracy: 0.9748\n",
      "Epoch 00124: val_accuracy did not improve from 0.89180\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0710 - accuracy: 0.9747 - val_loss: 0.5675 - val_accuracy: 0.8918\n",
      "Epoch 125/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0696 - accuracy: 0.9750\n",
      "Epoch 00125: val_accuracy improved from 0.89180 to 0.89210, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model5_125-0.89.hdf5\n",
      "390/390 [==============================] - 136s 349ms/step - loss: 0.0695 - accuracy: 0.9750 - val_loss: 0.5825 - val_accuracy: 0.8921\n",
      "Epoch 126/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0690 - accuracy: 0.9761\n",
      "Epoch 00126: val_accuracy did not improve from 0.89210\n",
      "390/390 [==============================] - 136s 348ms/step - loss: 0.0691 - accuracy: 0.9760 - val_loss: 0.6159 - val_accuracy: 0.8876\n",
      "Epoch 127/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0708 - accuracy: 0.9746\n",
      "Epoch 00127: val_accuracy did not improve from 0.89210\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0709 - accuracy: 0.9746 - val_loss: 0.6079 - val_accuracy: 0.8850\n",
      "Epoch 128/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0699 - accuracy: 0.9747\n",
      "Epoch 00128: val_accuracy did not improve from 0.89210\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0699 - accuracy: 0.9747 - val_loss: 0.6289 - val_accuracy: 0.8841\n",
      "Epoch 129/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0681 - accuracy: 0.9754\n",
      "Epoch 00129: val_accuracy did not improve from 0.89210\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0680 - accuracy: 0.9754 - val_loss: 0.6260 - val_accuracy: 0.8868\n",
      "Epoch 130/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0685 - accuracy: 0.9760\n",
      "Epoch 00130: val_accuracy did not improve from 0.89210\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0685 - accuracy: 0.9759 - val_loss: 0.6424 - val_accuracy: 0.8821\n",
      "Epoch 131/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0637 - accuracy: 0.9768\n",
      "Epoch 00131: val_accuracy did not improve from 0.89210\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0638 - accuracy: 0.9768 - val_loss: 0.6219 - val_accuracy: 0.8863\n",
      "Epoch 132/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0664 - accuracy: 0.9763\n",
      "Epoch 00132: val_accuracy did not improve from 0.89210\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0664 - accuracy: 0.9763 - val_loss: 0.6491 - val_accuracy: 0.8841\n",
      "Epoch 133/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0641 - accuracy: 0.9771\n",
      "Epoch 00133: val_accuracy did not improve from 0.89210\n",
      "390/390 [==============================] - 136s 348ms/step - loss: 0.0640 - accuracy: 0.9772 - val_loss: 0.6434 - val_accuracy: 0.8854\n",
      "Epoch 134/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0652 - accuracy: 0.9771\n",
      "Epoch 00134: val_accuracy did not improve from 0.89210\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0651 - accuracy: 0.9771 - val_loss: 0.6236 - val_accuracy: 0.8865\n",
      "Epoch 135/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0664 - accuracy: 0.9768\n",
      "Epoch 00135: val_accuracy did not improve from 0.89210\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0665 - accuracy: 0.9768 - val_loss: 0.6119 - val_accuracy: 0.8880\n",
      "Epoch 136/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0660 - accuracy: 0.9766\n",
      "Epoch 00136: val_accuracy did not improve from 0.89210\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0660 - accuracy: 0.9767 - val_loss: 0.6272 - val_accuracy: 0.8867\n",
      "Epoch 137/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0648 - accuracy: 0.9765\n",
      "Epoch 00137: val_accuracy did not improve from 0.89210\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0648 - accuracy: 0.9765 - val_loss: 0.6227 - val_accuracy: 0.8883\n",
      "Epoch 138/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0663 - accuracy: 0.9762\n",
      "Epoch 00138: val_accuracy did not improve from 0.89210\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0663 - accuracy: 0.9762 - val_loss: 0.6828 - val_accuracy: 0.8830\n",
      "Epoch 139/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0642 - accuracy: 0.9773\n",
      "Epoch 00139: val_accuracy did not improve from 0.89210\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0641 - accuracy: 0.9773 - val_loss: 0.6671 - val_accuracy: 0.8811\n",
      "Epoch 140/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0627 - accuracy: 0.9773\n",
      "Epoch 00140: val_accuracy did not improve from 0.89210\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0629 - accuracy: 0.9773 - val_loss: 0.6484 - val_accuracy: 0.8865\n",
      "Epoch 141/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0650 - accuracy: 0.9771\n",
      "Epoch 00141: val_accuracy did not improve from 0.89210\n",
      "\n",
      "Epoch 00141: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0651 - accuracy: 0.9770 - val_loss: 0.6447 - val_accuracy: 0.8866\n",
      "Epoch 142/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0603 - accuracy: 0.9787\n",
      "Epoch 00142: val_accuracy did not improve from 0.89210\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0603 - accuracy: 0.9787 - val_loss: 0.6345 - val_accuracy: 0.8887\n",
      "Epoch 143/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0602 - accuracy: 0.9785\n",
      "Epoch 00143: val_accuracy did not improve from 0.89210\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0602 - accuracy: 0.9785 - val_loss: 0.6355 - val_accuracy: 0.8880\n",
      "Epoch 144/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0600 - accuracy: 0.9781\n",
      "Epoch 00144: val_accuracy did not improve from 0.89210\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0600 - accuracy: 0.9781 - val_loss: 0.6335 - val_accuracy: 0.8887\n",
      "Epoch 145/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0586 - accuracy: 0.9793\n",
      "Epoch 00145: val_accuracy did not improve from 0.89210\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0586 - accuracy: 0.9793 - val_loss: 0.6340 - val_accuracy: 0.8878\n",
      "Epoch 146/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0597 - accuracy: 0.9789\n",
      "Epoch 00146: val_accuracy did not improve from 0.89210\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0598 - accuracy: 0.9789 - val_loss: 0.6390 - val_accuracy: 0.8873\n",
      "Epoch 147/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0585 - accuracy: 0.9791\n",
      "Epoch 00147: val_accuracy did not improve from 0.89210\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0584 - accuracy: 0.9792 - val_loss: 0.6372 - val_accuracy: 0.8878\n",
      "Epoch 148/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0585 - accuracy: 0.9791\n",
      "Epoch 00148: val_accuracy did not improve from 0.89210\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0585 - accuracy: 0.9791 - val_loss: 0.6324 - val_accuracy: 0.8883\n",
      "Epoch 149/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0589 - accuracy: 0.9786\n",
      "Epoch 00149: val_accuracy did not improve from 0.89210\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0588 - accuracy: 0.9786 - val_loss: 0.6336 - val_accuracy: 0.8888\n",
      "Epoch 150/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0561 - accuracy: 0.9797\n",
      "Epoch 00150: val_accuracy did not improve from 0.89210\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0561 - accuracy: 0.9796 - val_loss: 0.6279 - val_accuracy: 0.8890\n",
      "Epoch 151/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0568 - accuracy: 0.9794\n",
      "Epoch 00151: val_accuracy did not improve from 0.89210\n",
      "390/390 [==============================] - 136s 348ms/step - loss: 0.0568 - accuracy: 0.9794 - val_loss: 0.6345 - val_accuracy: 0.8883\n",
      "Epoch 152/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0563 - accuracy: 0.9799\n",
      "Epoch 00152: val_accuracy did not improve from 0.89210\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0564 - accuracy: 0.9799 - val_loss: 0.6357 - val_accuracy: 0.8890\n",
      "Epoch 153/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0549 - accuracy: 0.9811\n",
      "Epoch 00153: val_accuracy did not improve from 0.89210\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0548 - accuracy: 0.9811 - val_loss: 0.6367 - val_accuracy: 0.8892\n",
      "Epoch 154/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0597 - accuracy: 0.9786\n",
      "Epoch 00154: val_accuracy did not improve from 0.89210\n",
      "390/390 [==============================] - 136s 348ms/step - loss: 0.0597 - accuracy: 0.9786 - val_loss: 0.6346 - val_accuracy: 0.8890\n",
      "Epoch 155/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0566 - accuracy: 0.9803\n",
      "Epoch 00155: val_accuracy did not improve from 0.89210\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0566 - accuracy: 0.9803 - val_loss: 0.6294 - val_accuracy: 0.8892\n",
      "Epoch 156/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0592 - accuracy: 0.9791\n",
      "Epoch 00156: val_accuracy did not improve from 0.89210\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0591 - accuracy: 0.9792 - val_loss: 0.6295 - val_accuracy: 0.8899\n",
      "Epoch 157/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0569 - accuracy: 0.9795\n",
      "Epoch 00157: val_accuracy did not improve from 0.89210\n",
      "\n",
      "Epoch 00157: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0569 - accuracy: 0.9795 - val_loss: 0.6296 - val_accuracy: 0.8905\n",
      "Epoch 158/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0564 - accuracy: 0.9796\n",
      "Epoch 00158: val_accuracy did not improve from 0.89210\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0563 - accuracy: 0.9797 - val_loss: 0.6307 - val_accuracy: 0.8903\n",
      "Epoch 159/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0574 - accuracy: 0.9792\n",
      "Epoch 00159: val_accuracy did not improve from 0.89210\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0574 - accuracy: 0.9791 - val_loss: 0.6280 - val_accuracy: 0.8900\n",
      "Epoch 160/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0568 - accuracy: 0.9797\n",
      "Epoch 00160: val_accuracy did not improve from 0.89210\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0569 - accuracy: 0.9796 - val_loss: 0.6276 - val_accuracy: 0.8908\n",
      "Epoch 161/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0579 - accuracy: 0.9789\n",
      "Epoch 00161: val_accuracy did not improve from 0.89210\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0578 - accuracy: 0.9788 - val_loss: 0.6288 - val_accuracy: 0.8903\n",
      "Epoch 162/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0589 - accuracy: 0.9787\n",
      "Epoch 00162: val_accuracy did not improve from 0.89210\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0589 - accuracy: 0.9787 - val_loss: 0.6321 - val_accuracy: 0.8902\n",
      "Epoch 163/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0564 - accuracy: 0.9799\n",
      "Epoch 00163: val_accuracy did not improve from 0.89210\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0563 - accuracy: 0.9800 - val_loss: 0.6301 - val_accuracy: 0.8898\n",
      "Epoch 164/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0584 - accuracy: 0.9789\n",
      "Epoch 00164: val_accuracy did not improve from 0.89210\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0584 - accuracy: 0.9789 - val_loss: 0.6253 - val_accuracy: 0.8903\n",
      "Epoch 165/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0559 - accuracy: 0.9808\n",
      "Epoch 00165: val_accuracy did not improve from 0.89210\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0559 - accuracy: 0.9808 - val_loss: 0.6271 - val_accuracy: 0.8904\n",
      "Epoch 166/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0579 - accuracy: 0.9793\n",
      "Epoch 00166: val_accuracy did not improve from 0.89210\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0580 - accuracy: 0.9793 - val_loss: 0.6305 - val_accuracy: 0.8906\n",
      "Epoch 167/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0542 - accuracy: 0.9804\n",
      "Epoch 00167: val_accuracy did not improve from 0.89210\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0541 - accuracy: 0.9805 - val_loss: 0.6304 - val_accuracy: 0.8903\n",
      "Epoch 168/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0567 - accuracy: 0.9790\n",
      "Epoch 00168: val_accuracy did not improve from 0.89210\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0567 - accuracy: 0.9790 - val_loss: 0.6275 - val_accuracy: 0.8910\n",
      "Epoch 169/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0588 - accuracy: 0.9790\n",
      "Epoch 00169: val_accuracy did not improve from 0.89210\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0587 - accuracy: 0.9790 - val_loss: 0.6263 - val_accuracy: 0.8912\n",
      "Epoch 170/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0587 - accuracy: 0.9789\n",
      "Epoch 00170: val_accuracy did not improve from 0.89210\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0587 - accuracy: 0.9789 - val_loss: 0.6336 - val_accuracy: 0.8901\n",
      "Epoch 171/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0565 - accuracy: 0.9798\n",
      "Epoch 00171: val_accuracy did not improve from 0.89210\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0565 - accuracy: 0.9799 - val_loss: 0.6327 - val_accuracy: 0.8901\n",
      "Epoch 172/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0595 - accuracy: 0.9792\n",
      "Epoch 00172: val_accuracy did not improve from 0.89210\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0595 - accuracy: 0.9792 - val_loss: 0.6267 - val_accuracy: 0.8905\n",
      "Epoch 173/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0556 - accuracy: 0.9805\n",
      "Epoch 00173: val_accuracy did not improve from 0.89210\n",
      "\n",
      "Epoch 00173: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0556 - accuracy: 0.9805 - val_loss: 0.6276 - val_accuracy: 0.8906\n",
      "Epoch 174/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0571 - accuracy: 0.9797\n",
      "Epoch 00174: val_accuracy did not improve from 0.89210\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0570 - accuracy: 0.9797 - val_loss: 0.6287 - val_accuracy: 0.8908\n",
      "Epoch 175/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0567 - accuracy: 0.9807\n",
      "Epoch 00175: val_accuracy did not improve from 0.89210\n",
      "390/390 [==============================] - 135s 347ms/step - loss: 0.0567 - accuracy: 0.9806 - val_loss: 0.6282 - val_accuracy: 0.8906\n"
     ]
    }
   ],
   "source": [
    "model_5.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "patience = 50\n",
    "base_path = '/home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/'\n",
    "checkpoint_file_name = base_path + 'CIFAR_model5' + '_{epoch:02d}-{val_accuracy:.2f}.hdf5'\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(checkpoint_file_name, monitor='val_accuracy', verbose=1, save_best_only=True)\n",
    "early_stop = EarlyStopping('val_accuracy', mode='max', patience = patience)\n",
    "reduce_LR = ReduceLROnPlateau(monitor='val_accuracy', mode='max', factor=0.1, patience=int(patience/3), verbose=1)\n",
    "\n",
    "callbacks = [model_checkpoint, early_stop, reduce_LR]\n",
    "\n",
    "epochs = 300\n",
    "batch_size = 128\n",
    "\n",
    "#https://keras.io/api/preprocessing/image/#flow-method\n",
    "history_5 = model_5.fit(data_generator.flow(X_train, y_train, batch_size),\n",
    "                    steps_per_epoch = int(len(X_train)/batch_size),\n",
    "                    epochs = epochs,\n",
    "                    callbacks = callbacks,\n",
    "                    validation_data = (X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#history plot for accyracy\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.plot(history_5.history['accuracy'])\n",
    "plt.plot(history_5.history['val_accuracy'])\n",
    "plt.title(\"Model Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend([\"train\", \"test\"], loc=\"upper left\")\n",
    "plt.show()\n",
    "\n",
    "# history plot for accuracy\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.plot(history_5.history[\"loss\"])\n",
    "plt.plot(history_5.history[\"val_loss\"])\n",
    "plt.title(\"Model Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend([\"train\", \"test\"], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 9s 878us/sample - loss: 0.5825 - accuracy: 0.8921\n",
      "[0.5824969663321972, 0.8921]\n"
     ]
    }
   ],
   "source": [
    "best_model_5 = tf.keras.models.load_model('/home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model5_125-0.89.hdf5')\n",
    "scores = best_model_5.evaluate(X_test, y_test, verbose=1)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model -6\n",
    "- Model-5 without dropouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BN-->ReLU-->Conv2D-->Dropout-->concat(input, output)-->(put in loop)\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "num_classes = 10\n",
    "\n",
    "def denseblock(input, num_filter, dropout_rate):\n",
    "    global compression      # to keep the growth rate of number of filters\n",
    "    temp = input\n",
    "    for _ in range(l): \n",
    "        BatchNorm = layers.BatchNormalization()(temp)\n",
    "        relu = layers.Activation('relu')(BatchNorm)\n",
    "        Conv2D_7_7= layers.SeparableConv2D(int(num_filter*compression), (7,7), use_bias=False, padding='same')(relu)\n",
    "        if dropout_rate>0:\n",
    "            Conv2D_7_7 = layers.Dropout(dropout_rate)(Conv2D_7_7)\n",
    "\n",
    "        #concat the input(temp) and output(conv2d_7_7) , in resnet we add but here we concat \n",
    "        concat = layers.Concatenate(axis=-1)([temp,Conv2D_7_7])\n",
    "        \n",
    "        #change the concat as input\n",
    "        temp = concat\n",
    "        \n",
    "    return temp\n",
    "\n",
    "#BN-->relu-->conv2d(1x1)-->dropout-->avg_pool\n",
    "def transition(input, num_filter, dropout_rate):\n",
    "    global compression\n",
    "    BatchNorm = layers.BatchNormalization()(input)\n",
    "    relu = layers.Activation('relu')(BatchNorm)\n",
    "    Conv2D_BottleNeck = layers.SeparableConvolution2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
    "    if dropout_rate>0:\n",
    "         Conv2D_BottleNeck = layers.Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
    "    avg = layers.AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
    "    return avg\n",
    "\n",
    "#BN-->relu-->avgpool-->flat-->softmax\n",
    "def output_layer(input):\n",
    "    global compression\n",
    "    BatchNorm = layers.BatchNormalization()(input)\n",
    "    relu = layers.Activation('relu')(BatchNorm)\n",
    "    AvgPooling = layers.AveragePooling2D(pool_size=(2,2))(relu)\n",
    "    conv_op = layers.SeparableConvolution2D(num_classes, (2,2), padding='valid')(AvgPooling)\n",
    "    flat = layers.Flatten()(conv_op)\n",
    "    output = layers.Dense(num_classes, activation='softmax')(flat)\n",
    "    return output\n",
    "\n",
    "# Hyperparameters\n",
    "l = 21\n",
    "num_filter = 48\n",
    "compression = 0.3\n",
    "dropout_rate = 0\n",
    "num_classes = 10\n",
    "\n",
    "input = layers.Input(shape=(input_size))\n",
    "First_Conv2D = layers.Conv2D(num_filter, (7,7), use_bias=False ,padding='same')(input)\n",
    "\n",
    "#First dense and transition block\n",
    "First_Block = denseblock(First_Conv2D, num_filter, dropout_rate)\n",
    "First_Transition = transition(First_Block, num_filter, dropout_rate)\n",
    "\n",
    "#Second dense and transition block\n",
    "Second_Block = denseblock(First_Transition, num_filter, dropout_rate)\n",
    "Second_Transition = transition(Second_Block, num_filter, dropout_rate)\n",
    "\n",
    "#Third dense and transition block\n",
    "Third_Block = denseblock(Second_Transition, num_filter, dropout_rate)\n",
    "Third_Transition = transition(Third_Block, num_filter, dropout_rate)\n",
    "\n",
    "#last dense and output block\n",
    "Last_Block = denseblock(Third_Transition,  num_filter, dropout_rate)\n",
    "output = output_layer(Last_Block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 32, 48)   7056        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32, 32, 48)   192         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 32, 32, 48)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d (SeparableConv (None, 32, 32, 14)   3024        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 32, 32, 62)   0           conv2d[0][0]                     \n",
      "                                                                 separable_conv2d[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 62)   248         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 62)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_1 (SeparableCo (None, 32, 32, 14)   3906        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 76)   0           concatenate[0][0]                \n",
      "                                                                 separable_conv2d_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 76)   304         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 76)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2 (SeparableCo (None, 32, 32, 14)   4788        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 90)   0           concatenate_1[0][0]              \n",
      "                                                                 separable_conv2d_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 90)   360         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 90)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_3 (SeparableCo (None, 32, 32, 14)   5670        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 32, 32, 104)  0           concatenate_2[0][0]              \n",
      "                                                                 separable_conv2d_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 104)  416         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 104)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_4 (SeparableCo (None, 32, 32, 14)   6552        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 32, 32, 118)  0           concatenate_3[0][0]              \n",
      "                                                                 separable_conv2d_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 118)  472         concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 118)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_5 (SeparableCo (None, 32, 32, 14)   7434        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 32, 32, 132)  0           concatenate_4[0][0]              \n",
      "                                                                 separable_conv2d_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 132)  528         concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 132)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_6 (SeparableCo (None, 32, 32, 14)   8316        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 32, 32, 146)  0           concatenate_5[0][0]              \n",
      "                                                                 separable_conv2d_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 146)  584         concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 146)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_7 (SeparableCo (None, 32, 32, 14)   9198        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 32, 32, 160)  0           concatenate_6[0][0]              \n",
      "                                                                 separable_conv2d_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 160)  640         concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 160)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_8 (SeparableCo (None, 32, 32, 14)   10080       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 32, 32, 174)  0           concatenate_7[0][0]              \n",
      "                                                                 separable_conv2d_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 174)  696         concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 174)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_9 (SeparableCo (None, 32, 32, 14)   10962       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 32, 32, 188)  0           concatenate_8[0][0]              \n",
      "                                                                 separable_conv2d_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 32, 188)  752         concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 32, 32, 188)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_10 (SeparableC (None, 32, 32, 14)   11844       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 32, 32, 202)  0           concatenate_9[0][0]              \n",
      "                                                                 separable_conv2d_10[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 202)  808         concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 32, 32, 202)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_11 (SeparableC (None, 32, 32, 14)   12726       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 32, 32, 216)  0           concatenate_10[0][0]             \n",
      "                                                                 separable_conv2d_11[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 32, 32, 216)  864         concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 32, 32, 216)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_12 (SeparableC (None, 32, 32, 14)   13608       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 32, 32, 230)  0           concatenate_11[0][0]             \n",
      "                                                                 separable_conv2d_12[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 32, 32, 230)  920         concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 32, 32, 230)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_13 (SeparableC (None, 32, 32, 14)   14490       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 32, 32, 244)  0           concatenate_12[0][0]             \n",
      "                                                                 separable_conv2d_13[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 32, 32, 244)  976         concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 32, 32, 244)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_14 (SeparableC (None, 32, 32, 14)   15372       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 32, 32, 258)  0           concatenate_13[0][0]             \n",
      "                                                                 separable_conv2d_14[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 32, 258)  1032        concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 32, 32, 258)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_15 (SeparableC (None, 32, 32, 14)   16254       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 32, 32, 272)  0           concatenate_14[0][0]             \n",
      "                                                                 separable_conv2d_15[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 32, 32, 272)  1088        concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 32, 32, 272)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_16 (SeparableC (None, 32, 32, 14)   17136       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 32, 32, 286)  0           concatenate_15[0][0]             \n",
      "                                                                 separable_conv2d_16[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 32, 32, 286)  1144        concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 32, 32, 286)  0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_17 (SeparableC (None, 32, 32, 14)   18018       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 32, 32, 300)  0           concatenate_16[0][0]             \n",
      "                                                                 separable_conv2d_17[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 32, 32, 300)  1200        concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 32, 32, 300)  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_18 (SeparableC (None, 32, 32, 14)   18900       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 32, 32, 314)  0           concatenate_17[0][0]             \n",
      "                                                                 separable_conv2d_18[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 32, 32, 314)  1256        concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 32, 32, 314)  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_19 (SeparableC (None, 32, 32, 14)   19782       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 32, 32, 328)  0           concatenate_18[0][0]             \n",
      "                                                                 separable_conv2d_19[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 32, 32, 328)  1312        concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 32, 32, 328)  0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_20 (SeparableC (None, 32, 32, 14)   20664       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 32, 32, 342)  0           concatenate_19[0][0]             \n",
      "                                                                 separable_conv2d_20[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 32, 32, 342)  1368        concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 32, 32, 342)  0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_21 (SeparableC (None, 32, 32, 14)   5130        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 16, 16, 14)   0           separable_conv2d_21[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 16, 16, 14)   56          average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 16, 16, 14)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_22 (SeparableC (None, 16, 16, 14)   882         activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 16, 16, 28)   0           average_pooling2d[0][0]          \n",
      "                                                                 separable_conv2d_22[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 16, 16, 28)   112         concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 16, 16, 28)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_23 (SeparableC (None, 16, 16, 14)   1764        activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 16, 16, 42)   0           concatenate_21[0][0]             \n",
      "                                                                 separable_conv2d_23[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 16, 16, 42)   168         concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 16, 16, 42)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_24 (SeparableC (None, 16, 16, 14)   2646        activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 16, 16, 56)   0           concatenate_22[0][0]             \n",
      "                                                                 separable_conv2d_24[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 16, 16, 56)   224         concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16, 16, 56)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_25 (SeparableC (None, 16, 16, 14)   3528        activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 16, 16, 70)   0           concatenate_23[0][0]             \n",
      "                                                                 separable_conv2d_25[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 16, 16, 70)   280         concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 16, 16, 70)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_26 (SeparableC (None, 16, 16, 14)   4410        activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 16, 16, 84)   0           concatenate_24[0][0]             \n",
      "                                                                 separable_conv2d_26[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 16, 16, 84)   336         concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 16, 16, 84)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_27 (SeparableC (None, 16, 16, 14)   5292        activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 16, 16, 98)   0           concatenate_25[0][0]             \n",
      "                                                                 separable_conv2d_27[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 16, 16, 98)   392         concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 16, 16, 98)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_28 (SeparableC (None, 16, 16, 14)   6174        activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 16, 16, 112)  0           concatenate_26[0][0]             \n",
      "                                                                 separable_conv2d_28[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 16, 16, 112)  448         concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 16, 16, 112)  0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_29 (SeparableC (None, 16, 16, 14)   7056        activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 16, 16, 126)  0           concatenate_27[0][0]             \n",
      "                                                                 separable_conv2d_29[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 16, 16, 126)  504         concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 16, 16, 126)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_30 (SeparableC (None, 16, 16, 14)   7938        activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 16, 16, 140)  0           concatenate_28[0][0]             \n",
      "                                                                 separable_conv2d_30[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 16, 16, 140)  560         concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 16, 16, 140)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_31 (SeparableC (None, 16, 16, 14)   8820        activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 16, 16, 154)  0           concatenate_29[0][0]             \n",
      "                                                                 separable_conv2d_31[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 16, 16, 154)  616         concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 16, 16, 154)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_32 (SeparableC (None, 16, 16, 14)   9702        activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 16, 16, 168)  0           concatenate_30[0][0]             \n",
      "                                                                 separable_conv2d_32[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 16, 16, 168)  672         concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 16, 16, 168)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_33 (SeparableC (None, 16, 16, 14)   10584       activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 16, 16, 182)  0           concatenate_31[0][0]             \n",
      "                                                                 separable_conv2d_33[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 16, 16, 182)  728         concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 16, 16, 182)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_34 (SeparableC (None, 16, 16, 14)   11466       activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 16, 16, 196)  0           concatenate_32[0][0]             \n",
      "                                                                 separable_conv2d_34[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 16, 16, 196)  784         concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 16, 16, 196)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_35 (SeparableC (None, 16, 16, 14)   12348       activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)    (None, 16, 16, 210)  0           concatenate_33[0][0]             \n",
      "                                                                 separable_conv2d_35[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 16, 16, 210)  840         concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 16, 16, 210)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_36 (SeparableC (None, 16, 16, 14)   13230       activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)    (None, 16, 16, 224)  0           concatenate_34[0][0]             \n",
      "                                                                 separable_conv2d_36[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 16, 16, 224)  896         concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 16, 16, 224)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_37 (SeparableC (None, 16, 16, 14)   14112       activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)    (None, 16, 16, 238)  0           concatenate_35[0][0]             \n",
      "                                                                 separable_conv2d_37[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 16, 16, 238)  952         concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 16, 16, 238)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_38 (SeparableC (None, 16, 16, 14)   14994       activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_37 (Concatenate)    (None, 16, 16, 252)  0           concatenate_36[0][0]             \n",
      "                                                                 separable_conv2d_38[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 16, 16, 252)  1008        concatenate_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 16, 16, 252)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_39 (SeparableC (None, 16, 16, 14)   15876       activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_38 (Concatenate)    (None, 16, 16, 266)  0           concatenate_37[0][0]             \n",
      "                                                                 separable_conv2d_39[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 16, 16, 266)  1064        concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 16, 16, 266)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_40 (SeparableC (None, 16, 16, 14)   16758       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_39 (Concatenate)    (None, 16, 16, 280)  0           concatenate_38[0][0]             \n",
      "                                                                 separable_conv2d_40[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 16, 16, 280)  1120        concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 16, 16, 280)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_41 (SeparableC (None, 16, 16, 14)   17640       activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_40 (Concatenate)    (None, 16, 16, 294)  0           concatenate_39[0][0]             \n",
      "                                                                 separable_conv2d_41[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 16, 16, 294)  1176        concatenate_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 16, 16, 294)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_42 (SeparableC (None, 16, 16, 14)   18522       activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_41 (Concatenate)    (None, 16, 16, 308)  0           concatenate_40[0][0]             \n",
      "                                                                 separable_conv2d_42[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 16, 16, 308)  1232        concatenate_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 16, 16, 308)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_43 (SeparableC (None, 16, 16, 14)   4620        activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 8, 8, 14)     0           separable_conv2d_43[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 8, 8, 14)     56          average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 8, 8, 14)     0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_44 (SeparableC (None, 8, 8, 14)     882         activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_42 (Concatenate)    (None, 8, 8, 28)     0           average_pooling2d_1[0][0]        \n",
      "                                                                 separable_conv2d_44[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 8, 8, 28)     112         concatenate_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 8, 8, 28)     0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_45 (SeparableC (None, 8, 8, 14)     1764        activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_43 (Concatenate)    (None, 8, 8, 42)     0           concatenate_42[0][0]             \n",
      "                                                                 separable_conv2d_45[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 8, 8, 42)     168         concatenate_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 8, 8, 42)     0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_46 (SeparableC (None, 8, 8, 14)     2646        activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_44 (Concatenate)    (None, 8, 8, 56)     0           concatenate_43[0][0]             \n",
      "                                                                 separable_conv2d_46[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 8, 8, 56)     224         concatenate_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 8, 8, 56)     0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_47 (SeparableC (None, 8, 8, 14)     3528        activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_45 (Concatenate)    (None, 8, 8, 70)     0           concatenate_44[0][0]             \n",
      "                                                                 separable_conv2d_47[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 8, 8, 70)     280         concatenate_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 8, 8, 70)     0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_48 (SeparableC (None, 8, 8, 14)     4410        activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_46 (Concatenate)    (None, 8, 8, 84)     0           concatenate_45[0][0]             \n",
      "                                                                 separable_conv2d_48[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 8, 8, 84)     336         concatenate_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 8, 8, 84)     0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_49 (SeparableC (None, 8, 8, 14)     5292        activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_47 (Concatenate)    (None, 8, 8, 98)     0           concatenate_46[0][0]             \n",
      "                                                                 separable_conv2d_49[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 8, 8, 98)     392         concatenate_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 8, 8, 98)     0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_50 (SeparableC (None, 8, 8, 14)     6174        activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_48 (Concatenate)    (None, 8, 8, 112)    0           concatenate_47[0][0]             \n",
      "                                                                 separable_conv2d_50[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 8, 8, 112)    448         concatenate_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 8, 8, 112)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_51 (SeparableC (None, 8, 8, 14)     7056        activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_49 (Concatenate)    (None, 8, 8, 126)    0           concatenate_48[0][0]             \n",
      "                                                                 separable_conv2d_51[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 8, 8, 126)    504         concatenate_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 8, 8, 126)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_52 (SeparableC (None, 8, 8, 14)     7938        activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_50 (Concatenate)    (None, 8, 8, 140)    0           concatenate_49[0][0]             \n",
      "                                                                 separable_conv2d_52[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 8, 8, 140)    560         concatenate_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 8, 8, 140)    0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_53 (SeparableC (None, 8, 8, 14)     8820        activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_51 (Concatenate)    (None, 8, 8, 154)    0           concatenate_50[0][0]             \n",
      "                                                                 separable_conv2d_53[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 8, 8, 154)    616         concatenate_51[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 8, 8, 154)    0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_54 (SeparableC (None, 8, 8, 14)     9702        activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_52 (Concatenate)    (None, 8, 8, 168)    0           concatenate_51[0][0]             \n",
      "                                                                 separable_conv2d_54[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 8, 8, 168)    672         concatenate_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 8, 8, 168)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_55 (SeparableC (None, 8, 8, 14)     10584       activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_53 (Concatenate)    (None, 8, 8, 182)    0           concatenate_52[0][0]             \n",
      "                                                                 separable_conv2d_55[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 8, 8, 182)    728         concatenate_53[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 8, 8, 182)    0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_56 (SeparableC (None, 8, 8, 14)     11466       activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_54 (Concatenate)    (None, 8, 8, 196)    0           concatenate_53[0][0]             \n",
      "                                                                 separable_conv2d_56[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 8, 8, 196)    784         concatenate_54[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 8, 8, 196)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_57 (SeparableC (None, 8, 8, 14)     12348       activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_55 (Concatenate)    (None, 8, 8, 210)    0           concatenate_54[0][0]             \n",
      "                                                                 separable_conv2d_57[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 8, 8, 210)    840         concatenate_55[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 8, 8, 210)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_58 (SeparableC (None, 8, 8, 14)     13230       activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_56 (Concatenate)    (None, 8, 8, 224)    0           concatenate_55[0][0]             \n",
      "                                                                 separable_conv2d_58[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 8, 8, 224)    896         concatenate_56[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 8, 8, 224)    0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_59 (SeparableC (None, 8, 8, 14)     14112       activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_57 (Concatenate)    (None, 8, 8, 238)    0           concatenate_56[0][0]             \n",
      "                                                                 separable_conv2d_59[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 8, 8, 238)    952         concatenate_57[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 8, 8, 238)    0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_60 (SeparableC (None, 8, 8, 14)     14994       activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_58 (Concatenate)    (None, 8, 8, 252)    0           concatenate_57[0][0]             \n",
      "                                                                 separable_conv2d_60[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 8, 8, 252)    1008        concatenate_58[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 8, 8, 252)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_61 (SeparableC (None, 8, 8, 14)     15876       activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_59 (Concatenate)    (None, 8, 8, 266)    0           concatenate_58[0][0]             \n",
      "                                                                 separable_conv2d_61[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 8, 8, 266)    1064        concatenate_59[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 8, 8, 266)    0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_62 (SeparableC (None, 8, 8, 14)     16758       activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_60 (Concatenate)    (None, 8, 8, 280)    0           concatenate_59[0][0]             \n",
      "                                                                 separable_conv2d_62[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 8, 8, 280)    1120        concatenate_60[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 8, 8, 280)    0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_63 (SeparableC (None, 8, 8, 14)     17640       activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_61 (Concatenate)    (None, 8, 8, 294)    0           concatenate_60[0][0]             \n",
      "                                                                 separable_conv2d_63[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 8, 8, 294)    1176        concatenate_61[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 8, 8, 294)    0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_64 (SeparableC (None, 8, 8, 14)     18522       activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_62 (Concatenate)    (None, 8, 8, 308)    0           concatenate_61[0][0]             \n",
      "                                                                 separable_conv2d_64[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 8, 8, 308)    1232        concatenate_62[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 8, 8, 308)    0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_65 (SeparableC (None, 8, 8, 14)     4620        activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 4, 4, 14)     0           separable_conv2d_65[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 4, 4, 14)     56          average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 4, 4, 14)     0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_66 (SeparableC (None, 4, 4, 14)     882         activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_63 (Concatenate)    (None, 4, 4, 28)     0           average_pooling2d_2[0][0]        \n",
      "                                                                 separable_conv2d_66[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 4, 4, 28)     112         concatenate_63[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 4, 4, 28)     0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_67 (SeparableC (None, 4, 4, 14)     1764        activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_64 (Concatenate)    (None, 4, 4, 42)     0           concatenate_63[0][0]             \n",
      "                                                                 separable_conv2d_67[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 4, 4, 42)     168         concatenate_64[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 4, 4, 42)     0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_68 (SeparableC (None, 4, 4, 14)     2646        activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_65 (Concatenate)    (None, 4, 4, 56)     0           concatenate_64[0][0]             \n",
      "                                                                 separable_conv2d_68[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 4, 4, 56)     224         concatenate_65[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 4, 4, 56)     0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_69 (SeparableC (None, 4, 4, 14)     3528        activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_66 (Concatenate)    (None, 4, 4, 70)     0           concatenate_65[0][0]             \n",
      "                                                                 separable_conv2d_69[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 4, 4, 70)     280         concatenate_66[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 4, 4, 70)     0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_70 (SeparableC (None, 4, 4, 14)     4410        activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_67 (Concatenate)    (None, 4, 4, 84)     0           concatenate_66[0][0]             \n",
      "                                                                 separable_conv2d_70[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 4, 4, 84)     336         concatenate_67[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 4, 4, 84)     0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_71 (SeparableC (None, 4, 4, 14)     5292        activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_68 (Concatenate)    (None, 4, 4, 98)     0           concatenate_67[0][0]             \n",
      "                                                                 separable_conv2d_71[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 4, 4, 98)     392         concatenate_68[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 4, 4, 98)     0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_72 (SeparableC (None, 4, 4, 14)     6174        activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_69 (Concatenate)    (None, 4, 4, 112)    0           concatenate_68[0][0]             \n",
      "                                                                 separable_conv2d_72[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 4, 4, 112)    448         concatenate_69[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 4, 4, 112)    0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_73 (SeparableC (None, 4, 4, 14)     7056        activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_70 (Concatenate)    (None, 4, 4, 126)    0           concatenate_69[0][0]             \n",
      "                                                                 separable_conv2d_73[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 4, 4, 126)    504         concatenate_70[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 4, 4, 126)    0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_74 (SeparableC (None, 4, 4, 14)     7938        activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_71 (Concatenate)    (None, 4, 4, 140)    0           concatenate_70[0][0]             \n",
      "                                                                 separable_conv2d_74[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 4, 4, 140)    560         concatenate_71[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 4, 4, 140)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_75 (SeparableC (None, 4, 4, 14)     8820        activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_72 (Concatenate)    (None, 4, 4, 154)    0           concatenate_71[0][0]             \n",
      "                                                                 separable_conv2d_75[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 4, 4, 154)    616         concatenate_72[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 4, 4, 154)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_76 (SeparableC (None, 4, 4, 14)     9702        activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_73 (Concatenate)    (None, 4, 4, 168)    0           concatenate_72[0][0]             \n",
      "                                                                 separable_conv2d_76[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 4, 4, 168)    672         concatenate_73[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 4, 4, 168)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_77 (SeparableC (None, 4, 4, 14)     10584       activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_74 (Concatenate)    (None, 4, 4, 182)    0           concatenate_73[0][0]             \n",
      "                                                                 separable_conv2d_77[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 4, 4, 182)    728         concatenate_74[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 4, 4, 182)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_78 (SeparableC (None, 4, 4, 14)     11466       activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_75 (Concatenate)    (None, 4, 4, 196)    0           concatenate_74[0][0]             \n",
      "                                                                 separable_conv2d_78[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 4, 4, 196)    784         concatenate_75[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 4, 4, 196)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_79 (SeparableC (None, 4, 4, 14)     12348       activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_76 (Concatenate)    (None, 4, 4, 210)    0           concatenate_75[0][0]             \n",
      "                                                                 separable_conv2d_79[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 4, 4, 210)    840         concatenate_76[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 4, 4, 210)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_80 (SeparableC (None, 4, 4, 14)     13230       activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_77 (Concatenate)    (None, 4, 4, 224)    0           concatenate_76[0][0]             \n",
      "                                                                 separable_conv2d_80[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 4, 4, 224)    896         concatenate_77[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 4, 4, 224)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_81 (SeparableC (None, 4, 4, 14)     14112       activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_78 (Concatenate)    (None, 4, 4, 238)    0           concatenate_77[0][0]             \n",
      "                                                                 separable_conv2d_81[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 4, 4, 238)    952         concatenate_78[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 4, 4, 238)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_82 (SeparableC (None, 4, 4, 14)     14994       activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_79 (Concatenate)    (None, 4, 4, 252)    0           concatenate_78[0][0]             \n",
      "                                                                 separable_conv2d_82[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 4, 4, 252)    1008        concatenate_79[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 4, 4, 252)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_83 (SeparableC (None, 4, 4, 14)     15876       activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_80 (Concatenate)    (None, 4, 4, 266)    0           concatenate_79[0][0]             \n",
      "                                                                 separable_conv2d_83[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 4, 4, 266)    1064        concatenate_80[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 4, 4, 266)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_84 (SeparableC (None, 4, 4, 14)     16758       activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_81 (Concatenate)    (None, 4, 4, 280)    0           concatenate_80[0][0]             \n",
      "                                                                 separable_conv2d_84[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 4, 4, 280)    1120        concatenate_81[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 4, 4, 280)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_85 (SeparableC (None, 4, 4, 14)     17640       activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_82 (Concatenate)    (None, 4, 4, 294)    0           concatenate_81[0][0]             \n",
      "                                                                 separable_conv2d_85[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 4, 4, 294)    1176        concatenate_82[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 4, 4, 294)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_86 (SeparableC (None, 4, 4, 14)     18522       activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_83 (Concatenate)    (None, 4, 4, 308)    0           concatenate_82[0][0]             \n",
      "                                                                 separable_conv2d_86[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 4, 4, 308)    1232        concatenate_83[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 4, 4, 308)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 2, 2, 308)    0           activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_87 (SeparableC (None, 1, 1, 10)     4322        average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 10)           0           separable_conv2d_87[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           110         flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 945,472\n",
      "Trainable params: 915,640\n",
      "Non-trainable params: 29,832\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_6 = tf.keras.models.Model(inputs=[input], outputs=[output])\n",
    "model_6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 390 steps, validate on 10000 samples\n",
      "Epoch 1/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 1.6755 - accuracy: 0.3733\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.28830, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model6_01-0.29.hdf5\n",
      "390/390 [==============================] - 161s 413ms/step - loss: 1.6753 - accuracy: 0.3734 - val_loss: 1.9707 - val_accuracy: 0.2883\n",
      "Epoch 2/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 1.2802 - accuracy: 0.5367\n",
      "Epoch 00002: val_accuracy improved from 0.28830 to 0.50130, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model6_02-0.50.hdf5\n",
      "390/390 [==============================] - 138s 354ms/step - loss: 1.2799 - accuracy: 0.5369 - val_loss: 1.4081 - val_accuracy: 0.5013\n",
      "Epoch 3/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 1.0749 - accuracy: 0.6182\n",
      "Epoch 00003: val_accuracy improved from 0.50130 to 0.55070, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model6_03-0.55.hdf5\n",
      "390/390 [==============================] - 138s 354ms/step - loss: 1.0746 - accuracy: 0.6183 - val_loss: 1.3930 - val_accuracy: 0.5507\n",
      "Epoch 4/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.9171 - accuracy: 0.6761\n",
      "Epoch 00004: val_accuracy improved from 0.55070 to 0.56570, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model6_04-0.57.hdf5\n",
      "390/390 [==============================] - 138s 354ms/step - loss: 0.9169 - accuracy: 0.6762 - val_loss: 1.3800 - val_accuracy: 0.5657\n",
      "Epoch 5/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.8098 - accuracy: 0.7160\n",
      "Epoch 00005: val_accuracy improved from 0.56570 to 0.67600, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model6_05-0.68.hdf5\n",
      "390/390 [==============================] - 138s 354ms/step - loss: 0.8097 - accuracy: 0.7159 - val_loss: 0.9822 - val_accuracy: 0.6760\n",
      "Epoch 6/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.7262 - accuracy: 0.7463\n",
      "Epoch 00006: val_accuracy did not improve from 0.67600\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.7262 - accuracy: 0.7463 - val_loss: 1.1215 - val_accuracy: 0.6348\n",
      "Epoch 7/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.6702 - accuracy: 0.7648\n",
      "Epoch 00007: val_accuracy improved from 0.67600 to 0.73430, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model6_07-0.73.hdf5\n",
      "390/390 [==============================] - 138s 354ms/step - loss: 0.6701 - accuracy: 0.7649 - val_loss: 0.7764 - val_accuracy: 0.7343\n",
      "Epoch 8/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.6188 - accuracy: 0.7824\n",
      "Epoch 00008: val_accuracy improved from 0.73430 to 0.77720, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model6_08-0.78.hdf5\n",
      "390/390 [==============================] - 138s 354ms/step - loss: 0.6186 - accuracy: 0.7825 - val_loss: 0.6698 - val_accuracy: 0.7772\n",
      "Epoch 9/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5802 - accuracy: 0.7982\n",
      "Epoch 00009: val_accuracy did not improve from 0.77720\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.5798 - accuracy: 0.7984 - val_loss: 0.8203 - val_accuracy: 0.7292\n",
      "Epoch 10/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5451 - accuracy: 0.8106\n",
      "Epoch 00010: val_accuracy did not improve from 0.77720\n",
      "390/390 [==============================] - 137s 352ms/step - loss: 0.5450 - accuracy: 0.8105 - val_loss: 0.7036 - val_accuracy: 0.7676\n",
      "Epoch 11/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.5137 - accuracy: 0.8217\n",
      "Epoch 00011: val_accuracy improved from 0.77720 to 0.79050, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model6_11-0.79.hdf5\n",
      "390/390 [==============================] - 138s 354ms/step - loss: 0.5137 - accuracy: 0.8217 - val_loss: 0.6237 - val_accuracy: 0.7905\n",
      "Epoch 12/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.4874 - accuracy: 0.8314\n",
      "Epoch 00012: val_accuracy did not improve from 0.79050\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.4872 - accuracy: 0.8315 - val_loss: 0.6534 - val_accuracy: 0.7857\n",
      "Epoch 13/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.4676 - accuracy: 0.8383\n",
      "Epoch 00013: val_accuracy improved from 0.79050 to 0.80100, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model6_13-0.80.hdf5\n",
      "390/390 [==============================] - 138s 354ms/step - loss: 0.4674 - accuracy: 0.8384 - val_loss: 0.6053 - val_accuracy: 0.8010\n",
      "Epoch 14/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.4518 - accuracy: 0.8422\n",
      "Epoch 00014: val_accuracy did not improve from 0.80100\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.4516 - accuracy: 0.8422 - val_loss: 0.6065 - val_accuracy: 0.8000\n",
      "Epoch 15/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.4317 - accuracy: 0.8496\n",
      "Epoch 00015: val_accuracy did not improve from 0.80100\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.4318 - accuracy: 0.8495 - val_loss: 0.8728 - val_accuracy: 0.7389\n",
      "Epoch 16/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.4150 - accuracy: 0.8558\n",
      "Epoch 00016: val_accuracy did not improve from 0.80100\n",
      "390/390 [==============================] - 137s 352ms/step - loss: 0.4149 - accuracy: 0.8558 - val_loss: 0.6928 - val_accuracy: 0.7833\n",
      "Epoch 17/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.3964 - accuracy: 0.8626\n",
      "Epoch 00017: val_accuracy did not improve from 0.80100\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.3961 - accuracy: 0.8628 - val_loss: 0.9070 - val_accuracy: 0.7273\n",
      "Epoch 18/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.3868 - accuracy: 0.8666\n",
      "Epoch 00018: val_accuracy improved from 0.80100 to 0.80490, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model6_18-0.80.hdf5\n",
      "390/390 [==============================] - 138s 354ms/step - loss: 0.3868 - accuracy: 0.8667 - val_loss: 0.6350 - val_accuracy: 0.8049\n",
      "Epoch 19/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.3678 - accuracy: 0.8715\n",
      "Epoch 00019: val_accuracy improved from 0.80490 to 0.81600, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model6_19-0.82.hdf5\n",
      "390/390 [==============================] - 138s 355ms/step - loss: 0.3677 - accuracy: 0.8714 - val_loss: 0.5698 - val_accuracy: 0.8160\n",
      "Epoch 20/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.3596 - accuracy: 0.8734\n",
      "Epoch 00020: val_accuracy improved from 0.81600 to 0.82040, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model6_20-0.82.hdf5\n",
      "390/390 [==============================] - 138s 354ms/step - loss: 0.3594 - accuracy: 0.8735 - val_loss: 0.5517 - val_accuracy: 0.8204\n",
      "Epoch 21/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.3471 - accuracy: 0.8786\n",
      "Epoch 00021: val_accuracy did not improve from 0.82040\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.3474 - accuracy: 0.8784 - val_loss: 0.6536 - val_accuracy: 0.7993\n",
      "Epoch 22/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.3368 - accuracy: 0.8832\n",
      "Epoch 00022: val_accuracy did not improve from 0.82040\n",
      "390/390 [==============================] - 137s 352ms/step - loss: 0.3370 - accuracy: 0.8830 - val_loss: 0.6179 - val_accuracy: 0.8077\n",
      "Epoch 23/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.3237 - accuracy: 0.8878\n",
      "Epoch 00023: val_accuracy did not improve from 0.82040\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.3240 - accuracy: 0.8877 - val_loss: 0.7175 - val_accuracy: 0.7860\n",
      "Epoch 24/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.3189 - accuracy: 0.8880\n",
      "Epoch 00024: val_accuracy did not improve from 0.82040\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.3189 - accuracy: 0.8880 - val_loss: 0.5838 - val_accuracy: 0.8171\n",
      "Epoch 25/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.3098 - accuracy: 0.8920\n",
      "Epoch 00025: val_accuracy improved from 0.82040 to 0.82790, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model6_25-0.83.hdf5\n",
      "390/390 [==============================] - 138s 354ms/step - loss: 0.3098 - accuracy: 0.8921 - val_loss: 0.5647 - val_accuracy: 0.8279\n",
      "Epoch 26/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.2966 - accuracy: 0.8960\n",
      "Epoch 00026: val_accuracy did not improve from 0.82790\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.2965 - accuracy: 0.8961 - val_loss: 0.5734 - val_accuracy: 0.8218\n",
      "Epoch 27/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.2893 - accuracy: 0.8979\n",
      "Epoch 00027: val_accuracy did not improve from 0.82790\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.2893 - accuracy: 0.8979 - val_loss: 0.5820 - val_accuracy: 0.8230\n",
      "Epoch 28/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.2768 - accuracy: 0.9022\n",
      "Epoch 00028: val_accuracy did not improve from 0.82790\n",
      "390/390 [==============================] - 137s 352ms/step - loss: 0.2770 - accuracy: 0.9021 - val_loss: 0.6923 - val_accuracy: 0.8024\n",
      "Epoch 29/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.2752 - accuracy: 0.9051\n",
      "Epoch 00029: val_accuracy did not improve from 0.82790\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.2754 - accuracy: 0.9049 - val_loss: 0.6549 - val_accuracy: 0.8176\n",
      "Epoch 30/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.2652 - accuracy: 0.9073\n",
      "Epoch 00030: val_accuracy improved from 0.82790 to 0.83870, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model6_30-0.84.hdf5\n",
      "390/390 [==============================] - 138s 354ms/step - loss: 0.2654 - accuracy: 0.9073 - val_loss: 0.5280 - val_accuracy: 0.8387\n",
      "Epoch 31/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.2660 - accuracy: 0.9066\n",
      "Epoch 00031: val_accuracy did not improve from 0.83870\n",
      "390/390 [==============================] - 137s 352ms/step - loss: 0.2660 - accuracy: 0.9066 - val_loss: 0.5413 - val_accuracy: 0.8364\n",
      "Epoch 32/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.2543 - accuracy: 0.9105\n",
      "Epoch 00032: val_accuracy did not improve from 0.83870\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.2543 - accuracy: 0.9106 - val_loss: 0.5786 - val_accuracy: 0.8306\n",
      "Epoch 33/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.2454 - accuracy: 0.9140\n",
      "Epoch 00033: val_accuracy improved from 0.83870 to 0.84930, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model6_33-0.85.hdf5\n",
      "390/390 [==============================] - 138s 354ms/step - loss: 0.2453 - accuracy: 0.9141 - val_loss: 0.5121 - val_accuracy: 0.8493\n",
      "Epoch 34/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.2444 - accuracy: 0.9137\n",
      "Epoch 00034: val_accuracy did not improve from 0.84930\n",
      "390/390 [==============================] - 137s 352ms/step - loss: 0.2445 - accuracy: 0.9136 - val_loss: 0.6663 - val_accuracy: 0.8154\n",
      "Epoch 35/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.2369 - accuracy: 0.9168\n",
      "Epoch 00035: val_accuracy did not improve from 0.84930\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.2369 - accuracy: 0.9168 - val_loss: 0.7122 - val_accuracy: 0.8040\n",
      "Epoch 36/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.2324 - accuracy: 0.9187\n",
      "Epoch 00036: val_accuracy did not improve from 0.84930\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.2322 - accuracy: 0.9188 - val_loss: 0.5439 - val_accuracy: 0.8392\n",
      "Epoch 37/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.2264 - accuracy: 0.9202\n",
      "Epoch 00037: val_accuracy did not improve from 0.84930\n",
      "390/390 [==============================] - 137s 352ms/step - loss: 0.2263 - accuracy: 0.9202 - val_loss: 0.7712 - val_accuracy: 0.7727\n",
      "Epoch 38/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.2230 - accuracy: 0.9224\n",
      "Epoch 00038: val_accuracy did not improve from 0.84930\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.2228 - accuracy: 0.9225 - val_loss: 0.5727 - val_accuracy: 0.8386\n",
      "Epoch 39/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.2154 - accuracy: 0.9225\n",
      "Epoch 00039: val_accuracy did not improve from 0.84930\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.2155 - accuracy: 0.9225 - val_loss: 0.5577 - val_accuracy: 0.8404\n",
      "Epoch 40/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.2102 - accuracy: 0.9266\n",
      "Epoch 00040: val_accuracy did not improve from 0.84930\n",
      "390/390 [==============================] - 137s 352ms/step - loss: 0.2102 - accuracy: 0.9266 - val_loss: 0.4954 - val_accuracy: 0.8489\n",
      "Epoch 41/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.2030 - accuracy: 0.9282\n",
      "Epoch 00041: val_accuracy did not improve from 0.84930\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.2030 - accuracy: 0.9281 - val_loss: 0.6793 - val_accuracy: 0.8150\n",
      "Epoch 42/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1999 - accuracy: 0.9299\n",
      "Epoch 00042: val_accuracy did not improve from 0.84930\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.2002 - accuracy: 0.9299 - val_loss: 0.6001 - val_accuracy: 0.8385\n",
      "Epoch 43/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1982 - accuracy: 0.9293\n",
      "Epoch 00043: val_accuracy did not improve from 0.84930\n",
      "390/390 [==============================] - 137s 352ms/step - loss: 0.1981 - accuracy: 0.9293 - val_loss: 0.5893 - val_accuracy: 0.8382\n",
      "Epoch 44/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1929 - accuracy: 0.9331\n",
      "Epoch 00044: val_accuracy did not improve from 0.84930\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.1928 - accuracy: 0.9331 - val_loss: 0.5809 - val_accuracy: 0.8305\n",
      "Epoch 45/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1906 - accuracy: 0.9325\n",
      "Epoch 00045: val_accuracy did not improve from 0.84930\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.1903 - accuracy: 0.9325 - val_loss: 0.5722 - val_accuracy: 0.8367\n",
      "Epoch 46/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1847 - accuracy: 0.9349\n",
      "Epoch 00046: val_accuracy did not improve from 0.84930\n",
      "390/390 [==============================] - 137s 352ms/step - loss: 0.1849 - accuracy: 0.9349 - val_loss: 0.6191 - val_accuracy: 0.8349\n",
      "Epoch 47/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1850 - accuracy: 0.9340\n",
      "Epoch 00047: val_accuracy did not improve from 0.84930\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.1848 - accuracy: 0.9342 - val_loss: 0.5609 - val_accuracy: 0.8484\n",
      "Epoch 48/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1780 - accuracy: 0.9370\n",
      "Epoch 00048: val_accuracy did not improve from 0.84930\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.1782 - accuracy: 0.9370 - val_loss: 0.5538 - val_accuracy: 0.8435\n",
      "Epoch 49/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1703 - accuracy: 0.9397\n",
      "Epoch 00049: val_accuracy improved from 0.84930 to 0.86030, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model6_49-0.86.hdf5\n",
      "390/390 [==============================] - 138s 354ms/step - loss: 0.1705 - accuracy: 0.9397 - val_loss: 0.5008 - val_accuracy: 0.8603\n",
      "Epoch 50/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1727 - accuracy: 0.9391\n",
      "Epoch 00050: val_accuracy did not improve from 0.86030\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.1728 - accuracy: 0.9391 - val_loss: 0.5259 - val_accuracy: 0.8520\n",
      "Epoch 51/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1671 - accuracy: 0.9415\n",
      "Epoch 00051: val_accuracy did not improve from 0.86030\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.1672 - accuracy: 0.9415 - val_loss: 0.5809 - val_accuracy: 0.8392\n",
      "Epoch 52/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1682 - accuracy: 0.9409\n",
      "Epoch 00052: val_accuracy did not improve from 0.86030\n",
      "390/390 [==============================] - 137s 352ms/step - loss: 0.1684 - accuracy: 0.9409 - val_loss: 0.6328 - val_accuracy: 0.8346\n",
      "Epoch 53/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1616 - accuracy: 0.9423\n",
      "Epoch 00053: val_accuracy improved from 0.86030 to 0.86160, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model6_53-0.86.hdf5\n",
      "390/390 [==============================] - 138s 354ms/step - loss: 0.1621 - accuracy: 0.9421 - val_loss: 0.5077 - val_accuracy: 0.8616\n",
      "Epoch 54/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1586 - accuracy: 0.9440\n",
      "Epoch 00054: val_accuracy did not improve from 0.86160\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.1585 - accuracy: 0.9440 - val_loss: 0.5327 - val_accuracy: 0.8547\n",
      "Epoch 55/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1549 - accuracy: 0.9452\n",
      "Epoch 00055: val_accuracy improved from 0.86160 to 0.86380, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model6_55-0.86.hdf5\n",
      "390/390 [==============================] - 138s 354ms/step - loss: 0.1549 - accuracy: 0.9452 - val_loss: 0.5082 - val_accuracy: 0.8638\n",
      "Epoch 56/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1561 - accuracy: 0.9444\n",
      "Epoch 00056: val_accuracy improved from 0.86380 to 0.87290, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model6_56-0.87.hdf5\n",
      "390/390 [==============================] - 138s 354ms/step - loss: 0.1560 - accuracy: 0.9444 - val_loss: 0.4334 - val_accuracy: 0.8729\n",
      "Epoch 57/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1516 - accuracy: 0.9462\n",
      "Epoch 00057: val_accuracy did not improve from 0.87290\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.1515 - accuracy: 0.9462 - val_loss: 0.4645 - val_accuracy: 0.8719\n",
      "Epoch 58/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1458 - accuracy: 0.9487\n",
      "Epoch 00058: val_accuracy did not improve from 0.87290\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.1457 - accuracy: 0.9488 - val_loss: 0.5121 - val_accuracy: 0.8672\n",
      "Epoch 59/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1464 - accuracy: 0.9487\n",
      "Epoch 00059: val_accuracy did not improve from 0.87290\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.1467 - accuracy: 0.9487 - val_loss: 0.5502 - val_accuracy: 0.8542\n",
      "Epoch 60/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1432 - accuracy: 0.9486\n",
      "Epoch 00060: val_accuracy did not improve from 0.87290\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.1431 - accuracy: 0.9486 - val_loss: 0.5808 - val_accuracy: 0.8520\n",
      "Epoch 61/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1422 - accuracy: 0.9504\n",
      "Epoch 00061: val_accuracy did not improve from 0.87290\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.1423 - accuracy: 0.9504 - val_loss: 0.5301 - val_accuracy: 0.8596\n",
      "Epoch 62/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1401 - accuracy: 0.9504\n",
      "Epoch 00062: val_accuracy did not improve from 0.87290\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.1401 - accuracy: 0.9504 - val_loss: 0.6384 - val_accuracy: 0.8413\n",
      "Epoch 63/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1371 - accuracy: 0.9509\n",
      "Epoch 00063: val_accuracy did not improve from 0.87290\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.1373 - accuracy: 0.9509 - val_loss: 0.5965 - val_accuracy: 0.8532\n",
      "Epoch 64/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1314 - accuracy: 0.9535\n",
      "Epoch 00064: val_accuracy did not improve from 0.87290\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.1316 - accuracy: 0.9535 - val_loss: 0.5519 - val_accuracy: 0.8591\n",
      "Epoch 65/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1301 - accuracy: 0.9530\n",
      "Epoch 00065: val_accuracy did not improve from 0.87290\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.1300 - accuracy: 0.9530 - val_loss: 0.6794 - val_accuracy: 0.8387\n",
      "Epoch 66/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1320 - accuracy: 0.9533\n",
      "Epoch 00066: val_accuracy did not improve from 0.87290\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.1321 - accuracy: 0.9532 - val_loss: 0.5336 - val_accuracy: 0.8595\n",
      "Epoch 67/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1286 - accuracy: 0.9544\n",
      "Epoch 00067: val_accuracy did not improve from 0.87290\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.1287 - accuracy: 0.9543 - val_loss: 0.5444 - val_accuracy: 0.8577\n",
      "Epoch 68/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1263 - accuracy: 0.9548\n",
      "Epoch 00068: val_accuracy did not improve from 0.87290\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.1263 - accuracy: 0.9548 - val_loss: 0.5496 - val_accuracy: 0.8597\n",
      "Epoch 69/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1257 - accuracy: 0.9546\n",
      "Epoch 00069: val_accuracy did not improve from 0.87290\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.1259 - accuracy: 0.9546 - val_loss: 0.5733 - val_accuracy: 0.8591\n",
      "Epoch 70/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1251 - accuracy: 0.9554\n",
      "Epoch 00070: val_accuracy did not improve from 0.87290\n",
      "390/390 [==============================] - 137s 352ms/step - loss: 0.1250 - accuracy: 0.9554 - val_loss: 0.5491 - val_accuracy: 0.8535\n",
      "Epoch 71/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1243 - accuracy: 0.9560\n",
      "Epoch 00071: val_accuracy did not improve from 0.87290\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.1243 - accuracy: 0.9560 - val_loss: 0.5506 - val_accuracy: 0.8616\n",
      "Epoch 72/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.1219 - accuracy: 0.9565\n",
      "Epoch 00072: val_accuracy did not improve from 0.87290\n",
      "\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.1221 - accuracy: 0.9564 - val_loss: 0.7693 - val_accuracy: 0.8225\n",
      "Epoch 73/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0768 - accuracy: 0.9740\n",
      "Epoch 00073: val_accuracy improved from 0.87290 to 0.89580, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model6_73-0.90.hdf5\n",
      "390/390 [==============================] - 138s 355ms/step - loss: 0.0767 - accuracy: 0.9740 - val_loss: 0.4004 - val_accuracy: 0.8958\n",
      "Epoch 74/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0613 - accuracy: 0.9795\n",
      "Epoch 00074: val_accuracy did not improve from 0.89580\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.0614 - accuracy: 0.9795 - val_loss: 0.4125 - val_accuracy: 0.8946\n",
      "Epoch 75/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0567 - accuracy: 0.9807\n",
      "Epoch 00075: val_accuracy did not improve from 0.89580\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.0566 - accuracy: 0.9807 - val_loss: 0.4108 - val_accuracy: 0.8951\n",
      "Epoch 76/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0528 - accuracy: 0.9819\n",
      "Epoch 00076: val_accuracy improved from 0.89580 to 0.89610, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model6_76-0.90.hdf5\n",
      "390/390 [==============================] - 138s 354ms/step - loss: 0.0528 - accuracy: 0.9819 - val_loss: 0.4177 - val_accuracy: 0.8961\n",
      "Epoch 77/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0472 - accuracy: 0.9841\n",
      "Epoch 00077: val_accuracy did not improve from 0.89610\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.0473 - accuracy: 0.9841 - val_loss: 0.4338 - val_accuracy: 0.8952\n",
      "Epoch 78/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0447 - accuracy: 0.9851\n",
      "Epoch 00078: val_accuracy did not improve from 0.89610\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.0447 - accuracy: 0.9851 - val_loss: 0.4628 - val_accuracy: 0.8919\n",
      "Epoch 79/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0448 - accuracy: 0.9846\n",
      "Epoch 00079: val_accuracy did not improve from 0.89610\n",
      "390/390 [==============================] - 137s 352ms/step - loss: 0.0447 - accuracy: 0.9846 - val_loss: 0.4731 - val_accuracy: 0.8919\n",
      "Epoch 80/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0397 - accuracy: 0.9865\n",
      "Epoch 00080: val_accuracy did not improve from 0.89610\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.0397 - accuracy: 0.9865 - val_loss: 0.4634 - val_accuracy: 0.8931\n",
      "Epoch 81/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0375 - accuracy: 0.9872\n",
      "Epoch 00081: val_accuracy improved from 0.89610 to 0.89920, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model6_81-0.90.hdf5\n",
      "390/390 [==============================] - 138s 354ms/step - loss: 0.0375 - accuracy: 0.9872 - val_loss: 0.4493 - val_accuracy: 0.8992\n",
      "Epoch 82/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0364 - accuracy: 0.9880\n",
      "Epoch 00082: val_accuracy improved from 0.89920 to 0.89990, saving model to /home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model6_82-0.90.hdf5\n",
      "390/390 [==============================] - 138s 354ms/step - loss: 0.0364 - accuracy: 0.9880 - val_loss: 0.4682 - val_accuracy: 0.8999\n",
      "Epoch 83/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0360 - accuracy: 0.9875\n",
      "Epoch 00083: val_accuracy did not improve from 0.89990\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.0360 - accuracy: 0.9875 - val_loss: 0.4960 - val_accuracy: 0.8919\n",
      "Epoch 84/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0371 - accuracy: 0.9872\n",
      "Epoch 00084: val_accuracy did not improve from 0.89990\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.0371 - accuracy: 0.9872 - val_loss: 0.5114 - val_accuracy: 0.8920\n",
      "Epoch 85/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0366 - accuracy: 0.9872\n",
      "Epoch 00085: val_accuracy did not improve from 0.89990\n",
      "390/390 [==============================] - 137s 352ms/step - loss: 0.0366 - accuracy: 0.9872 - val_loss: 0.4935 - val_accuracy: 0.8941\n",
      "Epoch 86/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0352 - accuracy: 0.9876\n",
      "Epoch 00086: val_accuracy did not improve from 0.89990\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.0351 - accuracy: 0.9876 - val_loss: 0.5134 - val_accuracy: 0.8921\n",
      "Epoch 87/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0338 - accuracy: 0.9881\n",
      "Epoch 00087: val_accuracy did not improve from 0.89990\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.0338 - accuracy: 0.9881 - val_loss: 0.4842 - val_accuracy: 0.8960\n",
      "Epoch 88/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0344 - accuracy: 0.9883\n",
      "Epoch 00088: val_accuracy did not improve from 0.89990\n",
      "390/390 [==============================] - 137s 352ms/step - loss: 0.0344 - accuracy: 0.9883 - val_loss: 0.5214 - val_accuracy: 0.8917\n",
      "Epoch 89/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0317 - accuracy: 0.9891\n",
      "Epoch 00089: val_accuracy did not improve from 0.89990\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.0317 - accuracy: 0.9891 - val_loss: 0.5089 - val_accuracy: 0.8964\n",
      "Epoch 90/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0305 - accuracy: 0.9897\n",
      "Epoch 00090: val_accuracy did not improve from 0.89990\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.0305 - accuracy: 0.9897 - val_loss: 0.5021 - val_accuracy: 0.8962\n",
      "Epoch 91/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0304 - accuracy: 0.9902\n",
      "Epoch 00091: val_accuracy did not improve from 0.89990\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.0305 - accuracy: 0.9901 - val_loss: 0.5550 - val_accuracy: 0.8916\n",
      "Epoch 92/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0297 - accuracy: 0.9898\n",
      "Epoch 00092: val_accuracy did not improve from 0.89990\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.0298 - accuracy: 0.9898 - val_loss: 0.5071 - val_accuracy: 0.8972\n",
      "Epoch 93/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0296 - accuracy: 0.9901\n",
      "Epoch 00093: val_accuracy did not improve from 0.89990\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.0297 - accuracy: 0.9901 - val_loss: 0.5258 - val_accuracy: 0.8939\n",
      "Epoch 94/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0284 - accuracy: 0.9903\n",
      "Epoch 00094: val_accuracy did not improve from 0.89990\n",
      "390/390 [==============================] - 137s 352ms/step - loss: 0.0286 - accuracy: 0.9903 - val_loss: 0.5146 - val_accuracy: 0.8958\n",
      "Epoch 95/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0277 - accuracy: 0.9909\n",
      "Epoch 00095: val_accuracy did not improve from 0.89990\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.0277 - accuracy: 0.9909 - val_loss: 0.5141 - val_accuracy: 0.8984\n",
      "Epoch 96/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0275 - accuracy: 0.9907\n",
      "Epoch 00096: val_accuracy did not improve from 0.89990\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.0276 - accuracy: 0.9907 - val_loss: 0.5237 - val_accuracy: 0.8962\n",
      "Epoch 97/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0282 - accuracy: 0.9899\n",
      "Epoch 00097: val_accuracy did not improve from 0.89990\n",
      "390/390 [==============================] - 137s 352ms/step - loss: 0.0282 - accuracy: 0.9899 - val_loss: 0.5292 - val_accuracy: 0.8979\n",
      "Epoch 98/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0269 - accuracy: 0.9909\n",
      "Epoch 00098: val_accuracy did not improve from 0.89990\n",
      "\n",
      "Epoch 00098: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.0269 - accuracy: 0.9909 - val_loss: 0.5317 - val_accuracy: 0.8951\n",
      "Epoch 99/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0271 - accuracy: 0.9906\n",
      "Epoch 00099: val_accuracy did not improve from 0.89990\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.0271 - accuracy: 0.9906 - val_loss: 0.5343 - val_accuracy: 0.8962\n",
      "Epoch 100/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0243 - accuracy: 0.9920\n",
      "Epoch 00100: val_accuracy did not improve from 0.89990\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.0243 - accuracy: 0.9920 - val_loss: 0.5313 - val_accuracy: 0.8969\n",
      "Epoch 101/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0237 - accuracy: 0.9914\n",
      "Epoch 00101: val_accuracy did not improve from 0.89990\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.0236 - accuracy: 0.9914 - val_loss: 0.5344 - val_accuracy: 0.8961\n",
      "Epoch 102/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0240 - accuracy: 0.9918\n",
      "Epoch 00102: val_accuracy did not improve from 0.89990\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.0240 - accuracy: 0.9918 - val_loss: 0.5361 - val_accuracy: 0.8971\n",
      "Epoch 103/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0225 - accuracy: 0.9925\n",
      "Epoch 00103: val_accuracy did not improve from 0.89990\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.0225 - accuracy: 0.9925 - val_loss: 0.5332 - val_accuracy: 0.8971\n",
      "Epoch 104/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0259 - accuracy: 0.9914\n",
      "Epoch 00104: val_accuracy did not improve from 0.89990\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.0259 - accuracy: 0.9914 - val_loss: 0.5336 - val_accuracy: 0.8972\n",
      "Epoch 105/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0233 - accuracy: 0.9921\n",
      "Epoch 00105: val_accuracy did not improve from 0.89990\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.0233 - accuracy: 0.9921 - val_loss: 0.5345 - val_accuracy: 0.8969\n",
      "Epoch 106/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0224 - accuracy: 0.9918\n",
      "Epoch 00106: val_accuracy did not improve from 0.89990\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.0225 - accuracy: 0.9918 - val_loss: 0.5367 - val_accuracy: 0.8972\n",
      "Epoch 107/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0215 - accuracy: 0.9931\n",
      "Epoch 00107: val_accuracy did not improve from 0.89990\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.0216 - accuracy: 0.9931 - val_loss: 0.5334 - val_accuracy: 0.8979\n",
      "Epoch 108/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0215 - accuracy: 0.9927\n",
      "Epoch 00108: val_accuracy did not improve from 0.89990\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.0215 - accuracy: 0.9927 - val_loss: 0.5375 - val_accuracy: 0.8961\n",
      "Epoch 109/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0219 - accuracy: 0.9928\n",
      "Epoch 00109: val_accuracy did not improve from 0.89990\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.0219 - accuracy: 0.9927 - val_loss: 0.5292 - val_accuracy: 0.8986\n",
      "Epoch 110/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0221 - accuracy: 0.9925\n",
      "Epoch 00110: val_accuracy did not improve from 0.89990\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.0221 - accuracy: 0.9925 - val_loss: 0.5354 - val_accuracy: 0.8982\n",
      "Epoch 111/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0236 - accuracy: 0.9918\n",
      "Epoch 00111: val_accuracy did not improve from 0.89990\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.0236 - accuracy: 0.9918 - val_loss: 0.5348 - val_accuracy: 0.8974\n",
      "Epoch 112/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0218 - accuracy: 0.9926\n",
      "Epoch 00112: val_accuracy did not improve from 0.89990\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.0218 - accuracy: 0.9926 - val_loss: 0.5355 - val_accuracy: 0.8981\n",
      "Epoch 113/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0209 - accuracy: 0.9929\n",
      "Epoch 00113: val_accuracy did not improve from 0.89990\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.0209 - accuracy: 0.9929 - val_loss: 0.5347 - val_accuracy: 0.8971\n",
      "Epoch 114/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0213 - accuracy: 0.9926\n",
      "Epoch 00114: val_accuracy did not improve from 0.89990\n",
      "\n",
      "Epoch 00114: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.0214 - accuracy: 0.9926 - val_loss: 0.5340 - val_accuracy: 0.8975\n",
      "Epoch 115/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0223 - accuracy: 0.9926\n",
      "Epoch 00115: val_accuracy did not improve from 0.89990\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.0223 - accuracy: 0.9926 - val_loss: 0.5359 - val_accuracy: 0.8975\n",
      "Epoch 116/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0229 - accuracy: 0.9922\n",
      "Epoch 00116: val_accuracy did not improve from 0.89990\n",
      "390/390 [==============================] - 137s 352ms/step - loss: 0.0229 - accuracy: 0.9923 - val_loss: 0.5363 - val_accuracy: 0.8971\n",
      "Epoch 117/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0217 - accuracy: 0.9928\n",
      "Epoch 00117: val_accuracy did not improve from 0.89990\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.0217 - accuracy: 0.9928 - val_loss: 0.5350 - val_accuracy: 0.8975\n",
      "Epoch 118/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0194 - accuracy: 0.9936\n",
      "Epoch 00118: val_accuracy did not improve from 0.89990\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.0194 - accuracy: 0.9937 - val_loss: 0.5358 - val_accuracy: 0.8971\n",
      "Epoch 119/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0216 - accuracy: 0.9925\n",
      "Epoch 00119: val_accuracy did not improve from 0.89990\n",
      "390/390 [==============================] - 137s 352ms/step - loss: 0.0216 - accuracy: 0.9925 - val_loss: 0.5338 - val_accuracy: 0.8978\n",
      "Epoch 120/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0222 - accuracy: 0.9924\n",
      "Epoch 00120: val_accuracy did not improve from 0.89990\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.0222 - accuracy: 0.9924 - val_loss: 0.5363 - val_accuracy: 0.8974\n",
      "Epoch 121/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0201 - accuracy: 0.9932\n",
      "Epoch 00121: val_accuracy did not improve from 0.89990\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.0201 - accuracy: 0.9932 - val_loss: 0.5330 - val_accuracy: 0.8979\n",
      "Epoch 122/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0216 - accuracy: 0.9926\n",
      "Epoch 00122: val_accuracy did not improve from 0.89990\n",
      "390/390 [==============================] - 137s 352ms/step - loss: 0.0215 - accuracy: 0.9926 - val_loss: 0.5376 - val_accuracy: 0.8965\n",
      "Epoch 123/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0213 - accuracy: 0.9928\n",
      "Epoch 00123: val_accuracy did not improve from 0.89990\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.0212 - accuracy: 0.9929 - val_loss: 0.5361 - val_accuracy: 0.8972\n",
      "Epoch 124/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0208 - accuracy: 0.9931\n",
      "Epoch 00124: val_accuracy did not improve from 0.89990\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.0208 - accuracy: 0.9931 - val_loss: 0.5376 - val_accuracy: 0.8967\n",
      "Epoch 125/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0202 - accuracy: 0.9933\n",
      "Epoch 00125: val_accuracy did not improve from 0.89990\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.0202 - accuracy: 0.9933 - val_loss: 0.5372 - val_accuracy: 0.8971\n",
      "Epoch 126/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0199 - accuracy: 0.9929\n",
      "Epoch 00126: val_accuracy did not improve from 0.89990\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.0199 - accuracy: 0.9929 - val_loss: 0.5341 - val_accuracy: 0.8977\n",
      "Epoch 127/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0220 - accuracy: 0.9923\n",
      "Epoch 00127: val_accuracy did not improve from 0.89990\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.0222 - accuracy: 0.9923 - val_loss: 0.5363 - val_accuracy: 0.8966\n",
      "Epoch 128/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0213 - accuracy: 0.9927\n",
      "Epoch 00128: val_accuracy did not improve from 0.89990\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.0212 - accuracy: 0.9927 - val_loss: 0.5334 - val_accuracy: 0.8975\n",
      "Epoch 129/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0230 - accuracy: 0.9923\n",
      "Epoch 00129: val_accuracy did not improve from 0.89990\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.0230 - accuracy: 0.9923 - val_loss: 0.5349 - val_accuracy: 0.8973\n",
      "Epoch 130/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0214 - accuracy: 0.9926\n",
      "Epoch 00130: val_accuracy did not improve from 0.89990\n",
      "\n",
      "Epoch 00130: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.0214 - accuracy: 0.9925 - val_loss: 0.5356 - val_accuracy: 0.8976\n",
      "Epoch 131/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0201 - accuracy: 0.9932\n",
      "Epoch 00131: val_accuracy did not improve from 0.89990\n",
      "390/390 [==============================] - 137s 352ms/step - loss: 0.0201 - accuracy: 0.9932 - val_loss: 0.5365 - val_accuracy: 0.8970\n",
      "Epoch 132/300\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0216 - accuracy: 0.9921\n",
      "Epoch 00132: val_accuracy did not improve from 0.89990\n",
      "390/390 [==============================] - 137s 351ms/step - loss: 0.0217 - accuracy: 0.9921 - val_loss: 0.5356 - val_accuracy: 0.8976\n"
     ]
    }
   ],
   "source": [
    "model_6.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "patience = 50\n",
    "base_path = '/home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/'\n",
    "checkpoint_file_name = base_path + 'CIFAR_model6' + '_{epoch:02d}-{val_accuracy:.2f}.hdf5'\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(checkpoint_file_name, monitor='val_accuracy', verbose=1, save_best_only=True)\n",
    "early_stop = EarlyStopping('val_accuracy', mode='max', patience = patience)\n",
    "reduce_LR = ReduceLROnPlateau(monitor='val_accuracy', mode='max', factor=0.1, patience=int(patience/3), verbose=1)\n",
    "\n",
    "callbacks = [model_checkpoint, early_stop, reduce_LR]\n",
    "\n",
    "epochs = 300\n",
    "batch_size = 128\n",
    "\n",
    "#https://keras.io/api/preprocessing/image/#flow-method\n",
    "history_6 = model_6.fit(data_generator.flow(X_train, y_train, batch_size),\n",
    "                    steps_per_epoch = int(len(X_train)/batch_size),\n",
    "                    epochs = epochs,\n",
    "                    callbacks = callbacks,\n",
    "                    validation_data = (X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#history plot for accyracy\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.plot(history_6.history['accuracy'])\n",
    "plt.plot(history_6.history['val_accuracy'])\n",
    "plt.title(\"Model Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend([\"train\", \"test\"], loc=\"upper left\")\n",
    "plt.show()\n",
    "\n",
    "# history plot for accuracy\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.plot(history_6.history[\"loss\"])\n",
    "plt.plot(history_6.history[\"val_loss\"])\n",
    "plt.title(\"Model Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend([\"train\", \"test\"], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 9s 854us/sample - loss: 0.4682 - accuracy: 0.8999\n",
      "[0.46815555404126646, 0.8999]\n"
     ]
    }
   ],
   "source": [
    "best_model_6 = tf.keras.models.load_model('/home/ubuntu/Project/my_data/CNN_CIFAR/checkpoint/CIFAR_model6_82-0.90.hdf5')\n",
    "scores = best_model_6.evaluate(X_test, y_test, verbose=1)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------------+-------------+-------------+---------+------------------+---------------+\n",
      "|  Model  |          Conv          | final_layer | kernel_size | dropout | No of parameters | Test Accuracy |\n",
      "+---------+------------------------+-------------+-------------+---------+------------------+---------------+\n",
      "| model_1 |         Conv2D         |    dense    |     3x3     | 118,918 |       0.2        |     80.83%    |\n",
      "| model_2 |         Conv2D         |    dense    |     3x3     | 118,918 |       0.2        |     81.33%    |\n",
      "| model_3 | SeparableConvolution2D |    dense    |     5x5     |   0.2   |     258,282      |     86.81%    |\n",
      "| model_4 | SeparableConvolution2D |    dense    |     7x7     |   0.2   |     385,002      |     87.16%    |\n",
      "| model_5 | SeparableConvolution2D |    Conv2D   |     7x7     |   0.2   |     945,472      |     89.21%    |\n",
      "| model_5 | SeparableConvolution2D |    Conv2D   |     7x7     |    0    |     945,472      |    89.999%    |\n",
      "+---------+------------------------+-------------+-------------+---------+------------------+---------------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "    \n",
    "x = PrettyTable()\n",
    "\n",
    "x.field_names = [\"Model\", \"Conv\", 'final_layer', \"kernel_size\", 'dropout', 'No of parameters', \"Test Accuracy\"]\n",
    "x.add_row(['model_1','Conv2D','dense', '3x3', '118,918', '0.2','80.83%'])\n",
    "x.add_row(['model_2','Conv2D','dense', '3x3', '118,918', '0.2','81.33%'])\n",
    "x.add_row(['model_3','SeparableConvolution2D', 'dense', '5x5', '0.2','258,282', '86.81%'])\n",
    "x.add_row(['model_4','SeparableConvolution2D', 'dense', '7x7', '0.2','385,002', '87.16%'])\n",
    "x.add_row(['model_5','SeparableConvolution2D', 'Conv2D', '7x7', '0.2','945,472', '89.21%'])\n",
    "x.add_row(['model_5','SeparableConvolution2D', 'Conv2D', '7x7', '0','945,472', '89.999%'])\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note:\n",
    "- After tried, final layer as Conv2D instead of flatten layer without dropout i have achieved test accuracy of 89.999%"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PremKumar_kaliyamoorthy_DenseNet.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow2_p36)",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
